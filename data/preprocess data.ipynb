{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### make datasets into BERT format & split train-test if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = 'train'\n",
    "out_path = 'aclImdb/'\n",
    "path = 'aclImdb/' + train + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cur_path = path+'pos'\n",
    "directory = os.fsencode(cur_path)\n",
    "\n",
    "txt_lst = []\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if not filename.endswith(\".txt\"): \n",
    "        print(filename + ' - not .txt')\n",
    "        continue\n",
    "    else:\n",
    "        with open(os.path.join(cur_path, filename), 'r', encoding='utf-8') as f:\n",
    "            txt_lst.append(f.read().replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pos = pd.DataFrame(txt_lst, columns=['content'])\n",
    "pos['label'] = np.ones((len(pos), 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 2)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lens = pos.content.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7218"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lens < 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pos = pos[lens < 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cur_path = path+'neg'\n",
    "directory = os.fsencode(cur_path)\n",
    "\n",
    "txt_lst = []\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if not filename.endswith(\".txt\"): \n",
    "        print(filename + ' - not .txt')\n",
    "        continue\n",
    "    else:\n",
    "        with open(os.path.join(cur_path, filename), 'r', encoding='utf-8') as f:\n",
    "            txt_lst.append(f.read().replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "neg = pd.DataFrame(txt_lst, columns=['content'])\n",
    "neg['label'] = np.zeros((len(neg), 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lens = neg.content.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7362"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lens < 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "neg = neg[lens < 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([pos,neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes it was a little low budget, but this movie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I really liked this movie I saw the original c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I appreciated the photography, the textures, t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>...intimate and specific. Yes, a bit of a cind...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A classic cartoon, always enjoyable and funny....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  label\n",
       "0   Yes it was a little low budget, but this movie...      1\n",
       "1   I really liked this movie I saw the original c...      1\n",
       "2   I appreciated the photography, the textures, t...      1\n",
       "8   ...intimate and specific. Yes, a bit of a cind...      1\n",
       "13  A classic cartoon, always enjoyable and funny....      1"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.label.astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(out_path + 'imdb_' + train + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### click-bait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_data = pd.read_json('clickbait/instances.jsonl', lines=True)\n",
    "df_target = pd.read_json('clickbait/truth.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19538"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mrege both dataframes\n",
    "df = df_data.merge(df_target, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>postMedia</th>\n",
       "      <th>postText</th>\n",
       "      <th>postTimestamp</th>\n",
       "      <th>targetCaptions</th>\n",
       "      <th>targetDescription</th>\n",
       "      <th>targetKeywords</th>\n",
       "      <th>targetParagraphs</th>\n",
       "      <th>targetTitle</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthJudgments</th>\n",
       "      <th>truthMean</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthMode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>858462320779026432</td>\n",
       "      <td>[]</td>\n",
       "      <td>[UK’s response to modern slavery leaving victi...</td>\n",
       "      <td>Sat Apr 29 23:25:41 +0000 2017</td>\n",
       "      <td>[modern-slavery-rex.jpg]</td>\n",
       "      <td>“Inexcusable” failures in the UK’s system for ...</td>\n",
       "      <td>modern slavery, Department For Work And Pensio...</td>\n",
       "      <td>[Thousands of modern slavery victims have not ...</td>\n",
       "      <td>‘Inexcusable’ failures in UK’s response to mod...</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>[0.33333333330000003, 0.0, 0.33333333330000003...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>858421020331560960</td>\n",
       "      <td>[]</td>\n",
       "      <td>[this is good]</td>\n",
       "      <td>Sat Apr 29 20:41:34 +0000 2017</td>\n",
       "      <td>[In this July 1, 2010 file photo, Dr. Charmain...</td>\n",
       "      <td>President Donald Trump has appointed pro-life ...</td>\n",
       "      <td>Americans United for Life, Dr. Charmaine Yoest...</td>\n",
       "      <td>[President Donald Trump has appointed the pro-...</td>\n",
       "      <td>Donald Trump Appoints Pro-Life Advocate as Ass...</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>858368123753435136</td>\n",
       "      <td>[]</td>\n",
       "      <td>[The \"forgotten\" Trump roast: Relive his bruta...</td>\n",
       "      <td>Sat Apr 29 17:11:23 +0000 2017</td>\n",
       "      <td>[President Trump will not attend this year's W...</td>\n",
       "      <td>President Trump won't be at this year's White ...</td>\n",
       "      <td>trump whcd, whcd, white house correspondents d...</td>\n",
       "      <td>[When the White House correspondents’ dinner i...</td>\n",
       "      <td>The ‘forgotten’ Trump roast: Relive his brutal...</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>[0.33333333330000003, 1.0, 0.33333333330000003...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>858323428260139008</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Meet the happiest #dog in the world!]</td>\n",
       "      <td>Sat Apr 29 14:13:46 +0000 2017</td>\n",
       "      <td>[Maru , Maru, Maru, Maru, Maru]</td>\n",
       "      <td>The article is about Maru, a husky dog who has...</td>\n",
       "      <td>Maru, husky, dogs, pandas, furball, instagram</td>\n",
       "      <td>[Adorable is probably an understatement. This ...</td>\n",
       "      <td>Meet The Happiest Dog In The World, Maru The H...</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>[1.0, 0.6666666666000001, 1.0, 1.0, 1.0]</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>858283602626347008</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Tokyo's subway is shut down amid fears over a...</td>\n",
       "      <td>Sat Apr 29 11:35:31 +0000 2017</td>\n",
       "      <td>[All nine lines of Tokyo's subway system were ...</td>\n",
       "      <td>The temporary suspension, which lasted ten min...</td>\n",
       "      <td>Tokyo,subway,shut,fears,North,Korean,attack</td>\n",
       "      <td>[One of Tokyo's major subways systems says it ...</td>\n",
       "      <td>Tokyo's subway is shut down amid fears over an...</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id postMedia  \\\n",
       "0  858462320779026432        []   \n",
       "1  858421020331560960        []   \n",
       "2  858368123753435136        []   \n",
       "3  858323428260139008        []   \n",
       "4  858283602626347008        []   \n",
       "\n",
       "                                            postText  \\\n",
       "0  [UK’s response to modern slavery leaving victi...   \n",
       "1                                     [this is good]   \n",
       "2  [The \"forgotten\" Trump roast: Relive his bruta...   \n",
       "3             [Meet the happiest #dog in the world!]   \n",
       "4  [Tokyo's subway is shut down amid fears over a...   \n",
       "\n",
       "                    postTimestamp  \\\n",
       "0  Sat Apr 29 23:25:41 +0000 2017   \n",
       "1  Sat Apr 29 20:41:34 +0000 2017   \n",
       "2  Sat Apr 29 17:11:23 +0000 2017   \n",
       "3  Sat Apr 29 14:13:46 +0000 2017   \n",
       "4  Sat Apr 29 11:35:31 +0000 2017   \n",
       "\n",
       "                                      targetCaptions  \\\n",
       "0                           [modern-slavery-rex.jpg]   \n",
       "1  [In this July 1, 2010 file photo, Dr. Charmain...   \n",
       "2  [President Trump will not attend this year's W...   \n",
       "3                    [Maru , Maru, Maru, Maru, Maru]   \n",
       "4  [All nine lines of Tokyo's subway system were ...   \n",
       "\n",
       "                                   targetDescription  \\\n",
       "0  “Inexcusable” failures in the UK’s system for ...   \n",
       "1  President Donald Trump has appointed pro-life ...   \n",
       "2  President Trump won't be at this year's White ...   \n",
       "3  The article is about Maru, a husky dog who has...   \n",
       "4  The temporary suspension, which lasted ten min...   \n",
       "\n",
       "                                      targetKeywords  \\\n",
       "0  modern slavery, Department For Work And Pensio...   \n",
       "1  Americans United for Life, Dr. Charmaine Yoest...   \n",
       "2  trump whcd, whcd, white house correspondents d...   \n",
       "3      Maru, husky, dogs, pandas, furball, instagram   \n",
       "4        Tokyo,subway,shut,fears,North,Korean,attack   \n",
       "\n",
       "                                    targetParagraphs  \\\n",
       "0  [Thousands of modern slavery victims have not ...   \n",
       "1  [President Donald Trump has appointed the pro-...   \n",
       "2  [When the White House correspondents’ dinner i...   \n",
       "3  [Adorable is probably an understatement. This ...   \n",
       "4  [One of Tokyo's major subways systems says it ...   \n",
       "\n",
       "                                         targetTitle    truthClass  \\\n",
       "0  ‘Inexcusable’ failures in UK’s response to mod...  no-clickbait   \n",
       "1  Donald Trump Appoints Pro-Life Advocate as Ass...     clickbait   \n",
       "2  The ‘forgotten’ Trump roast: Relive his brutal...  no-clickbait   \n",
       "3  Meet The Happiest Dog In The World, Maru The H...     clickbait   \n",
       "4  Tokyo's subway is shut down amid fears over an...  no-clickbait   \n",
       "\n",
       "                                      truthJudgments  truthMean  truthMedian  \\\n",
       "0  [0.33333333330000003, 0.0, 0.33333333330000003...   0.133333     0.000000   \n",
       "1                          [1.0, 1.0, 1.0, 1.0, 1.0]   1.000000     1.000000   \n",
       "2  [0.33333333330000003, 1.0, 0.33333333330000003...   0.466667     0.333333   \n",
       "3           [1.0, 0.6666666666000001, 1.0, 1.0, 1.0]   0.933333     1.000000   \n",
       "4                          [0.0, 0.0, 0.0, 0.0, 0.0]   0.000000     0.000000   \n",
       "\n",
       "   truthMode  \n",
       "0   0.000000  \n",
       "1   1.000000  \n",
       "2   0.333333  \n",
       "3   1.000000  \n",
       "4   0.000000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/conda_envs/thesis/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[['postText','truthClass']]  # take only wanted columns\n",
    "filtered_df.truthClass = (filtered_df.truthClass == 'clickbait')  # binarise classes\n",
    "filtered_df.columns = ['content', 'label']  # change column names\n",
    "filtered_df.label = filtered_df.label.astype(int)  # make zero 1 for similarity to the others\n",
    "filtered_df.content = filtered_df.content.apply(lambda x: x[0])  # take string and not list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK’s response to modern slavery leaving victim...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The \"forgotten\" Trump roast: Relive his brutal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meet the happiest #dog in the world!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tokyo's subway is shut down amid fears over an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  label\n",
       "0  UK’s response to modern slavery leaving victim...      0\n",
       "1                                       this is good      1\n",
       "2  The \"forgotten\" Trump roast: Relive his brutal...      0\n",
       "3               Meet the happiest #dog in the world!      1\n",
       "4  Tokyo's subway is shut down amid fears over an...      0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "df_click_train, df_click_test = train_test_split(filtered_df, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save files\n",
    "df_click_train.to_csv('clickbait/clickbait_train.csv', index=False)\n",
    "df_click_test.to_csv('clickbait/clickbait_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam/SPAM text message 20170820 - Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.Category = (df.Category == 'spam').astype(int)\n",
    "df.columns = ['label', 'content']\n",
    "df = df[['content', 'label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_spam_train, df_spam_test = train_test_split(df, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_spam_train.to_csv('spam/spam_train.csv', index=False)\n",
    "df_spam_test.to_csv('spam/spam_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('toxic/train.csv')\n",
    "df_test = pd.read_csv('toxic/test.csv')\n",
    "test_labels = pd.read_csv('toxic/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add wanted labels from class\n",
    "df_test[\"toxic\"] = test_labels.toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# filter only labelled test data\n",
    "df_test = df_test[df_test.toxic != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>Thank you for understanding. I think very high...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>:Dear god this site is horrible.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>\"::: Somebody will invariably try to add Relig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>\" \\n\\n It says it right there that it IS a typ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>\" \\n\\n == Before adding a new product to the l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  toxic\n",
       "5   0001ea8717f6de06  Thank you for understanding. I think very high...      0\n",
       "7   000247e83dcc1211                   :Dear god this site is horrible.      0\n",
       "11  0002f87b16116a7f  \"::: Somebody will invariably try to add Relig...      0\n",
       "13  0003e1cccfd5a40a  \" \\n\\n It says it right there that it IS a typ...      0\n",
       "14  00059ace3e3e9a53  \" \\n\\n == Before adding a new product to the l...      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# take only wanted columns and change their names\n",
    "df_train_toxic = df_train[[\"comment_text\", \"toxic\"]]\n",
    "df_train_toxic.columns = ['content', 'label']\n",
    "\n",
    "df_test_toxic = df_test[[\"comment_text\", \"toxic\"]]\n",
    "df_test_toxic.columns = ['content', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save\n",
    "df_train_toxic.to_csv('toxic/toxic_train.csv', index=False)\n",
    "df_test_toxic.to_csv('toxic/toxic_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = 'pubmed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "orig_df = pd.read_csv(path + 'pubmed_review_case.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = orig_df[['article_abstract', 'is_review']]\n",
    "df.columns = ['content', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lens = df.content.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2480153"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lens < 180).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3203404\n",
      "2480153\n"
     ]
    }
   ],
   "source": [
    "# filter lengths\n",
    "print(len(df))\n",
    "df_filter = df[df.content.apply(lambda x: len(x.split())) < 180]\n",
    "print(len(df_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In this review, we analyze data pertinent to t...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A new method of eliminating the exocrine funct...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The left ear of a 57-year-old female who suffe...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Takayasu's disease is a nonspecific arteritis ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lipids and sphingomyelinase activity were stud...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  label\n",
       "0  In this review, we analyze data pertinent to t...   True\n",
       "1  A new method of eliminating the exocrine funct...  False\n",
       "2  The left ear of a 57-year-old female who suffe...  False\n",
       "3  Takayasu's disease is a nonspecific arteritis ...  False\n",
       "4  Lipids and sphingomyelinase activity were stud...  False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train-test split\n",
    "df_filter = df_filter.sample(frac=1., random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_filter.iloc[:int(0.5*len(df_filter))].to_csv(path+'/pubmed_train.csv', index=False)\n",
    "df_filter.iloc[int(0.5*len(df_filter)):].to_csv(path+'/pubmed_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### pre process the strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "base_path = 'toxic/toxic'\n",
    "dataset = 'test'\n",
    "in_path = base_path + '_' + dataset + '.csv'\n",
    "out_path = base_path + '_' + dataset + '_clean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(in_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### drop nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### filter html markings & replace special utf-8 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def replace_special_chars(s):\n",
    "    map_dict = {'’':\"'\", '…':'...', \"–\":'-', '“':'\"', '—':'-', \"‘\":\"'\", '”':'\"', \"&amp;\":\"&\", \"&gt;\":'', '&lt;':'', '\\n':' ', '<br /><br />':' '}\n",
    "    for key in map_dict:\n",
    "        s = s.replace(key, map_dict[key])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['content'] = df.content.apply(replace_special_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### add white space around punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def space_punctuation(s):\n",
    "    s = re.sub(r'([0-9a-zA-Z])(\\')([a-zA-Z])', r'\\1____\\3', s)  # save midword apostrephes\n",
    "    s = re.sub(r'([a-zA-Z])(\\.)([a-zA-Z])', r'\\1~~~~\\3', s)  # save midword .\n",
    "    # space around punctuation\n",
    "    s = re.sub(r'([a-zA-Z])([.,!?#*()/\\[\\];:\"“”\\-\\'])', r'\\1 \\2', s)\n",
    "    s = re.sub(r'([.,!?#*()/\\[\\];:\"“”\\-\\'])([a-zA-Z])', r'\\1 \\2', s)\n",
    "\n",
    "    s = re.sub(r'____', \"'\", s)  # return apostrhephes\n",
    "    s = re.sub(r'~~~~', \".\", s)  # return .\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.content = df.content.apply(space_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# special case to surround \"=\"+ with spaces even if it is joined to text\n",
    "df.content = df.content.apply(lambda x: re.sub(r'(=)+', ' \\\\1 ', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### make text lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.content = df.content.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### remove extra white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.content = df.content.apply(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### filter extremely long sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# if not one can get indexing errors when training BERT model\n",
    "lens = df.content.apply(lambda x: len(x.split()))\n",
    "df = df[(lens<250)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### save csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "':: decided not to use full name on the wikipedia , and removed it from the signature above .'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample().iloc[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### train BERT model & inference on test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "this is in a seperate notebook (depends if training transfer BERT or end2end BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a sample based on sentence length and model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'aclImdb/imdb'\n",
    "test_path = base_path + '_test_pred_lstm.csv'\n",
    "out_path = base_path + '_sample_lstm.csv'\n",
    "max_sent_len = 150\n",
    "min_sent_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter by length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = df.content.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  42.,  517., 1071., 1006., 1618., 3438., 2952., 2247., 1616.,\n",
       "         319.]),\n",
       " array([  8.,  32.,  56.,  80., 104., 128., 152., 176., 200., 224., 248.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('num examples: ', 7552)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'num examples: ', sum((min_sent_len<=lens)&(lens<=max_sent_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[(min_sent_len<=lens)&(lens<=max_sent_len)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter by tp,fp, etc. wanted distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3618, 516, 3106, 312)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = df_filtered[(df_filtered.label == 1) & (df_filtered.preds == 1)]\n",
    "fp = df_filtered[(df_filtered.label == 0) & (df_filtered.preds == 1)]\n",
    "tn = df_filtered[(df_filtered.label == 0) & (df_filtered.preds == 0)]\n",
    "fn = df_filtered[(df_filtered.label == 1) & (df_filtered.preds == 0)]\n",
    "len(tp), len(fp), len(tn), len(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = df_filtered[(df_filtered.label == 1) & (df_filtered.preds == 1)].sample(125, random_state=42)\n",
    "fp = df_filtered[(df_filtered.label == 0) & (df_filtered.preds == 1)].sample(125, random_state=42)\n",
    "tn = df_filtered[(df_filtered.label == 0) & (df_filtered.preds == 0)].sample(125, random_state=42)\n",
    "fn = df_filtered[(df_filtered.label == 1) & (df_filtered.preds == 0)].sample(125, random_state=42)\n",
    "df_final = pd.concat([tp, fp, tn, fn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([tp, fp, tn, fn])\n",
    "# df_final = pd.concat([tp, tn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7552"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what more can you ask for ? a great screenplay based on one of the finest plays of the latter half of the 20th century , two fine emotional performances by courtney and finney , a realistic vision of war time london , a great supporting cast . this film takes you on an emotional rollercoaster through humour , sadness , loss and fulfillment . if you are in the theatre it is even more effective . this is a true 10 on the rating scale !'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.sample().iloc[0].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "de-duplicate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final) - df_final.content.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop_duplicates('content', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final) - df_final.content.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len mean:  111.46981031258349\n",
      "len std:  32.299696041079265\n",
      "len median:  123.0\n",
      "len min:  20\n",
      "len max:  150\n",
      "accuracy:  0.8982099919850387\n"
     ]
    }
   ],
   "source": [
    "filtered_lens = df_final.content.apply(lambda x: len(x.split()))\n",
    "print('len mean: ', filtered_lens.mean())\n",
    "print('len std: ', filtered_lens.std())\n",
    "print('len median: ', filtered_lens.median())\n",
    "print('len min: ', filtered_lens.min())\n",
    "print('len max: ', filtered_lens.max())\n",
    "print('accuracy: ',(len(tp) + len(tn))/len(df_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make train test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" = why am i not allowed to removed my ( defam...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>= milena &amp; doah ? we dating or what ? = truth ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>: i agree obviously an idiot looks at the pric...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>= hey white fuking christian ashole = this mot...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\" : don't look at the sun . it's not daring it...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  label  preds\n",
       "0  \" = why am i not allowed to removed my ( defam...      1      1\n",
       "1  = milena & doah ? we dating or what ? = truth ...      1      1\n",
       "2  : i agree obviously an idiot looks at the pric...      1      1\n",
       "3  = hey white fuking christian ashole = this mot...      1      1\n",
       "4  \" : don't look at the sun . it's not daring it...      1      1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(668, 12754)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = df_filtered[(df_filtered.label == 1) & (df_filtered.preds == 1)]\n",
    "tn = df_filtered[(df_filtered.label == 0) & (df_filtered.preds == 0)]\n",
    "len(tp), len(tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp_train = tp[~tp.content.isin(df_test.content)]\n",
    "# or \n",
    "tn_train = tn[~tn.content.isin(df_test.content)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12629, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp_train_final = tp_train.sample(1000, random_state=3)\n",
    "tn_train_final = tn_train.sample(12500, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tn_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_out_path = base_path + '_train_sample.csv'\n",
    "tn_train_final.to_csv(train_out_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gallilm",
   "language": "python",
   "name": "gallilm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
