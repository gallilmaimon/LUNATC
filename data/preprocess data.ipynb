{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### standardise data format & split train-test if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part shows how to take the raw datasets and transform them to a standard required format, namely only 2 columns with given names, same label format etc. You can use these examples (as well as extra datasets here) to learn how to prepare any new datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = 'train'  # run for 'train' and then \n",
    "out_path = 'aclImdb/'\n",
    "path = 'aclImdb/' + train + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cur_path = path+'pos'\n",
    "directory = os.fsencode(cur_path)\n",
    "\n",
    "txt_lst = []\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if not filename.endswith(\".txt\"): \n",
    "        print(filename + ' - not .txt')\n",
    "        continue\n",
    "    else:\n",
    "        with open(os.path.join(cur_path, filename), 'r', encoding='utf-8') as f:\n",
    "            txt_lst.append(f.read().replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pos = pd.DataFrame(txt_lst, columns=['content'])\n",
    "pos['label'] = np.ones((len(pos), 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 2)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lens = pos.content.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7218"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lens < 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pos = pos[lens < 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cur_path = path+'neg'\n",
    "directory = os.fsencode(cur_path)\n",
    "\n",
    "txt_lst = []\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if not filename.endswith(\".txt\"): \n",
    "        print(filename + ' - not .txt')\n",
    "        continue\n",
    "    else:\n",
    "        with open(os.path.join(cur_path, filename), 'r', encoding='utf-8') as f:\n",
    "            txt_lst.append(f.read().replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "neg = pd.DataFrame(txt_lst, columns=['content'])\n",
    "neg['label'] = np.zeros((len(neg), 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lens = neg.content.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7362"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lens < 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "neg = neg[lens < 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([pos,neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes it was a little low budget, but this movie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I really liked this movie I saw the original c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I appreciated the photography, the textures, t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>...intimate and specific. Yes, a bit of a cind...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A classic cartoon, always enjoyable and funny....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  label\n",
       "0   Yes it was a little low budget, but this movie...      1\n",
       "1   I really liked this movie I saw the original c...      1\n",
       "2   I appreciated the photography, the textures, t...      1\n",
       "8   ...intimate and specific. Yes, a bit of a cind...      1\n",
       "13  A classic cartoon, always enjoyable and funny....      1"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.label.astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(out_path + 'imdb_' + train + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### click-bait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_data = pd.read_json('clickbait/instances.jsonl', lines=True)\n",
    "df_target = pd.read_json('clickbait/truth.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19538"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mrege both dataframes\n",
    "df = df_data.merge(df_target, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>postMedia</th>\n",
       "      <th>postText</th>\n",
       "      <th>postTimestamp</th>\n",
       "      <th>targetCaptions</th>\n",
       "      <th>targetDescription</th>\n",
       "      <th>targetKeywords</th>\n",
       "      <th>targetParagraphs</th>\n",
       "      <th>targetTitle</th>\n",
       "      <th>truthClass</th>\n",
       "      <th>truthJudgments</th>\n",
       "      <th>truthMean</th>\n",
       "      <th>truthMedian</th>\n",
       "      <th>truthMode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>858462320779026432</td>\n",
       "      <td>[]</td>\n",
       "      <td>[UK’s response to modern slavery leaving victi...</td>\n",
       "      <td>Sat Apr 29 23:25:41 +0000 2017</td>\n",
       "      <td>[modern-slavery-rex.jpg]</td>\n",
       "      <td>“Inexcusable” failures in the UK’s system for ...</td>\n",
       "      <td>modern slavery, Department For Work And Pensio...</td>\n",
       "      <td>[Thousands of modern slavery victims have not ...</td>\n",
       "      <td>‘Inexcusable’ failures in UK’s response to mod...</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>[0.33333333330000003, 0.0, 0.33333333330000003...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>858421020331560960</td>\n",
       "      <td>[]</td>\n",
       "      <td>[this is good]</td>\n",
       "      <td>Sat Apr 29 20:41:34 +0000 2017</td>\n",
       "      <td>[In this July 1, 2010 file photo, Dr. Charmain...</td>\n",
       "      <td>President Donald Trump has appointed pro-life ...</td>\n",
       "      <td>Americans United for Life, Dr. Charmaine Yoest...</td>\n",
       "      <td>[President Donald Trump has appointed the pro-...</td>\n",
       "      <td>Donald Trump Appoints Pro-Life Advocate as Ass...</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>858368123753435136</td>\n",
       "      <td>[]</td>\n",
       "      <td>[The \"forgotten\" Trump roast: Relive his bruta...</td>\n",
       "      <td>Sat Apr 29 17:11:23 +0000 2017</td>\n",
       "      <td>[President Trump will not attend this year's W...</td>\n",
       "      <td>President Trump won't be at this year's White ...</td>\n",
       "      <td>trump whcd, whcd, white house correspondents d...</td>\n",
       "      <td>[When the White House correspondents’ dinner i...</td>\n",
       "      <td>The ‘forgotten’ Trump roast: Relive his brutal...</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>[0.33333333330000003, 1.0, 0.33333333330000003...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>858323428260139008</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Meet the happiest #dog in the world!]</td>\n",
       "      <td>Sat Apr 29 14:13:46 +0000 2017</td>\n",
       "      <td>[Maru , Maru, Maru, Maru, Maru]</td>\n",
       "      <td>The article is about Maru, a husky dog who has...</td>\n",
       "      <td>Maru, husky, dogs, pandas, furball, instagram</td>\n",
       "      <td>[Adorable is probably an understatement. This ...</td>\n",
       "      <td>Meet The Happiest Dog In The World, Maru The H...</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>[1.0, 0.6666666666000001, 1.0, 1.0, 1.0]</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>858283602626347008</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Tokyo's subway is shut down amid fears over a...</td>\n",
       "      <td>Sat Apr 29 11:35:31 +0000 2017</td>\n",
       "      <td>[All nine lines of Tokyo's subway system were ...</td>\n",
       "      <td>The temporary suspension, which lasted ten min...</td>\n",
       "      <td>Tokyo,subway,shut,fears,North,Korean,attack</td>\n",
       "      <td>[One of Tokyo's major subways systems says it ...</td>\n",
       "      <td>Tokyo's subway is shut down amid fears over an...</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id postMedia  \\\n",
       "0  858462320779026432        []   \n",
       "1  858421020331560960        []   \n",
       "2  858368123753435136        []   \n",
       "3  858323428260139008        []   \n",
       "4  858283602626347008        []   \n",
       "\n",
       "                                            postText  \\\n",
       "0  [UK’s response to modern slavery leaving victi...   \n",
       "1                                     [this is good]   \n",
       "2  [The \"forgotten\" Trump roast: Relive his bruta...   \n",
       "3             [Meet the happiest #dog in the world!]   \n",
       "4  [Tokyo's subway is shut down amid fears over a...   \n",
       "\n",
       "                    postTimestamp  \\\n",
       "0  Sat Apr 29 23:25:41 +0000 2017   \n",
       "1  Sat Apr 29 20:41:34 +0000 2017   \n",
       "2  Sat Apr 29 17:11:23 +0000 2017   \n",
       "3  Sat Apr 29 14:13:46 +0000 2017   \n",
       "4  Sat Apr 29 11:35:31 +0000 2017   \n",
       "\n",
       "                                      targetCaptions  \\\n",
       "0                           [modern-slavery-rex.jpg]   \n",
       "1  [In this July 1, 2010 file photo, Dr. Charmain...   \n",
       "2  [President Trump will not attend this year's W...   \n",
       "3                    [Maru , Maru, Maru, Maru, Maru]   \n",
       "4  [All nine lines of Tokyo's subway system were ...   \n",
       "\n",
       "                                   targetDescription  \\\n",
       "0  “Inexcusable” failures in the UK’s system for ...   \n",
       "1  President Donald Trump has appointed pro-life ...   \n",
       "2  President Trump won't be at this year's White ...   \n",
       "3  The article is about Maru, a husky dog who has...   \n",
       "4  The temporary suspension, which lasted ten min...   \n",
       "\n",
       "                                      targetKeywords  \\\n",
       "0  modern slavery, Department For Work And Pensio...   \n",
       "1  Americans United for Life, Dr. Charmaine Yoest...   \n",
       "2  trump whcd, whcd, white house correspondents d...   \n",
       "3      Maru, husky, dogs, pandas, furball, instagram   \n",
       "4        Tokyo,subway,shut,fears,North,Korean,attack   \n",
       "\n",
       "                                    targetParagraphs  \\\n",
       "0  [Thousands of modern slavery victims have not ...   \n",
       "1  [President Donald Trump has appointed the pro-...   \n",
       "2  [When the White House correspondents’ dinner i...   \n",
       "3  [Adorable is probably an understatement. This ...   \n",
       "4  [One of Tokyo's major subways systems says it ...   \n",
       "\n",
       "                                         targetTitle    truthClass  \\\n",
       "0  ‘Inexcusable’ failures in UK’s response to mod...  no-clickbait   \n",
       "1  Donald Trump Appoints Pro-Life Advocate as Ass...     clickbait   \n",
       "2  The ‘forgotten’ Trump roast: Relive his brutal...  no-clickbait   \n",
       "3  Meet The Happiest Dog In The World, Maru The H...     clickbait   \n",
       "4  Tokyo's subway is shut down amid fears over an...  no-clickbait   \n",
       "\n",
       "                                      truthJudgments  truthMean  truthMedian  \\\n",
       "0  [0.33333333330000003, 0.0, 0.33333333330000003...   0.133333     0.000000   \n",
       "1                          [1.0, 1.0, 1.0, 1.0, 1.0]   1.000000     1.000000   \n",
       "2  [0.33333333330000003, 1.0, 0.33333333330000003...   0.466667     0.333333   \n",
       "3           [1.0, 0.6666666666000001, 1.0, 1.0, 1.0]   0.933333     1.000000   \n",
       "4                          [0.0, 0.0, 0.0, 0.0, 0.0]   0.000000     0.000000   \n",
       "\n",
       "   truthMode  \n",
       "0   0.000000  \n",
       "1   1.000000  \n",
       "2   0.333333  \n",
       "3   1.000000  \n",
       "4   0.000000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/conda_envs/thesis/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[['postText','truthClass']]  # take only wanted columns\n",
    "filtered_df.truthClass = (filtered_df.truthClass == 'clickbait')  # binarise classes\n",
    "filtered_df.columns = ['content', 'label']  # change column names\n",
    "filtered_df.label = filtered_df.label.astype(int)  # make zero 1 for similarity to the others\n",
    "filtered_df.content = filtered_df.content.apply(lambda x: x[0])  # take string and not list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK’s response to modern slavery leaving victim...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The \"forgotten\" Trump roast: Relive his brutal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meet the happiest #dog in the world!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tokyo's subway is shut down amid fears over an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  label\n",
       "0  UK’s response to modern slavery leaving victim...      0\n",
       "1                                       this is good      1\n",
       "2  The \"forgotten\" Trump roast: Relive his brutal...      0\n",
       "3               Meet the happiest #dog in the world!      1\n",
       "4  Tokyo's subway is shut down amid fears over an...      0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "df_click_train, df_click_test = train_test_split(filtered_df, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save files\n",
    "df_click_train.to_csv('clickbait/clickbait_train.csv', index=False)\n",
    "df_click_test.to_csv('clickbait/clickbait_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam/SPAM text message 20170820 - Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.Category = (df.Category == 'spam').astype(int)\n",
    "df.columns = ['label', 'content']\n",
    "df = df[['content', 'label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_spam_train, df_spam_test = train_test_split(df, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_spam_train.to_csv('spam/spam_train.csv', index=False)\n",
    "df_spam_test.to_csv('spam/spam_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('toxic/train.csv')\n",
    "df_test = pd.read_csv('toxic/test.csv')\n",
    "test_labels = pd.read_csv('toxic/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add wanted labels from class\n",
    "df_test[\"toxic\"] = test_labels.toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# filter only labelled test data\n",
    "df_test = df_test[df_test.toxic != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>Thank you for understanding. I think very high...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>:Dear god this site is horrible.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>\"::: Somebody will invariably try to add Relig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>\" \\n\\n It says it right there that it IS a typ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>\" \\n\\n == Before adding a new product to the l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  toxic\n",
       "5   0001ea8717f6de06  Thank you for understanding. I think very high...      0\n",
       "7   000247e83dcc1211                   :Dear god this site is horrible.      0\n",
       "11  0002f87b16116a7f  \"::: Somebody will invariably try to add Relig...      0\n",
       "13  0003e1cccfd5a40a  \" \\n\\n It says it right there that it IS a typ...      0\n",
       "14  00059ace3e3e9a53  \" \\n\\n == Before adding a new product to the l...      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# take only wanted columns and change their names\n",
    "df_train_toxic = df_train[[\"comment_text\", \"toxic\"]]\n",
    "df_train_toxic.columns = ['content', 'label']\n",
    "\n",
    "df_test_toxic = df_test[[\"comment_text\", \"toxic\"]]\n",
    "df_test_toxic.columns = ['content', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save\n",
    "df_train_toxic.to_csv('toxic/toxic_train.csv', index=False)\n",
    "df_test_toxic.to_csv('toxic/toxic_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = 'pubmed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "orig_df = pd.read_csv(path + 'pubmed_review_case.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/pandas/core/generic.py:5168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "df = orig_df[['article_abstract', 'is_review']]\n",
    "df.columns = ['content', 'label']\n",
    "df.label = df.label.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lens = df.content.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2480153"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lens < 180).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3203404\n",
      "2480153\n"
     ]
    }
   ],
   "source": [
    "# filter lengths\n",
    "print(len(df))\n",
    "df_filter = df[df.content.apply(lambda x: len(x.split())) < 180]\n",
    "print(len(df_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In this review, we analyze data pertinent to t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A new method of eliminating the exocrine funct...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The left ear of a 57-year-old female who suffe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Takayasu's disease is a nonspecific arteritis ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lipids and sphingomyelinase activity were stud...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  label\n",
       "0  In this review, we analyze data pertinent to t...      1\n",
       "1  A new method of eliminating the exocrine funct...      0\n",
       "2  The left ear of a 57-year-old female who suffe...      0\n",
       "3  Takayasu's disease is a nonspecific arteritis ...      0\n",
       "4  Lipids and sphingomyelinase activity were stud...      0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train-test split\n",
    "df_filter = df_filter.sample(frac=1., random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_filter.iloc[:int(0.5*len(df_filter))].to_csv(path+'/pubmed_train.csv', index=False)\n",
    "df_filter.iloc[int(0.5*len(df_filter)):].to_csv(path+'/pubmed_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../../multinli_1.0/multinli_1.0_'\n",
    "data_paths = [f'{base_path}{f}.txt' for f in ['train', 'dev_matched', 'dev_mismatched']]\n",
    "out_path = 'mnli/mnli_'\n",
    "test_size = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for data_path in data_paths:\n",
    "    # ugly dataframe parsing because of quote errors using regular read method \n",
    "    with open(data_path, 'r') as f:\n",
    "        data = [l.split('\\t') for l in f.readlines()]\n",
    "        df = pd.DataFrame(data[1:], columns=data[0])\n",
    "\n",
    "    df = df[['sentence1', 'sentence2', 'gold_label']]\n",
    "    df.columns = ['content', 'content2', 'label']\n",
    "    dfs.append(df)\n",
    "    \n",
    "total_df = pd.concat(dfs)\n",
    "total_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = total_df[total_df.label != '-']  # remove undecisive labels\n",
    "total_df.label = total_df.label.replace({\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2})  # map labels to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('They were all very disturbed.', \"It didn't disturb them at all.\", 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 18839\n",
    "total_df.iloc[i].content, total_df.iloc[i].content2, total_df.iloc[i].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>content2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Conceptually cream skimming has two basic dime...</td>\n",
       "      <td>Product and geography are what make cream skim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you know during the season and i guess at at y...</td>\n",
       "      <td>You lose the things to the following level if ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One of our number will carry out your instruct...</td>\n",
       "      <td>A member of my team will execute your orders w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do you know? All this is their information...</td>\n",
       "      <td>This information belongs to them.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeah i tell you what though if you go price so...</td>\n",
       "      <td>The tennis shoes have a range of prices.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392344</th>\n",
       "      <td>The volcano's name is thought to derive from a...</td>\n",
       "      <td>The volcano was given its name two hundred yea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392345</th>\n",
       "      <td>The soaring vaults of the sober interior have ...</td>\n",
       "      <td>German Gothic design is know for its soaring v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392346</th>\n",
       "      <td>you know since the women's movement in the wel...</td>\n",
       "      <td>The women's movement solved everything and we ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392347</th>\n",
       "      <td>The increase in one asset is offset by an equa...</td>\n",
       "      <td>.When an asset increases it means there is no ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392348</th>\n",
       "      <td>and uh of course it's a nine hundred number wh...</td>\n",
       "      <td>They're going to charge you when you call the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392349 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  content  \\\n",
       "0       Conceptually cream skimming has two basic dime...   \n",
       "1       you know during the season and i guess at at y...   \n",
       "2       One of our number will carry out your instruct...   \n",
       "3       How do you know? All this is their information...   \n",
       "4       yeah i tell you what though if you go price so...   \n",
       "...                                                   ...   \n",
       "392344  The volcano's name is thought to derive from a...   \n",
       "392345  The soaring vaults of the sober interior have ...   \n",
       "392346  you know since the women's movement in the wel...   \n",
       "392347  The increase in one asset is offset by an equa...   \n",
       "392348  and uh of course it's a nine hundred number wh...   \n",
       "\n",
       "                                                 content2  label  \n",
       "0       Product and geography are what make cream skim...      1  \n",
       "1       You lose the things to the following level if ...      0  \n",
       "2       A member of my team will execute your orders w...      0  \n",
       "3                       This information belongs to them.      0  \n",
       "4                The tennis shoes have a range of prices.      1  \n",
       "...                                                   ...    ...  \n",
       "392344  The volcano was given its name two hundred yea...      1  \n",
       "392345  German Gothic design is know for its soaring v...      0  \n",
       "392346  The women's movement solved everything and we ...      2  \n",
       "392347  .When an asset increases it means there is no ...      2  \n",
       "392348  They're going to charge you when you call the ...      0  \n",
       "\n",
       "[392349 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.iloc[:-test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>content2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>392349</th>\n",
       "      <td>i would i would love to go there i mean like a...</td>\n",
       "      <td>I think I would hate traveling there because i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392350</th>\n",
       "      <td>oh Teenage Mutant Ninja Turtles huh um-hum</td>\n",
       "      <td>The Teenage Mutant Ninja Turtles reboot.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392351</th>\n",
       "      <td>In 1793, when the leaders of the Revolution de...</td>\n",
       "      <td>The leaders of the Revolution declared the pal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392352</th>\n",
       "      <td>She didn't wait long to come here.</td>\n",
       "      <td>She had to wait for three days.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392353</th>\n",
       "      <td>These conferences will enable program staff to...</td>\n",
       "      <td>These conferences enable program staff to exam...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412697</th>\n",
       "      <td>Do you watch that?</td>\n",
       "      <td>Can you see?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412698</th>\n",
       "      <td>To a Western ear, the most predictable of lang...</td>\n",
       "      <td>To the Western ear, the least predictable of l...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412699</th>\n",
       "      <td>The recorder captured the sounds of loud thump...</td>\n",
       "      <td>The recorder didn't capture any of the sounds.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412700</th>\n",
       "      <td>That's a good attitude!</td>\n",
       "      <td>You feel good about this, don't you?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412701</th>\n",
       "      <td>Bloomer (for `flower'), butter (for `ram'), or...</td>\n",
       "      <td>Bloomer is another word for flower, butter is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  content  \\\n",
       "392349  i would i would love to go there i mean like a...   \n",
       "392350         oh Teenage Mutant Ninja Turtles huh um-hum   \n",
       "392351  In 1793, when the leaders of the Revolution de...   \n",
       "392352                 She didn't wait long to come here.   \n",
       "392353  These conferences will enable program staff to...   \n",
       "...                                                   ...   \n",
       "412697                                 Do you watch that?   \n",
       "412698  To a Western ear, the most predictable of lang...   \n",
       "412699  The recorder captured the sounds of loud thump...   \n",
       "412700                            That's a good attitude!   \n",
       "412701  Bloomer (for `flower'), butter (for `ram'), or...   \n",
       "\n",
       "                                                 content2  label  \n",
       "392349  I think I would hate traveling there because i...      2  \n",
       "392350           The Teenage Mutant Ninja Turtles reboot.      1  \n",
       "392351  The leaders of the Revolution declared the pal...      0  \n",
       "392352                    She had to wait for three days.      2  \n",
       "392353  These conferences enable program staff to exam...      1  \n",
       "...                                                   ...    ...  \n",
       "412697                                       Can you see?      2  \n",
       "412698  To the Western ear, the least predictable of l...      2  \n",
       "412699     The recorder didn't capture any of the sounds.      2  \n",
       "412700              You feel good about this, don't you?       1  \n",
       "412701  Bloomer is another word for flower, butter is ...      0  \n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.iloc[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.iloc[:-test_size].to_csv(out_path + 'train.csv', index=False)\n",
    "total_df.iloc[-test_size:].to_csv(out_path + 'test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### pre process the strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part shows how to pre-proccess the strings by removing special characters, standarising spacing, making lowercase and such. Run this on all datasets you wish to use (train and test)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "base_path = 'toxic/toxic'\n",
    "dataset = 'test'  # run also on 'train' and also on 'test'\n",
    "in_path = base_path + '_' + dataset + '.csv'\n",
    "out_path = base_path + '_' + dataset + '_clean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(in_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### drop nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### filter html markings & replace special utf-8 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def replace_special_chars(s):\n",
    "    map_dict = {'’':\"'\", '…':'...', \"–\":'-', '“':'\"', '—':'-', \"‘\":\"'\", '”':'\"', \"&amp;\":\"&\", \"&gt;\":'', '&lt;':'', '\\n':' ', '<br /><br />':' '}\n",
    "    for key in map_dict:\n",
    "        s = s.replace(key, map_dict[key])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['content'] = df.content.apply(replace_special_chars)\n",
    "if 'content2' in df.columns:\n",
    "    df['content2'] = df.content2.apply(replace_special_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### add white space around punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def space_punctuation(s):\n",
    "    s = re.sub(r'([0-9a-zA-Z])(\\')([a-zA-Z])', r'\\1____\\3', s)  # save midword apostrephes\n",
    "    s = re.sub(r'([a-zA-Z])(\\.)([a-zA-Z])', r'\\1~~~~\\3', s)  # save midword .\n",
    "    # space around punctuation\n",
    "    s = re.sub(r'([a-zA-Z])([.,!?#*()/\\[\\];:\"“”\\-\\'])', r'\\1 \\2', s)\n",
    "    s = re.sub(r'([.,!?#*()/\\[\\];:\"“”\\-\\'])([a-zA-Z])', r'\\1 \\2', s)\n",
    "\n",
    "    s = re.sub(r'____', \"'\", s)  # return apostrhephes\n",
    "    s = re.sub(r'~~~~', \".\", s)  # return .\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.content = df.content.apply(space_punctuation)\n",
    "if 'content2' in df.columns:\n",
    "    df.content2 = df.content2.apply(space_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# special case to surround \"=\"+ with spaces even if it is joined to text\n",
    "df.content = df.content.apply(lambda x: re.sub(r'(=)+', ' \\\\1 ', x))\n",
    "if 'content2' in df.columns:\n",
    "    df.content2 = df.content2.apply(lambda x: re.sub(r'(=)+', ' \\\\1 ', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### make text lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.content = df.content.apply(lambda x: x.lower())\n",
    "if 'content2' in df.columns:\n",
    "    df.content2 = df.content2.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### remove extra white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.content = df.content.apply(lambda x: ' '.join(x.split()))\n",
    "if 'content2' in df.columns:\n",
    "    df.content2 = df.content2.apply(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### filter extremely long sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# if not done, one can get indexing errors when training BERT model\n",
    "lens = df.content.apply(lambda x: len(x.split()))\n",
    "df = df[(lens<250)]\n",
    "if 'content2' in df.columns:\n",
    "    lens = df.content2.apply(lambda x: len(x.split()))\n",
    "    df = df[(lens<250)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df.content.eq(''))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### save csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fowler is such a hypocrite . he opposes having anything about foreign relations on the india page as shown above , but supports it on the pakistan page . what bs ?'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample().iloc[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### train prediction model & inference on test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "this is in a seperate script (depends if training BERT, word-LSTM, XLNet or other models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a sample based on sentence length and model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'pubmed/pubmed'\n",
    "model_name = 'lstm'\n",
    "test_path = base_path + f'_test_pred_{model_name}.csv'\n",
    "out_path = base_path + f'_sample_{model_name}.csv'\n",
    "max_sent_len = 150\n",
    "min_sent_len = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter by length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = df.content.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 49747., 129917., 172497., 179126., 190214., 180119., 170800.,\n",
       "        132635.,  33851.,   1102.]),\n",
       " array([  1. ,  25.8,  50.6,  75.4, 100.2, 125. , 149.8, 174.6, 199.4,\n",
       "        224.2, 249. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('num examples: ', 896588)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'num examples: ', sum((min_sent_len<=lens)&(lens<=max_sent_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[(min_sent_len<=lens)&(lens<=max_sent_len)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter by tp,fp, etc. wanted distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary case\n",
    "if df_filtered.label.max() == 1:\n",
    "    tp = df_filtered[(df_filtered.label == 1) & (df_filtered.preds == 1)]\n",
    "    fp = df_filtered[(df_filtered.label == 0) & (df_filtered.preds == 1)]\n",
    "    tn = df_filtered[(df_filtered.label == 0) & (df_filtered.preds == 0)]\n",
    "    fn = df_filtered[(df_filtered.label == 1) & (df_filtered.preds == 0)]\n",
    "    df_final = pd.concat([tp, fp, tn, fn])\n",
    "else:  # multiclass case, corrctly classifed only, as they are more interesting to attack\n",
    "    all_df = []\n",
    "    for i in range(df_filtered.label.max()):\n",
    "        all_df.append(df_filtered[(df_filtered.label == i) & (df_filtered.preds == i)])\n",
    "        df_final = pd.concat(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "896588"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positional therapy appears to be an attractive strategy for many patients with positional obstructive sleep apnea ( osa ). however , under the american academy of sleep medicine osa guidelines , positional therapy is considered as only an alternative therapy , because previous research has demonstrated poor treatment tolerance and adherence . recent technological advances have renewed interest in positional therapy , with the invention of new sophisticated vibratory positional therapy devices . these devices have shown great promise with efficacy , markedly improved patient tolerance , and long - term adherence . we review the literature on positional therapy and explore the most current evidence on the new positional therapy devices .'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.sample().iloc[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>approximately 54 million people around the wor...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it has become mandatory for the application fo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>diabetes in pregnancy has been shown to induce...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>endogenous cardiac glycoside inhibitors of the...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cell culture technology has spread prolificall...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  label  preds\n",
       "1   approximately 54 million people around the wor...      1      1\n",
       "9   it has become mandatory for the application fo...      1      1\n",
       "14  diabetes in pregnancy has been shown to induce...      1      1\n",
       "16  endogenous cardiac glycoside inhibitors of the...      1      1\n",
       "17  cell culture technology has spread prolificall...      1      1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "de-duplicate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop_duplicates('content', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len mean:  88.72977665914418\n",
      "len std:  36.654601550083974\n",
      "len median:  91.0\n",
      "len min:  15\n",
      "len max:  150\n"
     ]
    }
   ],
   "source": [
    "filtered_lens = df_final.content.apply(lambda x: len(x.split()))\n",
    "print('len mean: ', filtered_lens.mean())\n",
    "print('len std: ', filtered_lens.std())\n",
    "print('len median: ', filtered_lens.median())\n",
    "print('len min: ', filtered_lens.min())\n",
    "print('len max: ', filtered_lens.max())\n",
    "# print('accuracy: ',(len(tp) + len(tn))/len(df_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select indices for universal attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in the paper, the focus of the universal attacks is on samples in which an attack is known to exist in the search space. We therefore perform different attacks - textfooler, PWWS, basic-search, and then use only the indices in which an attack was found as part of the train and test datasets for the universal approaches.\n",
    "\n",
    "First, perform the different attacks as explained in the readme. Afterwards, use this part of the notebook to calculate the indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "data_path = 'aclImdb/imdb'\n",
    "model_type = 'bert'\n",
    "selected_class = 1\n",
    "train_size = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textfooler\n",
    "df_tf = pd.read_csv(f'{data_path}_tf_{model_type}.csv')\n",
    "suc_tf = np.where((df_tf.max_score > 0.1) & (df_tf.preds == selected_class) & (df_tf.label == selected_class))[0]\n",
    "\n",
    "# PWWS\n",
    "df_pwws = pd.read_csv(f'{data_path}_pwws_{model_type}.csv')\n",
    "suc_pwws = np.where((df_pwws.max_score > 0.1) & (df_pwws.preds == selected_class) & (df_pwws.label == selected_class))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Search\n",
    "suc_search = []\n",
    "for i in np.where((df_tf.preds == selected_class) & (df_tf.label == selected_class))[0]:\n",
    "    try:\n",
    "        df = pd.read_csv(f'{data_path}_dqn_results/{i}.csv')\n",
    "        if df.score.max() > 10:\n",
    "            suc_search.append(i)\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train indices are only from textfooler attack as explained in the paper\n",
    "train_inds = set(suc_tf[:train_size])\n",
    "\n",
    "# test indices are all other indices with succesful attack\n",
    "test_inds = (set(suc_tf[train_size:]) | set(suc_pwws) | set(suc_search)) - train_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 1129, train_size: 750, test_size: 379\n"
     ]
    }
   ],
   "source": [
    "print(f'total samples: {len(train_inds | test_inds)}, train_size: {len(train_inds)}, test_size: {len(test_inds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we calculated the indices we print them as string so that they can be copied to the appropriate yml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0, 1, 3, 10, 11, 16, 20, 34, 57, 59, 71, 73, 76, 88, 90, 108, 117, 119, 121, 125, 131, 132, 134, 137, 141, 145, 147, 154, 159, 164, 168, 174, 181, 183, 186, 192, 194, 203, 206, 210, 212, 214, 215, 227, 228, 229, 235, 236, 242, 243, 244, 259, 269, 275, 279, 284, 292, 293, 300, 306, 314, 320, 322, 331, 340, 346, 350, 351, 354, 357, 361, 368, 373, 375, 377, 385, 388, 389, 394, 404, 405, 408, 411, 418, 423, 429, 432, 433, 445, 451, 452, 453, 486, 492, 495, 499, 505, 506, 508, 511, 512, 513, 528, 529, 531, 532, 539, 543, 548, 552, 554, 555, 559, 560, 564, 567, 579, 585, 592, 595, 601, 613, 616, 623, 624, 629, 630, 633, 637, 638, 644, 645, 646, 647, 658, 664, 666, 672, 675, 680, 687, 688, 709, 710, 716, 718, 719, 721, 726, 727, 729, 730, 734, 750, 752, 754, 755, 756, 769, 777, 787, 791, 798, 803, 806, 811, 819, 822, 831, 835, 836, 843, 845, 855, 858, 859, 863, 866, 872, 873, 878, 892, 898, 900, 904, 906, 911, 917, 932, 938, 943, 953, 956, 962, 966, 968, 973, 981, 988, 991, 993, 994, 995, 998, 1013, 1016, 1020, 1021, 1023, 1027, 1028, 1030, 1033, 1034, 1041, 1043, 1044, 1046, 1052, 1064, 1066, 1067, 1071, 1074, 1078, 1082, 1089, 1097, 1100, 1104, 1107, 1108, 1110, 1113, 1114, 1123, 1125, 1126, 1127, 1135, 1137, 1144, 1155, 1156, 1160, 1165, 1166, 1168, 1170, 1171, 1172, 1178, 1180, 1181, 1184, 1192, 1198, 1201, 1202, 1204, 1205, 1206, 1211, 1215, 1216, 1217, 1218, 1220, 1231, 1238, 1245, 1249, 1260, 1262, 1266, 1268, 1273, 1275, 1276, 1280, 1284, 1285, 1295, 1304, 1306, 1308, 1309, 1314, 1315, 1317, 1321, 1322, 1326, 1333, 1341, 1344, 1349, 1350, 1356, 1357, 1364, 1366, 1367, 1368, 1370, 1373, 1383, 1385, 1391, 1402, 1403, 1418, 1419, 1421, 1431, 1436, 1438, 1439, 1448, 1450, 1456, 1459, 1478, 1480, 1485, 1486, 1494, 1498, 1499, 1501, 1503, 1512, 1526, 1530, 1533, 1535, 1539, 1542, 1548, 1550, 1552, 1554, 1557, 1558, 1565, 1581, 1582, 1584, 1593, 1596, 1599, 1605, 1607, 1609, 1612, 1627, 1629, 1634, 1635, 1638, 1641, 1652, 1655, 1661, 1675, 1680, 1681, 1682, 1687, 1689, 1693, 1695, 1697, 1703, 1707, 1709, 1715, 1718, 1719, 1724, 1727, 1728, 1737, 1738, 1741, 1746, 1751, 1754, 1757, 1760, 1766, 1768, 1770, 1778, 1784, 1788, 1795, 1796, 1800, 1804, 1807, 1811, 1816, 1818, 1820, 1824, 1829, 1833, 1834, 1836, 1840, 1841, 1867, 1874, 1877, 1882, 1888, 1891, 1894, 1895, 1903, 1909, 1911, 1916, 1924, 1926, 1928, 1929, 1931, 1933, 1934, 1940, 1944, 1952, 1956, 1958, 1960, 1962, 1965, 1969, 1975, 1979, 1980, 1984, 1988, 1989, 1992, 1994, 1996, 1998, 2004, 2007, 2015, 2016, 2017, 2018, 2026, 2027, 2029, 2034, 2046, 2048, 2050, 2051, 2056, 2058, 2069, 2070, 2073, 2079, 2082, 2083, 2089, 2094, 2095, 2097, 2100, 2102, 2106, 2114, 2115, 2116, 2119, 2124, 2127, 2128, 2133, 2135, 2142, 2143, 2166, 2170, 2173, 2174, 2179, 2180, 2181, 2183, 2187, 2188, 2193, 2199, 2205, 2206, 2210, 2214, 2217, 2218, 2225, 2227, 2230, 2231, 2232, 2235, 2236, 2237, 2240, 2246, 2247, 2252, 2253, 2254, 2262, 2264, 2268, 2279, 2281, 2282, 2288, 2291, 2293, 2296, 2298, 2299, 2300, 2308, 2309, 2318, 2321, 2324, 2333, 2334, 2337, 2347, 2353, 2354, 2361, 2362, 2363, 2368, 2369, 2370, 2371, 2374, 2386, 2392, 2399, 2408, 2412, 2413, 2414, 2415, 2416, 2420, 2422, 2429, 2430, 2440, 2445, 2449, 2454, 2456, 2461, 2467, 2472, 2474, 2478, 2483, 2485, 2491, 2492, 2494, 2498, 2503, 2506, 2510, 2511, 2514, 2521, 2523, 2539, 2543, 2546, 2548, 2549, 2550, 2567, 2570, 2571, 2572, 2573, 2577, 2579, 2582, 2583, 2584, 2585, 2593, 2595, 2597, 2598, 2609, 2613, 2616, 2618, 2619, 2625, 2628, 2629, 2631, 2635, 2637, 2641, 2644, 2646, 2648, 2650, 2651, 2656, 2658, 2660, 2675, 2680, 2682, 2684, 2688, 2689, 2692, 2694, 2698, 2703, 2706, 2712, 2714, 2718, 2719, 2727, 2731, 2732, 2735, 2736, 2740, 2750, 2753, 2755, 2762, 2774, 2789, 2791, 2803, 2804, 2808, 2811, 2813, 2814, 2827, 2828, 2834, 2835, 2836, 2838, 2839, 2841, 2848, 2856, 2858, 2860, 2867, 2872, 2873, 2879, 2881, 2892, 2898, 2904, 2908, 2910, 2912, 2917, 2918, 2932, 2934, 2938, 2939, 2941, 2943, 2946, 2950, 2953, 2955, 2959, 2961, 2963, 2975, 2983, 2984, 2998, 3006, 3010, 3012, 3014, 3032, 3035, 3042, 3050, 3053, 3056, 3058, 3061, 3062, 3079, 3083, 3091, 3105, 3107, 3109, 3113, 3114, 3120, 3126, 3129, 3134, 3135, 3148, 3152, 3156, 3158, 3165, 3173, 3183, 3185, 3188, 3200, 3201, 3216, 3219, 3224, 3227, 3230, 3235'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "', '.join([str(s) for s in sorted(list(train_inds))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8, 13, 17, 35, 83, 103, 111, 129, 182, 184, 189, 221, 232, 237, 255, 264, 297, 328, 336, 338, 345, 356, 363, 430, 435, 436, 472, 473, 474, 477, 488, 489, 493, 521, 527, 537, 549, 589, 608, 610, 634, 642, 656, 669, 723, 740, 743, 761, 766, 768, 786, 794, 805, 812, 813, 832, 844, 861, 887, 889, 923, 961, 963, 982, 986, 992, 1024, 1050, 1068, 1077, 1086, 1090, 1129, 1145, 1158, 1167, 1175, 1226, 1235, 1242, 1261, 1269, 1311, 1318, 1342, 1351, 1363, 1369, 1392, 1430, 1443, 1447, 1454, 1466, 1468, 1473, 1488, 1508, 1509, 1515, 1520, 1604, 1622, 1626, 1630, 1632, 1647, 1663, 1672, 1684, 1698, 1706, 1721, 1731, 1739, 1747, 1769, 1794, 1823, 1825, 1872, 1884, 1900, 1901, 1902, 1917, 1938, 1941, 1948, 1950, 1955, 1967, 1971, 1976, 2005, 2009, 2013, 2038, 2041, 2042, 2045, 2088, 2093, 2098, 2099, 2101, 2108, 2122, 2134, 2145, 2190, 2197, 2198, 2222, 2226, 2238, 2259, 2272, 2283, 2284, 2303, 2310, 2316, 2326, 2346, 2372, 2373, 2375, 2378, 2404, 2410, 2431, 2460, 2469, 2542, 2551, 2558, 2561, 2564, 2568, 2592, 2604, 2611, 2621, 2623, 2626, 2636, 2645, 2665, 2670, 2700, 2713, 2724, 2733, 2752, 2756, 2773, 2819, 2842, 2843, 2852, 2854, 2890, 2891, 2896, 2901, 2906, 2911, 2920, 2921, 2925, 2977, 2989, 2994, 3027, 3031, 3052, 3069, 3086, 3117, 3136, 3151, 3159, 3174, 3180, 3213, 3220, 3225, 3228, 3237, 3243, 3249, 3252, 3260, 3263, 3270, 3283, 3285, 3286, 3288, 3291, 3301, 3302, 3308, 3309, 3311, 3312, 3316, 3323, 3324, 3326, 3329, 3330, 3333, 3335, 3336, 3341, 3343, 3344, 3345, 3351, 3352, 3353, 3355, 3356, 3358, 3359, 3368, 3371, 3373, 3374, 3377, 3378, 3388, 3392, 3394, 3397, 3402, 3403, 3404, 3405, 3406, 3408, 3413, 3421, 3422, 3427, 3429, 3436, 3438, 3440, 3441, 3448, 3451, 3453, 3458, 3462, 3470, 3478, 3485, 3486, 3491, 3492, 3505, 3507, 3511, 3517, 3518, 3522, 3523, 3525, 3527, 3528, 3533, 3536, 3537, 3543, 3544, 3551, 3555, 3560, 3564, 3567, 3572, 3573, 3574, 3584, 3588, 3589, 3590, 3592, 3595, 3596, 3597, 3598, 3601, 3603, 3616, 3617, 3622, 3629, 3636, 3641, 3648, 3649, 3651, 3661, 3666, 3667, 3670, 3672, 3676, 3677, 3679, 3680, 3683, 3686, 3689, 3690, 3691, 3694, 3696, 3702, 3705, 3706, 3708, 3710, 3711, 3712, 3713, 3714, 3715, 3717, 3720, 3724, 3725, 3727, 3733, 3740'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "', '.join([str(s) for s in sorted(list(test_inds))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gallilm2",
   "language": "python",
   "name": "gallilm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
