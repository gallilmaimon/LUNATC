{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_val = 42\n",
    "device = \"cuda:0\"\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/toxic/toxic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path+\"_train_clean.csv\")\n",
    "df_train, df_validation = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(data_path+\"_test_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lists of sentences and their labels.\n",
    "sentences_train = df_train.content.values\n",
    "labels_train = df_train.label.values\n",
    "\n",
    "sentences_validation = df_validation.content.values\n",
    "labels_validation = df_validation.label.values\n",
    "\n",
    "sentences_test = df_test.content.values\n",
    "labels_test = df_test.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tokenising & formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids_train = []\n",
    "\n",
    "# For every sentence in train\n",
    "for sent in sentences_train:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_train.append(encoded_sent)\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids_validation = []\n",
    "\n",
    "# For every sentence in test\n",
    "for sent in sentences_validation:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_validation.append(encoded_sent)\n",
    "    \n",
    "    \n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids_test = []\n",
    "\n",
    "# For every sentence in test\n",
    "for sent in sentences_test:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_test.append(encoded_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(input_ids, maxlen):\n",
    "    padded = []\n",
    "    for inp in input_ids:\n",
    "        if len(inp) >= maxlen:\n",
    "            padded.append(inp[:maxlen-1] + [inp[-1]])\n",
    "        else:\n",
    "            padded.append(inp + [0]*(maxlen - len(inp)))\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### histogram of length for choosing the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-304jl7k3 because the default path (/home/gallil/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens_train = [len(inp) for inp in  input_ids_train]\n",
    "plt.hist(lens_train, bins=1000, range=(0,1000))\n",
    "plt.show()\n",
    "lens_validation = [len(inp) for inp in  input_ids_validation]\n",
    "plt.hist(lens_validation, bins=1000, range=(0,1000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9849530981732972\n"
     ]
    }
   ],
   "source": [
    "print((np.array(lens_train)<=256).sum()/ len(lens_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding/truncating all sentences to 256 values...\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Set the maximum sequence length.\n",
    "MAX_LEN = 256\n",
    "\n",
    "print('Padding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "print('Padding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# Pad our input tokens with value 0.\n",
    "input_ids_train = pad_sequences(input_ids_train, maxlen=MAX_LEN)\n",
    "input_ids_validation = pad_sequences(input_ids_validation, maxlen=MAX_LEN)\n",
    "input_ids_test = pad_sequences(input_ids_test, maxlen=MAX_LEN)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks_train = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids_train:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks_train.append(att_mask)\n",
    "    \n",
    "# Create attention masks\n",
    "attention_masks_validation = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids_validation:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks_validation.append(att_mask)\n",
    "\n",
    "    \n",
    "attention_masks_test = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids_test:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks_test.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename\n",
    "train_inputs, validation_inputs, test_inputs, train_labels, validation_labels, test_labels = input_ids_train, input_ids_validation, input_ids_test, labels_train, labels_validation, labels_test\n",
    "train_masks, validation_masks, test_masks = attention_masks_train, attention_masks_validation, attention_masks_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset & dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all inputs and labels into torch tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "test_masks = torch.tensor(test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([135709, 256])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model & optimiser & scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2,\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 2\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, \n",
    "                                            num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return (pred_flat == labels_flat).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.81\n",
      "  Validation took: 0:01:24\n"
     ]
    }
   ],
   "source": [
    "# evaluation only - to make sure that accuracy is more or less random at the beginnig\n",
    "print(\"\")\n",
    "print(\"Running Validation...\")\n",
    "device = \"cuda\"\n",
    "t0 = time.time()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for batch in validation_dataloader:\n",
    "\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "    # values prior to applying an activation function like the softmax.\n",
    "    logits = outputs[0]\n",
    "    \n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences.\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Accumulate the total accuracy.\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    # Track the number of batches\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "# Report the final accuracy for this validation run.\n",
    "print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of  8,482.    Elapsed: 0:00:11.\n",
      "  Batch    80  of  8,482.    Elapsed: 0:00:22.\n",
      "  Batch   120  of  8,482.    Elapsed: 0:00:34.\n",
      "  Batch   160  of  8,482.    Elapsed: 0:00:45.\n",
      "  Batch   200  of  8,482.    Elapsed: 0:00:56.\n",
      "  Batch   240  of  8,482.    Elapsed: 0:01:07.\n",
      "  Batch   280  of  8,482.    Elapsed: 0:01:18.\n",
      "  Batch   320  of  8,482.    Elapsed: 0:01:30.\n",
      "  Batch   360  of  8,482.    Elapsed: 0:01:41.\n",
      "  Batch   400  of  8,482.    Elapsed: 0:01:52.\n",
      "  Batch   440  of  8,482.    Elapsed: 0:02:03.\n",
      "  Batch   480  of  8,482.    Elapsed: 0:02:15.\n",
      "  Batch   520  of  8,482.    Elapsed: 0:02:26.\n",
      "  Batch   560  of  8,482.    Elapsed: 0:02:37.\n",
      "  Batch   600  of  8,482.    Elapsed: 0:02:49.\n",
      "  Batch   640  of  8,482.    Elapsed: 0:03:00.\n",
      "  Batch   680  of  8,482.    Elapsed: 0:03:11.\n",
      "  Batch   720  of  8,482.    Elapsed: 0:03:23.\n",
      "  Batch   760  of  8,482.    Elapsed: 0:03:34.\n",
      "  Batch   800  of  8,482.    Elapsed: 0:03:46.\n",
      "  Batch   840  of  8,482.    Elapsed: 0:03:58.\n",
      "  Batch   880  of  8,482.    Elapsed: 0:04:11.\n",
      "  Batch   920  of  8,482.    Elapsed: 0:04:22.\n",
      "  Batch   960  of  8,482.    Elapsed: 0:04:33.\n",
      "  Batch 1,000  of  8,482.    Elapsed: 0:04:45.\n",
      "  Batch 1,040  of  8,482.    Elapsed: 0:04:56.\n",
      "  Batch 1,080  of  8,482.    Elapsed: 0:05:07.\n",
      "  Batch 1,120  of  8,482.    Elapsed: 0:05:19.\n",
      "  Batch 1,160  of  8,482.    Elapsed: 0:05:30.\n",
      "  Batch 1,200  of  8,482.    Elapsed: 0:05:42.\n",
      "  Batch 1,240  of  8,482.    Elapsed: 0:05:53.\n",
      "  Batch 1,280  of  8,482.    Elapsed: 0:06:05.\n",
      "  Batch 1,320  of  8,482.    Elapsed: 0:06:16.\n",
      "  Batch 1,360  of  8,482.    Elapsed: 0:06:27.\n",
      "  Batch 1,400  of  8,482.    Elapsed: 0:06:39.\n",
      "  Batch 1,440  of  8,482.    Elapsed: 0:06:50.\n",
      "  Batch 1,480  of  8,482.    Elapsed: 0:07:02.\n",
      "  Batch 1,520  of  8,482.    Elapsed: 0:07:13.\n",
      "  Batch 1,560  of  8,482.    Elapsed: 0:07:25.\n",
      "  Batch 1,600  of  8,482.    Elapsed: 0:07:36.\n",
      "  Batch 1,640  of  8,482.    Elapsed: 0:07:48.\n",
      "  Batch 1,680  of  8,482.    Elapsed: 0:07:59.\n",
      "  Batch 1,720  of  8,482.    Elapsed: 0:08:11.\n",
      "  Batch 1,760  of  8,482.    Elapsed: 0:08:22.\n",
      "  Batch 1,800  of  8,482.    Elapsed: 0:08:33.\n",
      "  Batch 1,840  of  8,482.    Elapsed: 0:08:45.\n",
      "  Batch 1,880  of  8,482.    Elapsed: 0:08:56.\n",
      "  Batch 1,920  of  8,482.    Elapsed: 0:09:08.\n",
      "  Batch 1,960  of  8,482.    Elapsed: 0:09:19.\n",
      "  Batch 2,000  of  8,482.    Elapsed: 0:09:31.\n",
      "  Batch 2,040  of  8,482.    Elapsed: 0:09:42.\n",
      "  Batch 2,080  of  8,482.    Elapsed: 0:09:54.\n",
      "  Batch 2,120  of  8,482.    Elapsed: 0:10:05.\n",
      "  Batch 2,160  of  8,482.    Elapsed: 0:10:17.\n",
      "  Batch 2,200  of  8,482.    Elapsed: 0:10:28.\n",
      "  Batch 2,240  of  8,482.    Elapsed: 0:10:40.\n",
      "  Batch 2,280  of  8,482.    Elapsed: 0:10:51.\n",
      "  Batch 2,320  of  8,482.    Elapsed: 0:11:03.\n",
      "  Batch 2,360  of  8,482.    Elapsed: 0:11:14.\n",
      "  Batch 2,400  of  8,482.    Elapsed: 0:11:26.\n",
      "  Batch 2,440  of  8,482.    Elapsed: 0:11:37.\n",
      "  Batch 2,480  of  8,482.    Elapsed: 0:11:48.\n",
      "  Batch 2,520  of  8,482.    Elapsed: 0:12:00.\n",
      "  Batch 2,560  of  8,482.    Elapsed: 0:12:11.\n",
      "  Batch 2,600  of  8,482.    Elapsed: 0:12:23.\n",
      "  Batch 2,640  of  8,482.    Elapsed: 0:12:34.\n",
      "  Batch 2,680  of  8,482.    Elapsed: 0:12:46.\n",
      "  Batch 2,720  of  8,482.    Elapsed: 0:12:57.\n",
      "  Batch 2,760  of  8,482.    Elapsed: 0:13:09.\n",
      "  Batch 2,800  of  8,482.    Elapsed: 0:13:20.\n",
      "  Batch 2,840  of  8,482.    Elapsed: 0:13:32.\n",
      "  Batch 2,880  of  8,482.    Elapsed: 0:13:43.\n",
      "  Batch 2,920  of  8,482.    Elapsed: 0:13:55.\n",
      "  Batch 2,960  of  8,482.    Elapsed: 0:14:06.\n",
      "  Batch 3,000  of  8,482.    Elapsed: 0:14:19.\n",
      "  Batch 3,040  of  8,482.    Elapsed: 0:14:30.\n",
      "  Batch 3,080  of  8,482.    Elapsed: 0:14:42.\n",
      "  Batch 3,120  of  8,482.    Elapsed: 0:14:53.\n",
      "  Batch 3,160  of  8,482.    Elapsed: 0:15:05.\n",
      "  Batch 3,200  of  8,482.    Elapsed: 0:15:16.\n",
      "  Batch 3,240  of  8,482.    Elapsed: 0:15:28.\n",
      "  Batch 3,280  of  8,482.    Elapsed: 0:15:39.\n",
      "  Batch 3,320  of  8,482.    Elapsed: 0:15:51.\n",
      "  Batch 3,360  of  8,482.    Elapsed: 0:16:02.\n",
      "  Batch 3,400  of  8,482.    Elapsed: 0:16:14.\n",
      "  Batch 3,440  of  8,482.    Elapsed: 0:16:25.\n",
      "  Batch 3,480  of  8,482.    Elapsed: 0:16:37.\n",
      "  Batch 3,520  of  8,482.    Elapsed: 0:16:48.\n",
      "  Batch 3,560  of  8,482.    Elapsed: 0:17:00.\n",
      "  Batch 3,600  of  8,482.    Elapsed: 0:17:11.\n",
      "  Batch 3,640  of  8,482.    Elapsed: 0:17:23.\n",
      "  Batch 3,680  of  8,482.    Elapsed: 0:17:34.\n",
      "  Batch 3,720  of  8,482.    Elapsed: 0:17:46.\n",
      "  Batch 3,760  of  8,482.    Elapsed: 0:17:57.\n",
      "  Batch 3,800  of  8,482.    Elapsed: 0:18:09.\n",
      "  Batch 3,840  of  8,482.    Elapsed: 0:18:20.\n",
      "  Batch 3,880  of  8,482.    Elapsed: 0:18:32.\n",
      "  Batch 3,920  of  8,482.    Elapsed: 0:18:43.\n",
      "  Batch 3,960  of  8,482.    Elapsed: 0:18:55.\n",
      "  Batch 4,000  of  8,482.    Elapsed: 0:19:07.\n",
      "  Batch 4,040  of  8,482.    Elapsed: 0:19:20.\n",
      "  Batch 4,080  of  8,482.    Elapsed: 0:19:31.\n",
      "  Batch 4,120  of  8,482.    Elapsed: 0:19:43.\n",
      "  Batch 4,160  of  8,482.    Elapsed: 0:19:54.\n",
      "  Batch 4,200  of  8,482.    Elapsed: 0:20:05.\n",
      "  Batch 4,240  of  8,482.    Elapsed: 0:20:17.\n",
      "  Batch 4,280  of  8,482.    Elapsed: 0:20:28.\n",
      "  Batch 4,320  of  8,482.    Elapsed: 0:20:40.\n",
      "  Batch 4,360  of  8,482.    Elapsed: 0:20:51.\n",
      "  Batch 4,400  of  8,482.    Elapsed: 0:21:03.\n",
      "  Batch 4,440  of  8,482.    Elapsed: 0:21:14.\n",
      "  Batch 4,480  of  8,482.    Elapsed: 0:21:26.\n",
      "  Batch 4,520  of  8,482.    Elapsed: 0:21:37.\n",
      "  Batch 4,560  of  8,482.    Elapsed: 0:21:49.\n",
      "  Batch 4,600  of  8,482.    Elapsed: 0:22:00.\n",
      "  Batch 4,640  of  8,482.    Elapsed: 0:22:12.\n",
      "  Batch 4,680  of  8,482.    Elapsed: 0:22:23.\n",
      "  Batch 4,720  of  8,482.    Elapsed: 0:22:35.\n",
      "  Batch 4,760  of  8,482.    Elapsed: 0:22:46.\n",
      "  Batch 4,800  of  8,482.    Elapsed: 0:22:58.\n",
      "  Batch 4,840  of  8,482.    Elapsed: 0:23:09.\n",
      "  Batch 4,880  of  8,482.    Elapsed: 0:23:21.\n",
      "  Batch 4,920  of  8,482.    Elapsed: 0:23:32.\n",
      "  Batch 4,960  of  8,482.    Elapsed: 0:23:44.\n",
      "  Batch 5,000  of  8,482.    Elapsed: 0:23:55.\n",
      "  Batch 5,040  of  8,482.    Elapsed: 0:24:07.\n",
      "  Batch 5,080  of  8,482.    Elapsed: 0:24:18.\n",
      "  Batch 5,120  of  8,482.    Elapsed: 0:24:31.\n",
      "  Batch 5,160  of  8,482.    Elapsed: 0:24:42.\n",
      "  Batch 5,200  of  8,482.    Elapsed: 0:24:54.\n",
      "  Batch 5,240  of  8,482.    Elapsed: 0:25:05.\n",
      "  Batch 5,280  of  8,482.    Elapsed: 0:25:17.\n",
      "  Batch 5,320  of  8,482.    Elapsed: 0:25:28.\n",
      "  Batch 5,360  of  8,482.    Elapsed: 0:25:40.\n",
      "  Batch 5,400  of  8,482.    Elapsed: 0:25:51.\n",
      "  Batch 5,440  of  8,482.    Elapsed: 0:26:03.\n",
      "  Batch 5,480  of  8,482.    Elapsed: 0:26:15.\n",
      "  Batch 5,520  of  8,482.    Elapsed: 0:26:26.\n",
      "  Batch 5,560  of  8,482.    Elapsed: 0:26:38.\n",
      "  Batch 5,600  of  8,482.    Elapsed: 0:26:49.\n",
      "  Batch 5,640  of  8,482.    Elapsed: 0:27:01.\n",
      "  Batch 5,680  of  8,482.    Elapsed: 0:27:12.\n",
      "  Batch 5,720  of  8,482.    Elapsed: 0:27:24.\n",
      "  Batch 5,760  of  8,482.    Elapsed: 0:27:35.\n",
      "  Batch 5,800  of  8,482.    Elapsed: 0:27:47.\n",
      "  Batch 5,840  of  8,482.    Elapsed: 0:27:58.\n",
      "  Batch 5,880  of  8,482.    Elapsed: 0:28:10.\n",
      "  Batch 5,920  of  8,482.    Elapsed: 0:28:21.\n",
      "  Batch 5,960  of  8,482.    Elapsed: 0:28:33.\n",
      "  Batch 6,000  of  8,482.    Elapsed: 0:28:45.\n",
      "  Batch 6,040  of  8,482.    Elapsed: 0:28:56.\n",
      "  Batch 6,080  of  8,482.    Elapsed: 0:29:08.\n",
      "  Batch 6,120  of  8,482.    Elapsed: 0:29:19.\n",
      "  Batch 6,160  of  8,482.    Elapsed: 0:29:31.\n",
      "  Batch 6,200  of  8,482.    Elapsed: 0:29:42.\n",
      "  Batch 6,240  of  8,482.    Elapsed: 0:29:54.\n",
      "  Batch 6,280  of  8,482.    Elapsed: 0:30:05.\n",
      "  Batch 6,320  of  8,482.    Elapsed: 0:30:17.\n",
      "  Batch 6,360  of  8,482.    Elapsed: 0:30:29.\n",
      "  Batch 6,400  of  8,482.    Elapsed: 0:30:40.\n",
      "  Batch 6,440  of  8,482.    Elapsed: 0:30:52.\n",
      "  Batch 6,480  of  8,482.    Elapsed: 0:31:03.\n",
      "  Batch 6,520  of  8,482.    Elapsed: 0:31:15.\n",
      "  Batch 6,560  of  8,482.    Elapsed: 0:31:27.\n",
      "  Batch 6,600  of  8,482.    Elapsed: 0:31:40.\n",
      "  Batch 6,640  of  8,482.    Elapsed: 0:31:52.\n",
      "  Batch 6,680  of  8,482.    Elapsed: 0:32:03.\n",
      "  Batch 6,720  of  8,482.    Elapsed: 0:32:15.\n",
      "  Batch 6,760  of  8,482.    Elapsed: 0:32:27.\n",
      "  Batch 6,800  of  8,482.    Elapsed: 0:32:38.\n",
      "  Batch 6,840  of  8,482.    Elapsed: 0:32:50.\n",
      "  Batch 6,880  of  8,482.    Elapsed: 0:33:01.\n",
      "  Batch 6,920  of  8,482.    Elapsed: 0:33:13.\n",
      "  Batch 6,960  of  8,482.    Elapsed: 0:33:24.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 7,000  of  8,482.    Elapsed: 0:33:36.\n",
      "  Batch 7,040  of  8,482.    Elapsed: 0:33:48.\n",
      "  Batch 7,080  of  8,482.    Elapsed: 0:33:59.\n",
      "  Batch 7,120  of  8,482.    Elapsed: 0:34:11.\n",
      "  Batch 7,160  of  8,482.    Elapsed: 0:34:22.\n",
      "  Batch 7,200  of  8,482.    Elapsed: 0:34:34.\n",
      "  Batch 7,240  of  8,482.    Elapsed: 0:34:45.\n",
      "  Batch 7,280  of  8,482.    Elapsed: 0:34:57.\n",
      "  Batch 7,320  of  8,482.    Elapsed: 0:35:08.\n",
      "  Batch 7,360  of  8,482.    Elapsed: 0:35:20.\n",
      "  Batch 7,400  of  8,482.    Elapsed: 0:35:32.\n",
      "  Batch 7,440  of  8,482.    Elapsed: 0:35:43.\n",
      "  Batch 7,480  of  8,482.    Elapsed: 0:35:55.\n",
      "  Batch 7,520  of  8,482.    Elapsed: 0:36:06.\n",
      "  Batch 7,560  of  8,482.    Elapsed: 0:36:18.\n",
      "  Batch 7,600  of  8,482.    Elapsed: 0:36:29.\n",
      "  Batch 7,640  of  8,482.    Elapsed: 0:36:41.\n",
      "  Batch 7,680  of  8,482.    Elapsed: 0:36:53.\n",
      "  Batch 7,720  of  8,482.    Elapsed: 0:37:05.\n",
      "  Batch 7,760  of  8,482.    Elapsed: 0:37:17.\n",
      "  Batch 7,800  of  8,482.    Elapsed: 0:37:28.\n",
      "  Batch 7,840  of  8,482.    Elapsed: 0:37:40.\n",
      "  Batch 7,880  of  8,482.    Elapsed: 0:37:51.\n",
      "  Batch 7,920  of  8,482.    Elapsed: 0:38:03.\n",
      "  Batch 7,960  of  8,482.    Elapsed: 0:38:14.\n",
      "  Batch 8,000  of  8,482.    Elapsed: 0:38:26.\n",
      "  Batch 8,040  of  8,482.    Elapsed: 0:38:38.\n",
      "  Batch 8,080  of  8,482.    Elapsed: 0:38:49.\n",
      "  Batch 8,120  of  8,482.    Elapsed: 0:39:01.\n",
      "  Batch 8,160  of  8,482.    Elapsed: 0:39:12.\n",
      "  Batch 8,200  of  8,482.    Elapsed: 0:39:24.\n",
      "  Batch 8,240  of  8,482.    Elapsed: 0:39:36.\n",
      "  Batch 8,280  of  8,482.    Elapsed: 0:39:47.\n",
      "  Batch 8,320  of  8,482.    Elapsed: 0:39:59.\n",
      "  Batch 8,360  of  8,482.    Elapsed: 0:40:10.\n",
      "  Batch 8,400  of  8,482.    Elapsed: 0:40:22.\n",
      "  Batch 8,440  of  8,482.    Elapsed: 0:40:34.\n",
      "  Batch 8,480  of  8,482.    Elapsed: 0:40:45.\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 0:40:46\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.9689\n",
      "  Validation took: 0:01:30\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of  8,482.    Elapsed: 0:00:12.\n",
      "  Batch    80  of  8,482.    Elapsed: 0:00:23.\n",
      "  Batch   120  of  8,482.    Elapsed: 0:00:35.\n",
      "  Batch   160  of  8,482.    Elapsed: 0:00:46.\n",
      "  Batch   200  of  8,482.    Elapsed: 0:00:58.\n",
      "  Batch   240  of  8,482.    Elapsed: 0:01:10.\n",
      "  Batch   280  of  8,482.    Elapsed: 0:01:21.\n",
      "  Batch   320  of  8,482.    Elapsed: 0:01:33.\n",
      "  Batch   360  of  8,482.    Elapsed: 0:01:44.\n",
      "  Batch   400  of  8,482.    Elapsed: 0:01:56.\n",
      "  Batch   440  of  8,482.    Elapsed: 0:02:08.\n",
      "  Batch   480  of  8,482.    Elapsed: 0:02:19.\n",
      "  Batch   520  of  8,482.    Elapsed: 0:02:31.\n",
      "  Batch   560  of  8,482.    Elapsed: 0:02:42.\n",
      "  Batch   600  of  8,482.    Elapsed: 0:02:54.\n",
      "  Batch   640  of  8,482.    Elapsed: 0:03:06.\n",
      "  Batch   680  of  8,482.    Elapsed: 0:03:17.\n",
      "  Batch   720  of  8,482.    Elapsed: 0:03:29.\n",
      "  Batch   760  of  8,482.    Elapsed: 0:03:40.\n",
      "  Batch   800  of  8,482.    Elapsed: 0:03:52.\n",
      "  Batch   840  of  8,482.    Elapsed: 0:04:04.\n",
      "  Batch   880  of  8,482.    Elapsed: 0:04:15.\n",
      "  Batch   920  of  8,482.    Elapsed: 0:04:27.\n",
      "  Batch   960  of  8,482.    Elapsed: 0:04:39.\n",
      "  Batch 1,000  of  8,482.    Elapsed: 0:04:50.\n",
      "  Batch 1,040  of  8,482.    Elapsed: 0:05:02.\n",
      "  Batch 1,080  of  8,482.    Elapsed: 0:05:13.\n",
      "  Batch 1,120  of  8,482.    Elapsed: 0:05:25.\n",
      "  Batch 1,160  of  8,482.    Elapsed: 0:05:37.\n",
      "  Batch 1,200  of  8,482.    Elapsed: 0:05:48.\n",
      "  Batch 1,240  of  8,482.    Elapsed: 0:06:00.\n",
      "  Batch 1,280  of  8,482.    Elapsed: 0:06:11.\n",
      "  Batch 1,320  of  8,482.    Elapsed: 0:06:23.\n",
      "  Batch 1,360  of  8,482.    Elapsed: 0:06:35.\n",
      "  Batch 1,400  of  8,482.    Elapsed: 0:06:46.\n",
      "  Batch 1,440  of  8,482.    Elapsed: 0:06:58.\n",
      "  Batch 1,480  of  8,482.    Elapsed: 0:07:10.\n",
      "  Batch 1,520  of  8,482.    Elapsed: 0:07:21.\n",
      "  Batch 1,560  of  8,482.    Elapsed: 0:07:33.\n",
      "  Batch 1,600  of  8,482.    Elapsed: 0:07:44.\n",
      "  Batch 1,640  of  8,482.    Elapsed: 0:07:56.\n",
      "  Batch 1,680  of  8,482.    Elapsed: 0:08:07.\n",
      "  Batch 1,720  of  8,482.    Elapsed: 0:08:19.\n",
      "  Batch 1,760  of  8,482.    Elapsed: 0:08:31.\n",
      "  Batch 1,800  of  8,482.    Elapsed: 0:08:42.\n",
      "  Batch 1,840  of  8,482.    Elapsed: 0:08:54.\n",
      "  Batch 1,880  of  8,482.    Elapsed: 0:09:05.\n",
      "  Batch 1,920  of  8,482.    Elapsed: 0:09:17.\n",
      "  Batch 1,960  of  8,482.    Elapsed: 0:09:29.\n",
      "  Batch 2,000  of  8,482.    Elapsed: 0:09:40.\n",
      "  Batch 2,040  of  8,482.    Elapsed: 0:09:52.\n",
      "  Batch 2,080  of  8,482.    Elapsed: 0:10:04.\n",
      "  Batch 2,120  of  8,482.    Elapsed: 0:10:15.\n",
      "  Batch 2,160  of  8,482.    Elapsed: 0:10:27.\n",
      "  Batch 2,200  of  8,482.    Elapsed: 0:10:38.\n",
      "  Batch 2,240  of  8,482.    Elapsed: 0:10:50.\n",
      "  Batch 2,280  of  8,482.    Elapsed: 0:11:02.\n",
      "  Batch 2,320  of  8,482.    Elapsed: 0:11:13.\n",
      "  Batch 2,360  of  8,482.    Elapsed: 0:11:25.\n",
      "  Batch 2,400  of  8,482.    Elapsed: 0:11:36.\n",
      "  Batch 2,440  of  8,482.    Elapsed: 0:11:48.\n",
      "  Batch 2,480  of  8,482.    Elapsed: 0:12:00.\n",
      "  Batch 2,520  of  8,482.    Elapsed: 0:12:11.\n",
      "  Batch 2,560  of  8,482.    Elapsed: 0:12:23.\n",
      "  Batch 2,600  of  8,482.    Elapsed: 0:12:34.\n",
      "  Batch 2,640  of  8,482.    Elapsed: 0:12:46.\n",
      "  Batch 2,680  of  8,482.    Elapsed: 0:12:58.\n",
      "  Batch 2,720  of  8,482.    Elapsed: 0:13:09.\n",
      "  Batch 2,760  of  8,482.    Elapsed: 0:13:21.\n",
      "  Batch 2,800  of  8,482.    Elapsed: 0:13:33.\n",
      "  Batch 2,840  of  8,482.    Elapsed: 0:13:44.\n",
      "  Batch 2,880  of  8,482.    Elapsed: 0:13:56.\n",
      "  Batch 2,920  of  8,482.    Elapsed: 0:14:07.\n",
      "  Batch 2,960  of  8,482.    Elapsed: 0:14:19.\n",
      "  Batch 3,000  of  8,482.    Elapsed: 0:14:31.\n",
      "  Batch 3,040  of  8,482.    Elapsed: 0:14:42.\n",
      "  Batch 3,080  of  8,482.    Elapsed: 0:14:54.\n",
      "  Batch 3,120  of  8,482.    Elapsed: 0:15:05.\n",
      "  Batch 3,160  of  8,482.    Elapsed: 0:15:17.\n",
      "  Batch 3,200  of  8,482.    Elapsed: 0:15:28.\n",
      "  Batch 3,240  of  8,482.    Elapsed: 0:15:40.\n",
      "  Batch 3,280  of  8,482.    Elapsed: 0:15:52.\n",
      "  Batch 3,320  of  8,482.    Elapsed: 0:16:03.\n",
      "  Batch 3,360  of  8,482.    Elapsed: 0:16:15.\n",
      "  Batch 3,400  of  8,482.    Elapsed: 0:16:26.\n",
      "  Batch 3,440  of  8,482.    Elapsed: 0:16:38.\n",
      "  Batch 3,480  of  8,482.    Elapsed: 0:16:50.\n",
      "  Batch 3,520  of  8,482.    Elapsed: 0:17:01.\n",
      "  Batch 3,560  of  8,482.    Elapsed: 0:17:13.\n",
      "  Batch 3,600  of  8,482.    Elapsed: 0:17:25.\n",
      "  Batch 3,640  of  8,482.    Elapsed: 0:17:36.\n",
      "  Batch 3,680  of  8,482.    Elapsed: 0:17:48.\n",
      "  Batch 3,720  of  8,482.    Elapsed: 0:17:59.\n",
      "  Batch 3,760  of  8,482.    Elapsed: 0:18:11.\n",
      "  Batch 3,800  of  8,482.    Elapsed: 0:18:23.\n",
      "  Batch 3,840  of  8,482.    Elapsed: 0:18:34.\n",
      "  Batch 3,880  of  8,482.    Elapsed: 0:18:46.\n",
      "  Batch 3,920  of  8,482.    Elapsed: 0:18:57.\n",
      "  Batch 3,960  of  8,482.    Elapsed: 0:19:09.\n",
      "  Batch 4,000  of  8,482.    Elapsed: 0:19:21.\n",
      "  Batch 4,040  of  8,482.    Elapsed: 0:19:32.\n",
      "  Batch 4,080  of  8,482.    Elapsed: 0:19:44.\n",
      "  Batch 4,120  of  8,482.    Elapsed: 0:19:55.\n",
      "  Batch 4,160  of  8,482.    Elapsed: 0:20:07.\n",
      "  Batch 4,200  of  8,482.    Elapsed: 0:20:18.\n",
      "  Batch 4,240  of  8,482.    Elapsed: 0:20:30.\n",
      "  Batch 4,280  of  8,482.    Elapsed: 0:20:42.\n",
      "  Batch 4,320  of  8,482.    Elapsed: 0:20:53.\n",
      "  Batch 4,360  of  8,482.    Elapsed: 0:21:05.\n",
      "  Batch 4,400  of  8,482.    Elapsed: 0:21:17.\n",
      "  Batch 4,440  of  8,482.    Elapsed: 0:21:28.\n",
      "  Batch 4,480  of  8,482.    Elapsed: 0:21:40.\n",
      "  Batch 4,520  of  8,482.    Elapsed: 0:21:51.\n",
      "  Batch 4,560  of  8,482.    Elapsed: 0:22:03.\n",
      "  Batch 4,600  of  8,482.    Elapsed: 0:22:15.\n",
      "  Batch 4,640  of  8,482.    Elapsed: 0:22:26.\n",
      "  Batch 4,680  of  8,482.    Elapsed: 0:22:38.\n",
      "  Batch 4,720  of  8,482.    Elapsed: 0:22:49.\n",
      "  Batch 4,760  of  8,482.    Elapsed: 0:23:01.\n",
      "  Batch 4,800  of  8,482.    Elapsed: 0:23:13.\n",
      "  Batch 4,840  of  8,482.    Elapsed: 0:23:26.\n",
      "  Batch 4,880  of  8,482.    Elapsed: 0:23:38.\n",
      "  Batch 4,920  of  8,482.    Elapsed: 0:23:50.\n",
      "  Batch 4,960  of  8,482.    Elapsed: 0:24:01.\n",
      "  Batch 5,000  of  8,482.    Elapsed: 0:24:13.\n",
      "  Batch 5,040  of  8,482.    Elapsed: 0:24:24.\n",
      "  Batch 5,080  of  8,482.    Elapsed: 0:24:36.\n",
      "  Batch 5,120  of  8,482.    Elapsed: 0:24:48.\n",
      "  Batch 5,160  of  8,482.    Elapsed: 0:24:59.\n",
      "  Batch 5,200  of  8,482.    Elapsed: 0:25:11.\n",
      "  Batch 5,240  of  8,482.    Elapsed: 0:25:22.\n",
      "  Batch 5,280  of  8,482.    Elapsed: 0:25:34.\n",
      "  Batch 5,320  of  8,482.    Elapsed: 0:25:46.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 5,360  of  8,482.    Elapsed: 0:25:57.\n",
      "  Batch 5,400  of  8,482.    Elapsed: 0:26:09.\n",
      "  Batch 5,440  of  8,482.    Elapsed: 0:26:20.\n",
      "  Batch 5,480  of  8,482.    Elapsed: 0:26:32.\n",
      "  Batch 5,520  of  8,482.    Elapsed: 0:26:44.\n",
      "  Batch 5,560  of  8,482.    Elapsed: 0:26:55.\n",
      "  Batch 5,600  of  8,482.    Elapsed: 0:27:07.\n",
      "  Batch 5,640  of  8,482.    Elapsed: 0:27:18.\n",
      "  Batch 5,680  of  8,482.    Elapsed: 0:27:30.\n",
      "  Batch 5,720  of  8,482.    Elapsed: 0:27:42.\n",
      "  Batch 5,760  of  8,482.    Elapsed: 0:27:53.\n",
      "  Batch 5,800  of  8,482.    Elapsed: 0:28:05.\n",
      "  Batch 5,840  of  8,482.    Elapsed: 0:28:16.\n",
      "  Batch 5,880  of  8,482.    Elapsed: 0:28:28.\n",
      "  Batch 5,920  of  8,482.    Elapsed: 0:28:40.\n",
      "  Batch 5,960  of  8,482.    Elapsed: 0:28:51.\n",
      "  Batch 6,000  of  8,482.    Elapsed: 0:29:03.\n",
      "  Batch 6,040  of  8,482.    Elapsed: 0:29:15.\n",
      "  Batch 6,080  of  8,482.    Elapsed: 0:29:26.\n",
      "  Batch 6,120  of  8,482.    Elapsed: 0:29:38.\n",
      "  Batch 6,160  of  8,482.    Elapsed: 0:29:49.\n",
      "  Batch 6,200  of  8,482.    Elapsed: 0:30:01.\n",
      "  Batch 6,240  of  8,482.    Elapsed: 0:30:13.\n",
      "  Batch 6,280  of  8,482.    Elapsed: 0:30:24.\n",
      "  Batch 6,320  of  8,482.    Elapsed: 0:30:36.\n",
      "  Batch 6,360  of  8,482.    Elapsed: 0:30:48.\n",
      "  Batch 6,400  of  8,482.    Elapsed: 0:30:59.\n",
      "  Batch 6,440  of  8,482.    Elapsed: 0:31:11.\n",
      "  Batch 6,480  of  8,482.    Elapsed: 0:31:22.\n",
      "  Batch 6,520  of  8,482.    Elapsed: 0:31:34.\n",
      "  Batch 6,560  of  8,482.    Elapsed: 0:31:45.\n",
      "  Batch 6,600  of  8,482.    Elapsed: 0:31:57.\n",
      "  Batch 6,640  of  8,482.    Elapsed: 0:32:09.\n",
      "  Batch 6,680  of  8,482.    Elapsed: 0:32:20.\n",
      "  Batch 6,720  of  8,482.    Elapsed: 0:32:32.\n",
      "  Batch 6,760  of  8,482.    Elapsed: 0:32:43.\n",
      "  Batch 6,800  of  8,482.    Elapsed: 0:32:55.\n",
      "  Batch 6,840  of  8,482.    Elapsed: 0:33:07.\n",
      "  Batch 6,880  of  8,482.    Elapsed: 0:33:18.\n",
      "  Batch 6,920  of  8,482.    Elapsed: 0:33:30.\n",
      "  Batch 6,960  of  8,482.    Elapsed: 0:33:43.\n",
      "  Batch 7,000  of  8,482.    Elapsed: 0:33:54.\n",
      "  Batch 7,040  of  8,482.    Elapsed: 0:34:06.\n",
      "  Batch 7,080  of  8,482.    Elapsed: 0:34:18.\n",
      "  Batch 7,120  of  8,482.    Elapsed: 0:34:29.\n",
      "  Batch 7,160  of  8,482.    Elapsed: 0:34:41.\n",
      "  Batch 7,200  of  8,482.    Elapsed: 0:34:53.\n",
      "  Batch 7,240  of  8,482.    Elapsed: 0:35:04.\n",
      "  Batch 7,280  of  8,482.    Elapsed: 0:35:16.\n",
      "  Batch 7,320  of  8,482.    Elapsed: 0:35:27.\n",
      "  Batch 7,360  of  8,482.    Elapsed: 0:35:39.\n",
      "  Batch 7,400  of  8,482.    Elapsed: 0:35:51.\n",
      "  Batch 7,440  of  8,482.    Elapsed: 0:36:02.\n",
      "  Batch 7,480  of  8,482.    Elapsed: 0:36:14.\n",
      "  Batch 7,520  of  8,482.    Elapsed: 0:36:26.\n",
      "  Batch 7,560  of  8,482.    Elapsed: 0:36:37.\n",
      "  Batch 7,600  of  8,482.    Elapsed: 0:36:49.\n",
      "  Batch 7,640  of  8,482.    Elapsed: 0:37:01.\n",
      "  Batch 7,680  of  8,482.    Elapsed: 0:37:12.\n",
      "  Batch 7,720  of  8,482.    Elapsed: 0:37:24.\n",
      "  Batch 7,760  of  8,482.    Elapsed: 0:37:36.\n",
      "  Batch 7,800  of  8,482.    Elapsed: 0:37:47.\n",
      "  Batch 7,840  of  8,482.    Elapsed: 0:37:59.\n",
      "  Batch 7,880  of  8,482.    Elapsed: 0:38:11.\n",
      "  Batch 7,920  of  8,482.    Elapsed: 0:38:22.\n",
      "  Batch 7,960  of  8,482.    Elapsed: 0:38:34.\n",
      "  Batch 8,000  of  8,482.    Elapsed: 0:38:45.\n",
      "  Batch 8,040  of  8,482.    Elapsed: 0:38:57.\n",
      "  Batch 8,080  of  8,482.    Elapsed: 0:39:09.\n",
      "  Batch 8,120  of  8,482.    Elapsed: 0:39:20.\n",
      "  Batch 8,160  of  8,482.    Elapsed: 0:39:32.\n",
      "  Batch 8,200  of  8,482.    Elapsed: 0:39:43.\n",
      "  Batch 8,240  of  8,482.    Elapsed: 0:39:55.\n",
      "  Batch 8,280  of  8,482.    Elapsed: 0:40:07.\n",
      "  Batch 8,320  of  8,482.    Elapsed: 0:40:18.\n",
      "  Batch 8,360  of  8,482.    Elapsed: 0:40:30.\n",
      "  Batch 8,400  of  8,482.    Elapsed: 0:40:42.\n",
      "  Batch 8,440  of  8,482.    Elapsed: 0:40:53.\n",
      "  Batch 8,480  of  8,482.    Elapsed: 0:41:05.\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:41:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.9681\n",
      "  Validation took: 0:01:32\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    print()\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull theloss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0 - This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.4f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), open(data_path+\"e2e_bert.pth\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with a saved model & cpu - Load a trained model that you have fine-tuned\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
    "model_loaded = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", state_dict=torch.load(data_path+\"e2e_bert.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "text = 'it was tedious at times but altogether i would recommend it'\n",
    "model_loaded.eval()\n",
    "with torch.no_grad():\n",
    "    sent_token = torch.Tensor(pad_sequences([tokenizer.encode(text, add_special_tokens=True)], 128)).long()\n",
    "    sent_att = (sent_token > 0).int()\n",
    "    res = model_loaded(sent_token, attention_mask=sent_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## infer on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'data/toxic/toxic'\n",
    "model_path = base_path + 'e2e_bert.pth'\n",
    "tst_path = base_path + '_test_clean.csv'\n",
    "out_path = base_path + '_test_pred.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", state_dict=torch.load(model_path))\n",
    "model_loaded.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rad the dataset\n",
    "tst_df = pd.read_csv(tst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "proba_list = []\n",
    "raw_out = []\n",
    "# evaluation only\n",
    "print(\"\")\n",
    "print(\"Running Test...\")\n",
    "device = \"cuda\"\n",
    "t0 = time.time()\n",
    "\n",
    "model_loaded.eval()\n",
    "\n",
    "# Tracking variables \n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for batch in test_dataloader:\n",
    "\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model_loaded(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # Get the \"logits\" output by the model\n",
    "    logits = outputs[0]\n",
    "    \n",
    "    raw_out.append(logits.cpu().numpy())\n",
    "    \n",
    "    probs, preds = F.softmax(logits).max(1)\n",
    "    \n",
    "    pred_list.append(preds.cpu().numpy())\n",
    "    proba_list.append(probs.cpu().numpy())\n",
    "    \n",
    "tst_df['preds'] = np.concatenate(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# look at distibution of probabilities\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(np.concatenate(proba_list), bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9180341400600918"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure of accuracy and no mistakes\n",
    "(tst_df['preds']==tst_df['label']).sum()/len(tst_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result\n",
    "tst_df.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### infernce with other code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.TextModels.E2EBert as E2EBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.TextModels.E2EBert' from '/home/gallil/Desktop/projects/LUNATC/src/TextModels/E2EBert.py'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(E2EBert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "code_model = E2EBert.E2EBertTextModel(trained_model=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.0220733, -4.599668 ]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_model.predict_proba('this movie was amazing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00827087529303001255"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999983491266880166"
     ]
    }
   ],
   "source": [
    "code_preds = []\n",
    "for i, text in enumerate(tst_df.content):\n",
    "    print(f'\\r{i/len(tst_df)}', end='')\n",
    "    code_preds.append(code_model.predict_proba(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.abs((np.concatenate(code_preds) - np.concatenate(raw_out))) > 0.0001).any()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test2",
   "language": "python",
   "name": "test2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
