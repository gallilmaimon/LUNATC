{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_val = 42\n",
    "device = \"cuda:0\"\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/aclImdb/imdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path+\"_train_clean.csv\")\n",
    "df_train, df_validation = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(data_path+\"_test_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lists of sentences and their labels.\n",
    "sentences_train = df_train.content.values\n",
    "labels_train = df_train.label.values\n",
    "\n",
    "sentences_validation = df_validation.content.values\n",
    "labels_validation = df_validation.label.values\n",
    "\n",
    "sentences_test = df_test.content.values\n",
    "labels_test = df_test.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tokenising & formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids_train = []\n",
    "\n",
    "# For every sentence in train\n",
    "for sent in sentences_train:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_train.append(encoded_sent)\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids_validation = []\n",
    "\n",
    "# For every sentence in test\n",
    "for sent in sentences_validation:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_validation.append(encoded_sent)\n",
    "    \n",
    "    \n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids_test = []\n",
    "\n",
    "# For every sentence in test\n",
    "for sent in sentences_test:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_test.append(encoded_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(input_ids, maxlen):\n",
    "    padded = []\n",
    "    for inp in input_ids:\n",
    "        if len(inp) >= maxlen:\n",
    "            padded.append(inp[:maxlen-1] + [inp[-1]])\n",
    "        else:\n",
    "            padded.append(inp + [0]*(maxlen - len(inp)))\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### histogram of length for choosing the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-ohqt9a28 because the default path (/home/gallil/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens_train = [len(inp) for inp in  input_ids_train]\n",
    "plt.hist(lens_train, bins=1000, range=(0,1000))\n",
    "plt.show()\n",
    "lens_validation = [len(inp) for inp in  input_ids_validation]\n",
    "plt.hist(lens_validation, bins=1000, range=(0,1000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9775066717499047\n"
     ]
    }
   ],
   "source": [
    "print((np.array(lens_train)<=256).sum()/ len(lens_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding/truncating all sentences to 256 values...\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Set the maximum sequence length.\n",
    "MAX_LEN = 256\n",
    "\n",
    "print('Padding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "print('Padding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# Pad our input tokens with value 0.\n",
    "input_ids_train = pad_sequences(input_ids_train, maxlen=MAX_LEN)\n",
    "input_ids_validation = pad_sequences(input_ids_validation, maxlen=MAX_LEN)\n",
    "input_ids_test = pad_sequences(input_ids_test, maxlen=MAX_LEN)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks_train = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids_train:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks_train.append(att_mask)\n",
    "    \n",
    "# Create attention masks\n",
    "attention_masks_validation = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids_validation:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks_validation.append(att_mask)\n",
    "\n",
    "    \n",
    "attention_masks_test = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids_test:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks_test.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename\n",
    "train_inputs, validation_inputs, test_inputs, train_labels, validation_labels, test_labels = input_ids_train, input_ids_validation, input_ids_test, labels_train, labels_validation, labels_test\n",
    "train_masks, validation_masks, test_masks = attention_masks_train, attention_masks_validation, attention_masks_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset & dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all inputs and labels into torch tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "test_masks = torch.tensor(test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13115, 256])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model & optimiser & scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2,\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 2\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, \n",
    "                                            num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return (pred_flat == labels_flat).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.51\n",
      "  Validation took: 0:00:09\n"
     ]
    }
   ],
   "source": [
    "# evaluation only - to make sure that accuracy is more or less random at the beginnig\n",
    "print(\"\")\n",
    "print(\"Running Validation...\")\n",
    "device = \"cuda\"\n",
    "t0 = time.time()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for batch in validation_dataloader:\n",
    "\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "    # values prior to applying an activation function like the softmax.\n",
    "    logits = outputs[0]\n",
    "    \n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences.\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Accumulate the total accuracy.\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    # Track the number of batches\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "# Report the final accuracy for this validation run.\n",
    "print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of    820.    Elapsed: 0:00:12.\n",
      "  Batch    80  of    820.    Elapsed: 0:00:25.\n",
      "  Batch   120  of    820.    Elapsed: 0:00:37.\n",
      "  Batch   160  of    820.    Elapsed: 0:00:50.\n",
      "  Batch   200  of    820.    Elapsed: 0:01:01.\n",
      "  Batch   240  of    820.    Elapsed: 0:01:14.\n",
      "  Batch   280  of    820.    Elapsed: 0:01:26.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d544e711a1a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Accumulate the training loss over all of the batches so that we can calculate the average loss at the end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# Perform a backward pass to calculate the gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    print()\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull theloss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0 - This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.4f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), open(data_path+\"e2e_bert.pth\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with a saved model & cpu - Load a trained model that you have fine-tuned\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
    "model_loaded = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", state_dict=torch.load(data_path+\"e2e_bert.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "text = 'it was tedious at times but altogether i would recommend it'\n",
    "model_loaded.eval()\n",
    "with torch.no_grad():\n",
    "    sent_token = torch.Tensor(pad_sequences([tokenizer.encode(text, add_special_tokens=True)], 128)).long()\n",
    "    sent_att = (sent_token > 0).int()\n",
    "    res = model_loaded(sent_token, attention_mask=sent_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## infer on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'data/aclImdb/imdb'\n",
    "model_path = base_path + 'e2e_bert.pth'\n",
    "tst_path = base_path + '_test_clean.csv'\n",
    "out_path = base_path + '_test_pred.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", state_dict=torch.load(model_path))\n",
    "model_loaded.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rad the dataset\n",
    "tst_df = pd.read_csv(tst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "proba_list = []\n",
    "raw_out = []\n",
    "# evaluation only\n",
    "print(\"\")\n",
    "print(\"Running Test...\")\n",
    "device = \"cuda\"\n",
    "t0 = time.time()\n",
    "\n",
    "model_loaded.eval()\n",
    "\n",
    "# Tracking variables \n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for batch in test_dataloader:\n",
    "\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model_loaded(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # Get the \"logits\" output by the model\n",
    "    logits = outputs[0]\n",
    "    \n",
    "    raw_out.append(logits.cpu().numpy())\n",
    "    \n",
    "    probs, preds = F.softmax(logits).max(1)\n",
    "    \n",
    "    pred_list.append(preds.cpu().numpy())\n",
    "    proba_list.append(probs.cpu().numpy())\n",
    "    \n",
    "tst_df['preds'] = np.concatenate(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# look at distibution of probabilities\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(np.concatenate(proba_list), bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9398354242546877"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure of accuracy and no mistakes\n",
    "(tst_df['preds']==tst_df['label']).sum()/len(tst_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result\n",
    "tst_df.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### infernce with other code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.TextModels.E2EBert as E2EBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(E2EBert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "code_model = E2EBert.E2EBertTextModel(trained_model=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.5622795,  2.4535475]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_model.predict_proba('this movie was amazing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99993255092405237564"
     ]
    }
   ],
   "source": [
    "code_preds = []\n",
    "for i, text in enumerate(tst_df.content):\n",
    "    print(f'\\r{i/len(tst_df)}', end='')\n",
    "    code_preds.append(code_model.predict_proba(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.abs((np.concatenate(code_preds) - np.concatenate(raw_out))) > 0.0001).any()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test2",
   "language": "python",
   "name": "test2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
