{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/aclImdb/imdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(data_path+\"_train_clean.csv\")\n",
    "df_test = pd.read_csv(data_path+\"_test_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes it was a little low budget , but this movi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i really liked this movie i saw the original c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i appreciated the photography , the textures ,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>... intimate and specific . yes , a bit of a c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a classic cartoon , always enjoyable and funny...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  label\n",
       "0  yes it was a little low budget , but this movi...      1\n",
       "1  i really liked this movie i saw the original c...      1\n",
       "2  i appreciated the photography , the textures ,...      1\n",
       "3  ... intimate and specific . yes , a bit of a c...      1\n",
       "4  a classic cartoon , always enjoyable and funny...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lists of sentences and their labels.\n",
    "sentences_train = df_train.content.values\n",
    "labels_train = df_train.label.values\n",
    "\n",
    "sentences_test = df_test.content.values\n",
    "labels_test = df_test.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tokenising & formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids_train = []\n",
    "\n",
    "# For every sentence in train\n",
    "for sent in sentences_train:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_train.append(encoded_sent)\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids_test = []\n",
    "\n",
    "# For every sentence in test\n",
    "for sent in sentences_test:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_test.append(encoded_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(input_ids, maxlen):\n",
    "    padded = []\n",
    "    for inp in input_ids:\n",
    "        if len(inp) >= maxlen:\n",
    "            padded.append(inp[:maxlen-1] + [inp[-1]])\n",
    "        else:\n",
    "            padded.append(inp + [0]*(maxlen - len(inp)))\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### histogram of length for choosing the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-axerrljx because the default path (/home/gallil/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD6CAYAAABamQdMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAR6klEQVR4nO3dbYxcV33H8e+vNgkEinDqTWripDaVoQ2IFrpEAVpEa2hSQDhvkIxE67aprFYpBdqKOuVF1BeRAkUUKgqSlQRMoYmskBKLp5Ia2qgSJGx4jGNCDKHJEhMvjXgolQKBf1/MNQzLrHd3Zta7c/b7kVb33nPvnfmfWfu3Z8+9M5uqQpLUlp9b7QIkSeNnuEtSgwx3SWqQ4S5JDTLcJalBhrskNWjRcE9yfZITSe6a1/7qJPckOZLkTX3tVyY51u27ZCWKliSd2sYlHPNu4O3Ae042JPltYBfwzKp6JMk5XfuFwG7g6cCTgX9P8tSq+uGpnmDz5s21bdu2oTogSevVnXfe+c2qmhq0b9Fwr6rbkmyb1/xnwDVV9Uh3zImufRdwY9d+X5JjwEXAJ0/1HNu2bWNmZmaxUiRJfZL890L7hp1zfyrwW0luT/KfSZ7TtZ8HPNB33GzXJkk6jZYyLbPQeZuAi4HnAAeTPAXIgGMHfr5Bkr3AXoALLrhgyDIkSYMMO3KfBW6unjuAHwGbu/bz+47bCjw46AGqan9VTVfV9NTUwCkjSdKQhg33DwC/A5DkqcAZwDeBQ8DuJGcm2Q7sAO4YQ52SpGVYdFomyQ3AC4HNSWaBq4Drgeu72yO/D+yp3sdLHklyELgbeBS4YrE7ZSRJ45e18JG/09PT5d0ykrQ8Se6squlB+3yHqiQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwX2Xb9n1otUuQ1CDDXZIaZLhLUoMM9zXC6RlJ42S4S1KDDHdJapDhLkkNMtwlqUGGuyQ1aNFwT3J9khPd30udv++vk1SSzX1tVyY5luSeJJeMu2BJ0uKWMnJ/N3Dp/MYk5wMvBu7va7sQ2A08vTvnHUk2jKVSSdKSLRruVXUb8PCAXf8AvB7o/wvbu4Abq+qRqroPOAZcNI5CJUlLN9Sce5KXA1+vqs/P23Ue8EDf9mzXJkk6jTYu94QkZwFvAH530O4BbTWgjSR7gb0AF1xwwXLLkCSdwjAj918GtgOfT/I1YCvwmSS/SG+kfn7fsVuBBwc9SFXtr6rpqpqempoaogxJ0kKWHe5V9cWqOqeqtlXVNnqB/uyq+gZwCNid5Mwk24EdwB1jrXgd8HNmJI1qKbdC3gB8Enhaktkkly90bFUdAQ4CdwMfBa6oqh+Oq1hJ0tIsOudeVa9cZP+2edtXA1ePVtb64Ahd0krxHapriGEvaVwMd0lqkOEuSQ0y3CWpQYa7JDXIcF8lXjyVtJIMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw30N8LZISeNmuEtSgwx3SWqQ4S5JDTLc1xjn3yWNg+EuSQ1ayt9QvT7JiSR39bX9fZIvJflCkn9N8qS+fVcmOZbkniSXrFDdkqRTWMrI/d3ApfPabgWeUVXPBL4MXAmQ5EJgN/D07px3JNkwtmolSUuyaLhX1W3Aw/PaPlZVj3abnwK2duu7gBur6pGqug84Blw0xnolSUswjjn3PwY+0q2fBzzQt2+2a/sZSfYmmUkyMzc3N4YyJEknjRTuSd4APAq872TTgMNq0LlVtb+qpqtqempqapQyJEnzbBz2xCR7gJcBO6vqZIDPAuf3HbYVeHD48iRJwxhq5J7kUuBvgJdX1f/17ToE7E5yZpLtwA7gjtHLlCQtx6Ij9yQ3AC8ENieZBa6id3fMmcCtSQA+VVV/WlVHkhwE7qY3XXNFVf1wpYqfVL5RSdJKWzTcq+qVA5qvO8XxVwNXj1KUJGk0vkN1DXOEL2lYhvtpZmBLOh0Md0lqkOEuSQ0y3Nc4p3EkDcNwl6QGGe6S1CDDXZIaZLhLUoMM9zXKC6mSRmG4S1KDDPcJ4Che0nIZ7pLUIMN9Qjh6l7QchrskNchwl6QGGe6S1CDDXZIatGi4J7k+yYkkd/W1nZ3k1iT3dstNffuuTHIsyT1JLlmpwiVJC1vKyP3dwKXz2vYBh6tqB3C42ybJhcBu4OndOe9IsmFs1UqSlmTRcK+q24CH5zXvAg506weAy/rab6yqR6rqPuAYcNF4SpUkLdWwc+7nVtVxgG55Ttd+HvBA33GzXdvPSLI3yUySmbm5uSHLkCQNMu4LqhnQVoMOrKr9VTVdVdNTU1NjLkOS1rdhw/2hJFsAuuWJrn0WOL/vuK3Ag8OXJ0kaxrDhfgjY063vAW7pa9+d5Mwk24EdwB2jlShJWq6Nix2Q5AbghcDmJLPAVcA1wMEklwP3A68AqKojSQ4CdwOPAldU1Q9XqPaJ4+fDSDpdFg33qnrlArt2LnD81cDVoxQlSRqN71CVpAYZ7pLUIMN9gjmHL2khhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CeU97hLOhXDXZIaZLhPEEfrkpbKcJekBhnuDXBEL2k+w12SGmS4S1KDDHdJatBI4Z7kdUmOJLkryQ1JHpvk7CS3Jrm3W24aV7GSpKUZOtyTnAf8BTBdVc8ANgC7gX3A4araARzutjVGXkCVtJhRp2U2Ao9LshE4C3gQ2AUc6PYfAC4b8TkkScs0dLhX1deBNwP3A8eBb1fVx4Bzq+p4d8xx4JxB5yfZm2Qmyczc3NywZUyMcY22T/U4juglnTTKtMwmeqP07cCTgccnedVSz6+q/VU1XVXTU1NTw5YhSRpglGmZFwH3VdVcVf0AuBl4HvBQki0A3fLE6GVqIY7WJQ0ySrjfD1yc5KwkAXYCR4FDwJ7umD3ALaOVqOUw7CVB74LoUKrq9iQ3AZ8BHgU+C+wHngAcTHI5vR8ArxhHoZKkpRs63AGq6irgqnnNj9AbxUuSVonvUJWkBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMO9Ef0fGOaHh0ky3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDPcVtNq3JK7280taPSOFe5InJbkpyZeSHE3y3CRnJ7k1yb3dctO4itXyGfDS+jTqyP1twEer6leAXwOOAvuAw1W1AzjcbUuSTqOhwz3JE4EXANcBVNX3q+pbwC7gQHfYAeCy0UqUJC3XKCP3pwBzwLuSfDbJtUkeD5xbVccBuuU5g05OsjfJTJKZubm5EcpY+5wakXS6jRLuG4FnA++sqmcB32MZUzBVtb+qpqtqempqaoQyJEnzjRLus8BsVd3ebd9EL+wfSrIFoFueGK1ESdJyDR3uVfUN4IEkT+uadgJ3A4eAPV3bHuCWkSqUJC3bxhHPfzXwviRnAF8F/ojeD4yDSS4H7gdeMeJzSJKWaaRwr6rPAdMDdu0c5XFb4sVUSavBd6hKUoMMd0lqkOHeqEHTQU4RSeuH4S5JDTLcJalBhrskNchwPwXnqCVNKsNdkhpkuEtSgwz3dcIpJml9MdwlqUGGuyQ1yHCXpAYZ7sswf97aeWxJa5XhvkwGuqRJYLhLUoMM9xXg6F7SajPcV8haCvi1VIuk02PkcE+yIclnk3yw2z47ya1J7u2Wm0Yvc/UsNxgNUklrwThG7q8BjvZt7wMOV9UO4HC3LUk6jUYK9yRbgZcC1/Y17wIOdOsHgMtGeY7TaT2MutdDHyWNPnJ/K/B64Ed9bedW1XGAbnnOoBOT7E0yk2Rmbm5uxDIkSf2GDvckLwNOVNWdw5xfVfurarqqpqempoYtQ5I0wMYRzn0+8PIkLwEeCzwxyXuBh5JsqarjSbYAJ8ZRqCRp6YYeuVfVlVW1taq2AbuBj1fVq4BDwJ7usD3ALSNXucY5jy1prVmJ+9yvAV6c5F7gxd22JOk0Gku4V9V/VNXLuvX/qaqdVbWjWz48jufQ+PibhtQ+36EqSQ0y3CWpQYb7GDndIWmtMNwHWCyk+/cb6JLWIsNdkhpkuC/BUkbnjuAlrSWG+zwnQ9q/lyppkhnuktQgw12SGmS4S1KDDHdJapDhPqRJv8A66fVLOjXDXZIaZLhLUoMMd0lqkOEuSQ1a9+HuhUVJLRo63JOcn+QTSY4mOZLkNV372UluTXJvt9w0vnJXjiEvqSWjjNwfBf6qqn4VuBi4IsmFwD7gcFXtAA5325Kk02jocK+q41X1mW79u8BR4DxgF3CgO+wAcNmINUqSlmksc+5JtgHPAm4Hzq2q49D7AQCcM47nWAlOxUhq1cjhnuQJwPuB11bVd5Zx3t4kM0lm5ubmRi1jJIa8pNaMFO5JHkMv2N9XVTd3zQ8l2dLt3wKcGHRuVe2vqumqmp6amhqlDEnSPKPcLRPgOuBoVb2lb9chYE+3vge4ZfjyJEnD2DjCuc8Hfh/4YpLPdW1/C1wDHExyOXA/8IqRKpQkLdvQ4V5V/wVkgd07h31cSdLo1v07VCWpRYa7JDXIcF/HvAVUapfhLkkNMtwlqUGGuyQ1yHCXpAat23D3YqKklq3bcFfPtn0f8ged1CDDXZIaZLhLUoMMdwE/uQbhFI3UBsNdP2bAS+0w3CWpQesy3B2ZLo2vkzS51mW4a3EGuzTZDHdJapDhLkkNGuVvqJ5SkkuBtwEbgGur6pqVeq6lcqpB0nqxIuGeZAPwT8CLgVng00kOVdXdK/F8izHUh3fytfvaNS9d5UokLcdKTctcBByrqq9W1feBG4FdK/RcP2V+kBvs47HQ69jf7mstrR0rFe7nAQ/0bc92bZKk02Cl5twzoK1+6oBkL7C32/zfJPeM8HybgW/++LHfOMIjTYaf6u/pstDr2t++gq/9qvR5ldnn9WGUPv/SQjtWKtxngfP7trcCD/YfUFX7gf3jeLIkM1U1PY7HmgTrrb9gn9cL+zw+KzUt82lgR5LtSc4AdgOHVui5JEnzrMjIvaoeTfLnwL/RuxXy+qo6shLPJUn6WSt2n3tVfRj48Eo9/jxjmd6ZIOutv2Cf1wv7PCapqsWPkiRNFD9+QJIaNNHhnuTSJPckOZZk32rXMy5Jzk/yiSRHkxxJ8pqu/ewktya5t1tu6jvnyu51uCfJJatX/fCSbEjy2SQf7LZb7++TktyU5Evd9/q566DPr+v+Td+V5IYkj22tz0muT3IiyV19bcvuY5LfSPLFbt8/Jhl0i/nCqmoiv+hdqP0K8BTgDODzwIWrXdeY+rYFeHa3/vPAl4ELgTcB+7r2fcAbu/ULu/6fCWzvXpcNq92PIfr9l8C/AB/stlvv7wHgT7r1M4Antdxnem9kvA94XLd9EPjD1voMvAB4NnBXX9uy+wjcATyX3vuGPgL83nLqmOSR+6p9xMFKq6rjVfWZbv27wFF6/zF20QsEuuVl3fou4MaqeqSq7gOO0Xt9JkaSrcBLgWv7mlvu7xPphcB1AFX1/ar6Fg33ubMReFySjcBZ9N7/0lSfq+o24OF5zcvqY5ItwBOr6pPVS/r39J2zJJMc7uviIw6SbAOeBdwOnFtVx6H3AwA4pzushdfircDrgR/1tbXc36cAc8C7uqmoa5M8nob7XFVfB94M3A8cB75dVR+j4T73WW4fz+vW57cv2SSH+6IfcTDpkjwBeD/w2qr6zqkOHdA2Ma9FkpcBJ6rqzqWeMqBtYvrb2UjvV/d3VtWzgO/R+3V9IRPf526eeRe96YcnA49P8qpTnTKgbaL6vAQL9XHkvk9yuC/6EQeTLMlj6AX7+6rq5q75oe7XNbrlia590l+L5wMvT/I1etNrv5PkvbTbX+j1Ybaqbu+2b6IX9i33+UXAfVU1V1U/AG4GnkfbfT5puX2c7dbnty/ZJId7sx9x0F0Vvw44WlVv6dt1CNjTre8Bbulr353kzCTbgR30LsZMhKq6sqq2VtU2et/Hj1fVq2i0vwBV9Q3ggSRP65p2AnfTcJ/pTcdcnOSs7t/4TnrXk1ru80nL6mM3dfPdJBd3r9Uf9J2zNKt9ZXnEq9IvoXcnyVeAN6x2PWPs12/S+xXsC8Dnuq+XAL8AHAbu7ZZn953zhu51uIdlXlVfS1/AC/nJ3TJN9xf4dWCm+z5/ANi0Dvr8d8CXgLuAf6Z3l0hTfQZuoHdN4Qf0RuCXD9NHYLp7nb4CvJ3uTadL/fIdqpLUoEmelpEkLcBwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQf8P8ItMMwKh64cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens_train = [len(inp) for inp in  input_ids_train]\n",
    "plt.hist(lens_train, bins=1000, range=(0,1000))\n",
    "plt.show()\n",
    "lens_test = [len(inp) for inp in  input_ids_test]\n",
    "plt.hist(lens_test, bins=1000, range=(0,1000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3146\n"
     ]
    }
   ],
   "source": [
    "print((np.array(lens_test)<=128).sum()) # / len(lens_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding/truncating all sentences to 128 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Set the maximum sequence length.\n",
    "MAX_LEN = 128\n",
    "\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# Pad our input tokens with value 0.\n",
    "input_ids_train = pad_sequences(input_ids_train, maxlen=MAX_LEN)\n",
    "input_ids_test = pad_sequences(input_ids_test, maxlen=MAX_LEN)\n",
    "\n",
    "print('\\nDone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks_train = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids_train:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks_train.append(att_mask)\n",
    "    \n",
    "# Create attention masks\n",
    "attention_masks_test = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids_test:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks_test.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = input_ids_train, input_ids_test, labels_train, labels_test \n",
    "train_masks, validation_masks = attention_masks_train, attention_masks_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset & dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all inputs and labels into torch tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14573, 128])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model & optimiser & scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 2\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, \n",
    "                                            num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return (pred_flat == labels_flat).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.50\n",
      "  Validation took: 0:00:41\n"
     ]
    }
   ],
   "source": [
    "# evaluation only - to make sure that accuracy is more or less random at the beginnig\n",
    "print(\"\")\n",
    "print(\"Running Validation...\")\n",
    "device = \"cuda\"\n",
    "t0 = time.time()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for batch in validation_dataloader:\n",
    "\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "    # values prior to applying an activation function like the softmax.\n",
    "    logits = outputs[0]\n",
    "    \n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences.\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Accumulate the total accuracy.\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    # Track the number of batches\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "# Report the final accuracy for this validation run.\n",
    "print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of    456.    Elapsed: 0:00:11.\n",
      "  Batch    80  of    456.    Elapsed: 0:00:22.\n",
      "  Batch   120  of    456.    Elapsed: 0:00:33.\n",
      "  Batch   160  of    456.    Elapsed: 0:00:44.\n",
      "  Batch   200  of    456.    Elapsed: 0:00:55.\n",
      "  Batch   240  of    456.    Elapsed: 0:01:06.\n",
      "  Batch   280  of    456.    Elapsed: 0:01:17.\n",
      "  Batch   320  of    456.    Elapsed: 0:01:28.\n",
      "  Batch   360  of    456.    Elapsed: 0:01:40.\n",
      "  Batch   400  of    456.    Elapsed: 0:01:51.\n",
      "  Batch   440  of    456.    Elapsed: 0:02:02.\n",
      "\n",
      "  Average training loss: 0.29\n",
      "  Training epcoh took: 0:02:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.9188\n",
      "  Validation took: 0:00:42\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of    456.    Elapsed: 0:00:11.\n",
      "  Batch    80  of    456.    Elapsed: 0:00:22.\n",
      "  Batch   120  of    456.    Elapsed: 0:00:34.\n",
      "  Batch   160  of    456.    Elapsed: 0:00:45.\n",
      "  Batch   200  of    456.    Elapsed: 0:00:57.\n",
      "  Batch   240  of    456.    Elapsed: 0:01:08.\n",
      "  Batch   280  of    456.    Elapsed: 0:01:19.\n",
      "  Batch   320  of    456.    Elapsed: 0:01:30.\n",
      "  Batch   360  of    456.    Elapsed: 0:01:42.\n",
      "  Batch   400  of    456.    Elapsed: 0:01:53.\n",
      "  Batch   440  of    456.    Elapsed: 0:02:04.\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:02:09\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.9186\n",
      "  Validation took: 0:00:42\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "device = \"cuda:0\"\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    print()\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull theloss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0 - This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.4f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), open(data_path+\"e2e_bert.pth\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0319 10:08:26.287150 140144781510400 tokenization_utils.py:374] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/gallil/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0319 10:08:27.398584 140144781510400 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/gallil/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
      "I0319 10:08:27.402496 140144781510400 configuration_utils.py:168] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0319 10:08:28.209434 140144781510400 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/gallil/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    }
   ],
   "source": [
    "# with a saved model & cpu - Load a trained model that you have fine-tuned\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
    "model_loaded = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", state_dict=torch.load(data_path+\"e2e_bert.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "text = 'it was tedious at times but altogether i would recommend it'\n",
    "model_loaded.eval()\n",
    "with torch.no_grad():\n",
    "    sent_token = torch.Tensor(pad_sequences([tokenizer.encode(text, add_special_tokens=True)], 128)).long()\n",
    "    sent_att = (sent_token > 0).int()\n",
    "    res = model_loaded(sent_token, attention_mask=sent_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## infer on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'data/toxic/toxic'\n",
    "model_path = base_path + 'e2e_bert.pth'\n",
    "tst_path = base_path + '_test_clean.csv'\n",
    "out_path = base_path + '_test_pred.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", state_dict=torch.load(model_path))\n",
    "model_loaded.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rad the dataset\n",
    "tst_df = pd.read_csv(tst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallil/anaconda3/envs/test2/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "proba_list = []\n",
    "# evaluation only\n",
    "print(\"\")\n",
    "print(\"Running Validation...\")\n",
    "device = \"cuda\"\n",
    "t0 = time.time()\n",
    "\n",
    "model_loaded.eval()\n",
    "\n",
    "# Tracking variables \n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for batch in validation_dataloader:\n",
    "\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model_loaded(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # Get the \"logits\" output by the model\n",
    "    logits = outputs[0]\n",
    "    \n",
    "    probs, preds = F.softmax(logits).max(1)\n",
    "    \n",
    "    pred_list.append(preds.cpu().numpy())\n",
    "    proba_list.append(probs.cpu().numpy())\n",
    "    \n",
    "tst_df['preds'] = np.concatenate(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmMAAAEvCAYAAAAJusb3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAATBElEQVR4nO3df8yd5X3f8c83OEuZOggEQ5GNarS4awCp6bAoU7UNxZuwknakFZGcaQNFnqwhNmXTfhT6x6pqQgJNWha0JhNKIkxWhVjpD9w2dEPOsuwHhZqWhAClsUoHFih2QkagW5hMvvvjuV09fnhsHzv2cx37vF7S0XPOde77+Dq6eOw397nPOdXdAQBgjLeNngAAwCITYwAAA4kxAICBxBgAwEBiDABgIDEGADDQutETOFWXXHJJb9q0afQ0AABO6IknnvhWd69f7b6zNsY2bdqUffv2jZ4GAMAJVdX/OtZ9XqYEABhIjAEADCTGAAAGEmMAAAOJMQCAgcQYAMBAYgwAYCAxBgAwkBgDABhIjAEADCTGAAAGOmu/mxIA4FRtuuN3/vz6n979gYEzcWQMAGAoMQYAMJAYAwAYSIwBAAwkxgAABhJjAAADiTEAgIHEGADAQGIMAGAgMQYAMJAYAwAYSIwBAAwkxgAABhJjAAADiTEAgIHEGADAQGIMAGAgMQYAMJAYAwAYSIwBAAwkxgAABhJjAAADiTEAgIHEGADAQGIMAGAgMQYAMJAYAwAYSIwBAAwkxgAABhJjAAADzRxjVXVeVf1hVf32dPviqnqkqr4x/bxo2bZ3VtX+qnquqm5cNn5tVT013XdvVdU0/o6q+vw0/lhVbTp9TxEAYH6dzJGxjyZ5dtntO5Ls7e7NSfZOt1NVVyXZnuTqJNuSfKKqzpv2+WSSnUk2T5dt0/iOJN/p7ncn+ViSe07p2QAAnGVmirGq2pjkA0k+tWz4piS7puu7knxw2fiD3f1Gdz+fZH+S66rq8iQXdPej3d1JHlixz5HH+kKSrUeOmgEAnMtmPTL275L8yyTfXzZ2WXe/nCTTz0un8Q1JXly23YFpbMN0feX4Uft09+EkryZ518pJVNXOqtpXVfsOHTo049QBAObXCWOsqn4mycHufmLGx1ztiFYfZ/x4+xw90H1fd2/p7i3r16+fcToAAPNr3Qzb/HSSv1NV70/yQ0kuqKr/mOSbVXV5d788vQR5cNr+QJIrlu2/MclL0/jGVcaX73OgqtYluTDJK6f4nAAAzhonPDLW3Xd298bu3pSlE/O/1N1/L8meJLdOm92a5KHp+p4k26d3SF6ZpRP1H59eynytqq6fzge7ZcU+Rx7r5unPeMuRMQCAc80sR8aO5e4ku6tqR5IXknwoSbr76araneSZJIeT3N7db0773Jbk/iTnJ3l4uiTJp5N8tqr2Z+mI2PYfYF4AAGeNk4qx7v5yki9P17+dZOsxtrsryV2rjO9Lcs0q49/LFHMAAIvEJ/ADAAwkxgAABhJjAAADiTEAgIHEGADAQGIMAGAgMQYAMJAYAwAYSIwBAAwkxgAABhJjAAADiTEAgIHEGADAQGIMAGAgMQYAMJAYAwAYSIwBAAwkxgAABhJjAAADiTEAgIHEGADAQGIMAGAgMQYAMJAYAwAYSIwBAAwkxgAABhJjAAADiTEAgIHEGADAQGIMAGAgMQYAMJAYAwAYSIwBAAwkxgAABhJjAAADiTEAgIHEGADAQGIMAGAgMQYAMJAYAwAYSIwBAAwkxgAABhJjAAADiTEAgIHEGADAQGIMAGAgMQYAMNAJY6yqfqiqHq+qr1bV01X1y9P4xVX1SFV9Y/p50bJ97qyq/VX1XFXduGz82qp6arrv3qqqafwdVfX5afyxqtp0+p8qAMD8meXI2BtJ3tfdP5HkvUm2VdX1Se5Isre7NyfZO91OVV2VZHuSq5NsS/KJqjpveqxPJtmZZPN02TaN70jyne5+d5KPJbnnNDw3AIC5d8IY6yWvTzffPl06yU1Jdk3ju5J8cLp+U5IHu/uN7n4+yf4k11XV5Uku6O5Hu7uTPLBinyOP9YUkW48cNQMAOJfNdM5YVZ1XVU8mOZjkke5+LMll3f1ykkw/L50235DkxWW7H5jGNkzXV44ftU93H07yapJ3ncoTAgA4m8wUY939Zne/N8nGLB3luuY4m692RKuPM368fY5+4KqdVbWvqvYdOnToRNMGAJh7J/Vuyu7+30m+nKVzvb45vfSY6efBabMDSa5YttvGJC9N4xtXGT9qn6pal+TCJK+s8uff191bunvL+vXrT2bqAABzaZZ3U66vqndO189P8reS/FGSPUlunTa7NclD0/U9SbZP75C8Mksn6j8+vZT5WlVdP50PdsuKfY481s1JvjSdVwYAcE5bN8M2lyfZNb0j8m1Jdnf3b1fVo0l2V9WOJC8k+VCSdPfTVbU7yTNJDie5vbvfnB7rtiT3Jzk/ycPTJUk+neSzVbU/S0fEtp+OJwcAMO9OGGPd/bUkP7nK+LeTbD3GPncluWuV8X1J3nK+WXd/L1PMAQAsEp/ADwAwkBgDABhIjAEADCTGAAAGEmMAAAOJMQCAgcQYAMBAYgwAYCAxBgAwkBgDABhIjAEADCTGAAAGEmMAAAOJMQCAgcQYAMBAYgwAYCAxBgAwkBgDABhIjAEADCTGAAAGEmMAAAOJMQCAgcQYAMBAYgwAYCAxBgAwkBgDABhIjAEADCTGAAAGEmMAAAOJMQCAgcQYAMBAYgwAYCAxBgAwkBgDABhIjAEADCTGAAAGEmMAAAOJMQCAgcQYAMBAYgwAYCAxBgAwkBgDABhIjAEADCTGAAAGEmMAAAOJMQCAgcQYAMBAJ4yxqrqiqv5LVT1bVU9X1Uen8Yur6pGq+sb086Jl+9xZVfur6rmqunHZ+LVV9dR0371VVdP4O6rq89P4Y1W16fQ/VQCA+TPLkbHDSf5Zd78nyfVJbq+qq5LckWRvd29Osne6nem+7UmuTrItySeq6rzpsT6ZZGeSzdNl2zS+I8l3uvvdST6W5J7T8NwAAObeCWOsu1/u7j+Yrr+W5NkkG5LclGTXtNmuJB+crt+U5MHufqO7n0+yP8l1VXV5kgu6+9Hu7iQPrNjnyGN9IcnWI0fNAADOZSd1ztj08uFPJnksyWXd/XKyFGxJLp0225DkxWW7HZjGNkzXV44ftU93H07yapJ3nczcAADORjPHWFX9cJJfS/JPuvu7x9t0lbE+zvjx9lk5h51Vta+q9h06dOhEUwYAmHszxVhVvT1LIfar3f3r0/A3p5ceM/08OI0fSHLFst03JnlpGt+4yvhR+1TVuiQXJnll5Ty6+77u3tLdW9avXz/L1AEA5tos76asJJ9O8mx3/9tld+1Jcut0/dYkDy0b3z69Q/LKLJ2o//j0UuZrVXX99Ji3rNjnyGPdnORL03llAADntHUzbPPTSf5+kqeq6slp7BeT3J1kd1XtSPJCkg8lSXc/XVW7kzyTpXdi3t7db0773Zbk/iTnJ3l4uiRLsffZqtqfpSNi23/A5wUAcFY4YYx193/P6ud0JcnWY+xzV5K7Vhnfl+SaVca/lynmAAAWiU/gBwAYSIwBAAwkxgAABhJjAAADiTEAgIHEGADAQGIMAGAgMQYAMJAYAwAYSIwBAAwkxgAABhJjAAADiTEAgIHEGADAQGIMAGAgMQYAMJAYAwAYSIwBAAwkxgAABhJjAAADiTEAgIHEGADAQGIMAGAgMQYAMJAYAwAYSIwBAAwkxgAABhJjAAADiTEAgIHEGADAQGIMAGAgMQYAMJAYAwAYSIwBAAwkxgAABhJjAAADiTEAgIHEGADAQGIMAGAgMQYAMJAYAwAYSIwBAAwkxgAABhJjAAADiTEAgIHEGADAQGIMAGCgE8ZYVX2mqg5W1deXjV1cVY9U1Temnxctu+/OqtpfVc9V1Y3Lxq+tqqem++6tqprG31FVn5/GH6uqTaf3KQIAzK9Zjozdn2TbirE7kuzt7s1J9k63U1VXJdme5Oppn09U1XnTPp9MsjPJ5uly5DF3JPlOd787yceS3HOqTwYA4Gxzwhjr7q8keWXF8E1Jdk3XdyX54LLxB7v7je5+Psn+JNdV1eVJLujuR7u7kzywYp8jj/WFJFuPHDUDADjXneo5Y5d198tJMv28dBrfkOTFZdsdmMY2TNdXjh+1T3cfTvJqkned4rwAAM4qp/sE/tWOaPVxxo+3z1sfvGpnVe2rqn2HDh06xSkCAMyPU42xb04vPWb6eXAaP5DkimXbbUzy0jS+cZXxo/apqnVJLsxbXxZNknT3fd29pbu3rF+//hSnDgAwP041xvYkuXW6fmuSh5aNb5/eIXlllk7Uf3x6KfO1qrp+Oh/slhX7HHmsm5N8aTqvDADgnLfuRBtU1eeS3JDkkqo6kOSXktydZHdV7UjyQpIPJUl3P11Vu5M8k+Rwktu7+83poW7L0jszz0/y8HRJkk8n+WxV7c/SEbHtp+WZAQCcBU4YY9394WPctfUY29+V5K5VxvcluWaV8e9lijkAgEXjE/gBAAYSYwAAA4kxAICBxBgAwEBiDABgIDEGADCQGAMAGEiMAQAMJMYAAAYSYwAAA4kxAICBxBgAwEBiDABgIDEGADCQGAMAGEiMAQAMJMYAAAYSYwAAA4kxAICBxBgAwEBiDABgIDEGADCQGAMAGEiMAQAMJMYAAAYSYwAAA4kxAICBxBgAwEBiDABgIDEGADCQGAMAGEiMAQAMJMYAAAYSYwAAA4kxAICBxBgAwEBiDABgIDEGADCQGAMAGEiMAQAMJMYAAAZaN3oCAABrZdMdvzN6Cm/hyBgAwEBiDABgIDEGADCQc8YAgHPaPJ4ntpwjYwAAA83NkbGq2pbk40nOS/Kp7r578JQAgLPYvB8RO2IuYqyqzkvyK0n+dpIDSX6/qvZ09zNjZwYAzLuzJbqOZS5iLMl1SfZ3958kSVU9mOSmJGIMAM5hZ3tInQ7zEmMbkry47PaBJD81aC4AnAWO/CP+p3d/YKbtZrX88YQCa2FeYqxWGeu3bFS1M8nO6ebrVfXcGZ1VckmSb53hP4OTZ13mjzWZTwuxLnXPfD/eCguxJmebumdN1uVHj3XHvMTYgSRXLLu9MclLKzfq7vuS3LdWk6qqfd29Za3+PGZjXeaPNZlP1mX+WJP5NHpd5uWjLX4/yeaqurKq/kKS7Un2DJ4TAMAZNxdHxrr7cFX9oyT/KUsfbfGZ7n568LQAAM64uYixJOnuLyb54uh5rLBmL4lyUqzL/LEm88m6zB9rMp+Grkt1v+U8eQAA1si8nDMGALCQxFiWvoqpqp6rqv1Vdccq999QVa9W1ZPT5V+NmOeiOdG6TNvcMK3J01X1X9d6jotmht+Vf7Hs9+TrVfVmVV08Yq6LYoY1ubCqfquqvjr9nnxkxDwXzQzrclFV/UZVfa2qHq+qa0bMc5FU1Weq6mBVff0Y91dV3Tut2deq6q+u2dwW/WXK6auY/jjLvoopyYeXfxVTVd2Q5J93988MmeQCmnFd3pnkfybZ1t0vVNWl3X1wyIQXwCxrsmL7n03yT7v7fWs3y8Uy4+/JLya5sLt/oarWJ3kuyY909/8bMedFMOO6/Jskr3f3L1fVjyf5le7eOmTCC6Kq/kaS15M80N1vid+qen+Sf5zk/Vn64PmPd/eafAC9I2PLvopp+svpyFcxMdYs6/J3k/x6d7+QJELsjDvZ35UPJ/ncmsxscc2yJp3kL1VVJfnhJK8kOby201w4s6zLVUn2Jkl3/1GSTVV12dpOc7F091ey9N//sdyUpVDr7v69JO+sqsvXYm5ibPWvYtqwynZ/bTrM/3BVXb02U1tos6zLjyW5qKq+XFVPVNUtaza7xTTr70qq6i8m2Zbk19ZgXotsljX590nek6UP0n4qyUe7+/trM72FNcu6fDXJzydJVV2XpU9n37gms+NYZv477nSbm4+2GGiWr2L6gyQ/2t2vT4cxfzPJ5jM+s8U2y7qsS3Jtkq1Jzk/yaFX9Xnf/8Zme3IKa6WvLJj+b5H909/H+L5Qf3CxrcmOSJ5O8L8lfTvJIVf237v7umZ7cAptlXe5O8vGqejJLkfyHccRytJP5O+60cmRshq9i6u7vdvfr0/UvJnl7VV2ydlNcSLN8RdaBJL/b3X/W3d9K8pUkP7FG81tEM31t2WR7vES5FmZZk49k6eX87u79SZ5P8uNrNL9FNeu/Kx/p7vcmuSXJ+iytDeOczN9xp5UYm+GrmKrqR6bzLY4cTn5bkm+v+UwXyyxfkfVQkr9eVeuml8V+KsmzazzPRTLT15ZV1YVJ/maW1ocza5Y1eSFLR48znZP0V5L8yZrOcvHM8u/KO6f7kuQfJPmKo5XD7Ulyy/SuyuuTvNrdL6/FH7zwL1Me66uYquofTvf/hyQ3J7mtqg4n+b9Jtveivw31DJtlXbr72ar63SRfS/L9JJ/q7lXfsswPbsbflST5uST/ubv/bNBUF8aMa/Kvk9xfVU9l6WWYX5iOJHOGzLgu70nyQFW9meSZJDuGTXhBVNXnktyQ5JKqOpDkl5K8PfnzNflilt5JuT/J/8nSUeW1mZumAAAYx8uUAAADiTEAgIHEGADAQGIMAGAgMQYAMJAYAwAYSIwBAAwkxgAABvr/5ST+epfRss0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# look at distibution of probabilities\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(np.concatenate(proba_list), bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9129989764585466"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure of accuracy and no mistakes\n",
    "(tst_df['preds']==tst_df['label']).sum()/len(tst_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result\n",
    "tst_df.to_csv(out_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test2",
   "language": "python",
   "name": "test2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
