base_path: '../../data/aclImdb/imdb'   # the base path for the data, model, results, etc.
ATTACKED_INDICES: '[8, 13, 17, 35, 83, 103, 111, 129, 182, 184, 189, 221, 232, 237, 255, 264, 297, 328, 336, 338, 345, 356, 363, 430, 435, 436, 472, 473, 474, 477, 488, 489, 493, 521, 527, 537, 549, 589, 608, 610, 634, 642, 656, 669, 723, 740, 743, 761, 766, 768, 786, 794, 805, 812, 813, 832, 844, 861, 887, 889, 923, 961, 963, 982, 986, 992, 1024, 1050, 1068, 1077, 1086, 1090, 1129, 1145, 1158, 1167, 1175, 1226, 1235, 1242, 1261, 1269, 1311, 1318, 1342, 1351, 1363, 1369, 1392, 1430, 1443, 1447, 1454, 1466, 1468, 1473, 1488, 1508, 1509, 1515, 1520, 1604, 1622, 1626, 1630, 1632, 1647, 1663, 1672, 1684, 1698, 1706, 1721, 1731, 1739, 1747, 1769, 1794, 1823, 1825, 1872, 1884, 1900, 1901, 1902, 1917, 1938, 1941, 1948, 1950, 1955, 1967, 1971, 1976, 2005, 2009, 2013, 2038, 2041, 2042, 2045, 2088, 2093, 2098, 2099, 2101, 2108, 2122, 2134, 2145, 2190, 2197, 2198, 2222, 2226, 2238, 2259, 2272, 2283, 2284, 2303, 2310, 2316, 2326, 2346, 2372, 2373, 2375, 2378, 2404, 2410, 2431, 2460, 2469, 2542, 2551, 2558, 2561, 2564, 2568, 2592, 2604, 2611, 2621, 2623, 2626, 2636, 2645, 2665, 2670, 2700, 2713, 2724, 2733, 2752, 2756, 2773, 2819, 2842, 2843, 2852, 2854, 2890, 2891, 2896, 2901, 2906, 2911, 2920, 2921, 2925, 2977, 2989, 2994, 3027, 3031, 3052, 3069, 3086, 3117, 3136, 3151, 3159, 3174, 3180, 3213, 3220, 3225, 3228, 3237, 3243, 3249, 3252, 3260, 3263, 3270, 3283, 3285, 3286, 3288, 3291, 3301, 3302, 3308, 3309, 3311, 3312, 3316, 3323, 3324, 3326, 3329, 3330, 3333, 3335, 3336, 3341, 3343, 3344, 3345, 3351, 3352, 3353, 3355, 3356, 3358, 3359, 3368, 3371, 3373, 3374, 3377, 3378, 3388, 3392, 3394, 3397, 3402, 3403, 3404, 3405, 3406, 3408, 3413, 3421, 3422, 3427, 3429, 3436, 3438, 3440, 3441, 3448, 3451, 3453, 3458, 3462, 3470, 3478, 3485, 3486, 3491, 3492, 3505, 3507, 3511, 3517, 3518, 3522, 3523, 3525, 3527, 3528, 3533, 3536, 3537, 3543, 3544, 3551, 3555, 3560, 3564, 3567, 3572, 3573, 3574, 3584, 3588, 3589, 3590, 3592, 3595, 3596, 3597, 3598, 3601, 3603, 3616, 3617, 3622, 3629, 3636, 3641, 3648, 3649, 3651, 3661, 3666, 3667, 3670, 3672, 3676, 3677, 3679, 3680, 3683, 3686, 3689, 3690, 3691, 3694, 3696, 3702, 3705, 3706, 3708, 3710, 3711, 3712, 3713, 3714, 3715, 3717, 3720, 3724, 3725, 3727, 3733, 3740]'  # a string describing list of the indices of the dataset to attack, can be 'range(i,j)', or '[i, j, k, m, ...]'
ENV_TYPE: 'Synonym'  # Environment type - from ['Synonym', 'SynonymDelete', 'SynonymMisspell']
USE_PPL: False  # boolean of whether to use perplexity (using GPT-2) to select more natural synonyms and integrate this for the reward
ATTACK_TYPE: 'test'  # attack each text individually or by learning all text together or by testing a pre-trained agent - from ['individual', 'universal', 'test']
NUM_CLASSES: 2  # Number of classes, 3 for MNLI and 2 otherwise
SEED: 42  # the random seed
DEVICE: 'cuda'  # which device to use
AGENT_TYPE: 'dqn_contin'  # agent used to attack ['dqn', 'dqn_contin']
MEMORY_SIZE: 15000  # the number of transition tuples to store in the DQN agent's memory
MODEL_TYPE: 'bert'  # attacked model type: BERT, or Word-LSTM ['bert', 'lstm']
BATCH_SIZE: 128  # number of transitions to sample for training the agent at each step
NUM_EPISODES: 1  # number of episodes to "play" for each text if attacking individually, or in test mode, or total number of rounds for universal attacks
EARLY_STOPPING: 100000000000000  # the reward above which the attack stops, set to above 200 for no early stopping. when aiming for any attack, and not necessarily the best this speeds things up
MAX_SENT_LEN: 150  # the maximum text length, which influences the number of actions. ignored if attacking individually
POLICY_UPDATE: 10000000  # every how many agent steps to update the policy network
TARGET_UPDATE: 7500000  # every how many agent episodes to update the target network
GAMMA: 0.995  # the decay parameter for the A3C loss
EPS_START: 0.0  # the initial epsilon for epsilon-greedy exploration
EPS_END: 0.0  # the minimal epsilon for epsilon-greedy exploration
EPS_DECAY: 22500  # the decay parameter for epsilon according to the equation: EPS_END + (EPS_START - EPS_END) * exp(-1. * steps_done / EPS_DECAY)
MAX_TURNS: 30000000  # max number of turns the agent gets in each round
STATE_SHAPE: 768  # the size of the agent state representation
LEARNING_RATE: 0.00005  # the learning rate for the DQN agent
NORMALISE_ROUNDS: -1  # number of samples to see for state normalising parameters, -1 means no normalising, 'offline' means offline normalising (which is not supported for individual attacks)
HANDLE_OUT: 'save'  # what to do with results from ['save', 'plot'], if to save to csv or plot and show reward graph. If something else the results aren't logged in any way
MEM_TYPE:  'regular'  # one of ['priority', 'regular'] if using 'priority' a priority replay buffer is used