{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "f = open('log2.txt', 'w')\n",
    "sys.stdout = f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_val = 42\n",
    "device = \"cuda:0\"\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/mnli2/mnli\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path+\"_train_clean.csv\")\n",
    "df_train, df_validation = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(data_path+\"_test_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# used for 2 text tasks like NLI\n",
    "if \"content2\" in df_train.columns:\n",
    "    df_train[\"content\"] = list(zip(df_train.content, df_train.content2))\n",
    "    df_train = df_train.drop(\"content2\", 1)\n",
    "    df_validation[\"content\"] = list(zip(df_validation.content, df_validation.content2))\n",
    "    df_validation = df_validation.drop(\"content2\", 1)\n",
    "    df_test[\"content\"] = list(zip(df_test.content, df_test.content2))\n",
    "    df_test = df_test.drop(\"content2\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lists of sentences and their labels.\n",
    "sentences_train = df_train.content.values\n",
    "labels_train = df_train.label.values\n",
    "\n",
    "sentences_validation = df_validation.content.values\n",
    "labels_validation = df_validation.label.values\n",
    "\n",
    "sentences_test = df_test.content.values\n",
    "labels_test = df_test.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tokenising & formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids_train = []\n",
    "\n",
    "# For every sentence in train\n",
    "for sent in sentences_train:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        *sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_train.append(encoded_sent)\n",
    "print(\"Train done!\")\n",
    "    \n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids_validation = []\n",
    "\n",
    "# For every sentence in test\n",
    "for sent in sentences_validation:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        *sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_validation.append(encoded_sent)\n",
    "print(\"Validation done!\")\n",
    "    \n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids_test = []\n",
    "\n",
    "# For every sentence in test\n",
    "for sent in sentences_test:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        *sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_test.append(encoded_sent)\n",
    "print(\"Test done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(input_ids, maxlen):\n",
    "    padded = []\n",
    "    for inp in input_ids:\n",
    "        if len(inp) >= maxlen:\n",
    "            padded.append(inp[:maxlen-1] + [inp[-1]])\n",
    "        else:\n",
    "            padded.append(inp + [0]*(maxlen - len(inp)))\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### histogram of length for choosing the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens_train = [len(inp) for inp in  input_ids_train]\n",
    "plt.hist(lens_train, bins=1000, range=(0,1000))\n",
    "plt.show()\n",
    "lens_validation = [len(inp) for inp in  input_ids_validation]\n",
    "plt.hist(lens_validation, bins=1000, range=(0,1000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((np.array(lens_train)<=256).sum()/ len(lens_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum sequence length.\n",
    "MAX_LEN = 256\n",
    "\n",
    "print('Padding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "print('Padding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# Pad our input tokens with value 0.\n",
    "input_ids_train = pad_sequences(input_ids_train, maxlen=MAX_LEN)\n",
    "input_ids_validation = pad_sequences(input_ids_validation, maxlen=MAX_LEN)\n",
    "input_ids_test = pad_sequences(input_ids_test, maxlen=MAX_LEN)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks_train = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids_train:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks_train.append(att_mask)\n",
    "    \n",
    "# Create attention masks\n",
    "attention_masks_validation = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids_validation:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks_validation.append(att_mask)\n",
    "\n",
    "    \n",
    "attention_masks_test = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids_test:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks_test.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename\n",
    "train_inputs, validation_inputs, test_inputs, train_labels, validation_labels, test_labels = input_ids_train, input_ids_validation, input_ids_test, labels_train, labels_validation, labels_test\n",
    "train_masks, validation_masks, test_masks = attention_masks_train, attention_masks_validation, attention_masks_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset & dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all inputs and labels into torch tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "test_masks = torch.tensor(test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([353059, 256])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model & optimiser & scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_LABELS = 3  # 3 for MNLI, 2 for IMDB, Toxic-WIKI, PUBMED\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = NUM_LABELS,\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 4  # 2 for text classification, 4 for MNLI \n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, \n",
    "                                            num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return (pred_flat == labels_flat).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation only - to make sure that accuracy is more or less random at the beginnig\n",
    "print(\"\")\n",
    "print(\"Running Validation...\")\n",
    "device = \"cuda\"\n",
    "t0 = time.time()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for batch in validation_dataloader:\n",
    "\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "    # values prior to applying an activation function like the softmax.\n",
    "    logits = outputs[0]\n",
    "    \n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences.\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Accumulate the total accuracy.\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    # Track the number of batches\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "# Report the final accuracy for this validation run.\n",
    "print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    print()\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 200 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull theloss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0 - This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.4f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), open(data_path+\"_bert.pth\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with a saved model & cpu - Load a trained model that you have fine-tuned\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
    "model_loaded = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", state_dict=torch.load(data_path+\"_bert.pth\"), num_labels=NUM_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "text = ('it was tedious movie at times but altogether i would recommend it', 'the movie is unrecommended')\n",
    "model_loaded.eval()\n",
    "with torch.no_grad():\n",
    "    if type(text) == tuple:\n",
    "        sent_token = torch.Tensor(pad_sequences([tokenizer.encode(*text, add_special_tokens=True)], 128)).long()\n",
    "    else:\n",
    "        sent_token = torch.Tensor(pad_sequences([tokenizer.encode(text, add_special_tokens=True)], 128)).long()\n",
    "    sent_att = (sent_token > 0).int()\n",
    "    res = model_loaded(sent_token, attention_mask=sent_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.2395, -1.3262,  4.2226]]),)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## infer on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'data/mnli2/mnli'\n",
    "model_path = base_path + '_bert.pth'\n",
    "tst_path = base_path + '_test_clean.csv'\n",
    "out_path = base_path + '_test_pred_bert.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_LABELS = 3\n",
    "model_loaded = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", state_dict=torch.load(model_path), num_labels=NUM_LABELS)\n",
    "model_loaded.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "tst_df = pd.read_csv(tst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "proba_list = []\n",
    "raw_out = []\n",
    "# evaluation only\n",
    "print(\"\")\n",
    "print(\"Running Test...\")\n",
    "device = \"cuda\"\n",
    "t0 = time.time()\n",
    "\n",
    "model_loaded.eval()\n",
    "\n",
    "# Tracking variables \n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for batch in test_dataloader:\n",
    "\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model_loaded(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # Get the \"logits\" output by the model\n",
    "    logits = outputs[0]\n",
    "    \n",
    "    raw_out.append(logits.cpu().numpy())\n",
    "    \n",
    "    probs, preds = F.softmax(logits).max(1)\n",
    "    \n",
    "    pred_list.append(preds.cpu().numpy())\n",
    "    proba_list.append(probs.cpu().numpy())\n",
    "    \n",
    "tst_df['preds'] = np.concatenate(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# look at distibution of probabilities\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(np.concatenate(proba_list), bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df[\"preds\"] = np.concatenate(code_preds).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8372"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure of accuracy and no mistakes\n",
    "(tst_df['preds']==tst_df['label']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result\n",
    "tst_df.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### infernce with other code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import src.TextModels.Bert as Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.TextModels.E2EBert' from '/home/gallil/Desktop/projects/LUNATC/src/TextModels/E2EBert.py'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(Bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for 2 text tasks like NLI\n",
    "if \"content2\" in tst_df.columns:\n",
    "    tst_df[\"content\"] = list(zip(tst_df.content, tst_df.content2))\n",
    "    tst_df = tst_df.drop(\"content2\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_model = Bert.BertTextModel(num_classes=3, trained_model=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "code_model.predict_proba(32*['amazing film !'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield ndx, iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code_preds = []\n",
    "# for i, text in enumerate(tst_df.content):\n",
    "#     print(f'\\r{i/len(tst_df)}', end='')\n",
    "#     code_preds.append(code_model.predict_proba(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9984"
     ]
    }
   ],
   "source": [
    "code_preds = []\n",
    "for i, text in batch(tst_df.content.values.tolist(), 64):\n",
    "    print(f'\\r{i/len(tst_df)}', end='')\n",
    "    if type(text[0]) == tuple:\n",
    "        text = tuple(zip(*text))\n",
    "    code_preds.append(code_model.predict_proba(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.abs((np.concatenate(code_preds) - np.concatenate(raw_out))) > 0.0001).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8372"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.concatenate(code_preds).argmax(1) == tst_df.label).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(on the basis of engineering estimates , the e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(tuppence was first at the rendezvous ., no on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(the discount shopping centers here rival thos...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(right inexperience also that's something that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(we shall be pinched at first , of course , be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>(do you watch that ?, can you see ?)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>(to a western ear , the most predictable of la...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>(the recorder captured the sounds of loud thum...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99989</th>\n",
       "      <td>(that's a good attitude !, you feel good about...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99990</th>\n",
       "      <td>(bloomer ( for `flower '), butter ( for `ram '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99991 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  label\n",
       "0      (on the basis of engineering estimates , the e...      1\n",
       "1      (tuppence was first at the rendezvous ., no on...      0\n",
       "2      (the discount shopping centers here rival thos...      2\n",
       "3      (right inexperience also that's something that...      0\n",
       "4      (we shall be pinched at first , of course , be...      1\n",
       "...                                                  ...    ...\n",
       "99986               (do you watch that ?, can you see ?)      2\n",
       "99987  (to a western ear , the most predictable of la...      2\n",
       "99988  (the recorder captured the sounds of loud thum...      2\n",
       "99989  (that's a good attitude !, you feel good about...      1\n",
       "99990  (bloomer ( for `flower '), butter ( for `ram '...      0\n",
       "\n",
       "[99991 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8368707690741589"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.concatenate(code_preds).argmax(1) == tst_df.label).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348857331908179"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.concatenate(code_preds).argmax(1) == tst_df.label).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gallilm2",
   "language": "python",
   "name": "gallilm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
