{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# f = open('log.txt', 'w')\n",
    "# sys.stdout = f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_val = 42\n",
    "device = \"cuda:0\"\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/mnli/mnli\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path+\"_train_clean.csv\")\n",
    "df_train, df_validation = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(data_path+\"_test_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# used for 2 text tasks like NLI\n",
    "if \"content2\" in df_train.columns:\n",
    "    df_train[\"content\"] = list(zip(df_train.content, df_train.content2))\n",
    "    df_train = df_train.drop(\"content2\", 1)\n",
    "    df_validation[\"content\"] = list(zip(df_validation.content, df_validation.content2))\n",
    "    df_validation = df_validation.drop(\"content2\", 1)\n",
    "    df_test[\"content\"] = list(zip(df_test.content, df_test.content2))\n",
    "    df_test = df_test.drop(\"content2\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lists of sentences and their labels.\n",
    "sentences_train = df_train.content.values\n",
    "labels_train = df_train.label.values\n",
    "\n",
    "sentences_validation = df_validation.content.values\n",
    "labels_validation = df_validation.label.values\n",
    "\n",
    "sentences_test = df_test.content.values\n",
    "labels_test = df_test.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tokenising & formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids_train = []\n",
    "\n",
    "# For every sentence in train\n",
    "for sent in sentences_train:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        *sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_train.append(encoded_sent)\n",
    "print(\"Train done!\")\n",
    "    \n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids_validation = []\n",
    "\n",
    "# For every sentence in test\n",
    "for sent in sentences_validation:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        *sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_validation.append(encoded_sent)\n",
    "print(\"Validation done!\")\n",
    "    \n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids_test = []\n",
    "\n",
    "# For every sentence in test\n",
    "for sent in sentences_test:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        *sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_test.append(encoded_sent)\n",
    "print(\"Test done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(input_ids, maxlen):\n",
    "    padded = []\n",
    "    for inp in input_ids:\n",
    "        if len(inp) >= maxlen:\n",
    "            padded.append(inp[:maxlen-1] + [inp[-1]])\n",
    "        else:\n",
    "            padded.append(inp + [0]*(maxlen - len(inp)))\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### histogram of length for choosing the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVKklEQVR4nO3dYYxdZ33n8e+vNgQDtXDKJEpnrLWRLHadSAQyypqyqroYNm6pcF5sJFei8a5SeRWlu9BdqbK3L1BfWMquqqob7SaSBTTOlmK5FDYWKCyWW1StFCVMIG3iBK8NpvHUaTylonhbyZD0vy/uQ3s1uZ65EzvXmXm+H+nqnPM/z3PvecbJb+4859x7UlVIkvrwE9f6ACRJk2PoS1JHDH1J6oihL0kdMfQlqSPrr/UBLOed73xnbdmy5VofhiStKk899dRfVdXU4vobPvS3bNnC3NzctT4MSVpVkvz5qLrTO5LUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDH9iy/8vX+hAkaSIMfUnqiKEvSR0x9CWpI4a+JHWk+9D3JK6knnQf+pLUE0Nfkjpi6EtSR8YK/SS/luRkkmeTfC7JW5Jcn+R4ktNtuWmo/YEkZ5KcSnLHUP22JM+0fQ8kyesxKEnSaMuGfpJp4D8As1V1C7AO2APsB05U1TbgRNsmyfa2/2ZgF/BgknXt6R4C9gHb2mPXVR2NJGlJ407vrAc2JFkPvBU4D+wGDrf9h4E72/pu4EhVXaqqs8AZ4PYkNwEbq+rxqirgkaE+18TwlTtexSOpB8uGflX9BfBbwAvAi8DfVNVXgRur6sXW5kXghtZlGjg39BTzrTbd1hfXXyXJviRzSeYWFhZWNiJJ0mWNM72zicG7963ATwNvS/KxpbqMqNUS9VcXqw5V1WxVzU5NTS13iJKkMY0zvfMh4GxVLVTVj4AvAD8DvNSmbGjLC639PLB5qP8Mg+mg+ba+uC5JmpBxQv8FYEeSt7arbXYCzwPHgL2tzV7g0bZ+DNiT5LokWxmcsH2yTQFdTLKjPc/dQ30kSROwfrkGVfVEks8D3wBeBr4JHALeDhxNcg+DXwx3tfYnkxwFnmvt76uqV9rT3Qs8DGwAHmsPSdKELBv6AFX1SeCTi8qXGLzrH9X+IHBwRH0OuGWFxyhJukr8RK4kdcTQl6SOGPqS1BFDX5I60m3oj/raBb+KQdJa123oS1KPDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SerIOPfIfXeSp4ceP0jyiSTXJzme5HRbbhrqcyDJmSSnktwxVL8tyTNt3wPtDlqSpAlZNvSr6lRV3VpVtwK3AX8HfBHYD5yoqm3AibZNku3AHuBmYBfwYJJ17ekeAvYxuIXitrZfkjQhK53e2Ql8u6r+HNgNHG71w8CdbX03cKSqLlXVWeAMcHu7efrGqnq8qgp4ZKiPJGkCVhr6e4DPtfUb283OacsbWn0aODfUZ77Vptv64rokaULGDv0kbwY+CvzBck1H1GqJ+qjX2pdkLsncwsLCuId4Vfj1ypLWspW80/954BtV9VLbfqlN2dCWF1p9Htg81G8GON/qMyPqr1JVh6pqtqpmp6amVnCIkqSlrCT0f4l/nNoBOAbsbet7gUeH6nuSXJdkK4MTtk+2KaCLSXa0q3buHuojSZqA9eM0SvJW4MPAvxsq3w8cTXIP8AJwF0BVnUxyFHgOeBm4r6peaX3uBR4GNgCPtcfEOYUjqVdjhX5V/R3wU4tq32NwNc+o9geBgyPqc8AtKz9MSdLV4CdyJakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDP0R/L59SWuVoS9JHRkr9JO8I8nnk3wryfNJ3p/k+iTHk5xuy01D7Q8kOZPkVJI7huq3JXmm7Xug3TZRkjQh477T/2/AV6rqnwLvAZ4H9gMnqmobcKJtk2Q7sAe4GdgFPJhkXXueh4B9DO6bu63tlyRNyLKhn2Qj8LPApwGq6odV9X1gN3C4NTsM3NnWdwNHqupSVZ0FzgC3J7kJ2FhVj1dVAY8M9ZEkTcA47/TfBSwAv5vkm0k+leRtwI1V9SJAW97Q2k8D54b6z7fadFtfXH+VJPuSzCWZW1hYWNGAJEmXN07orwfeBzxUVe8F/pY2lXMZo+bpa4n6q4tVh6pqtqpmp6amxjhESdI4xgn9eWC+qp5o259n8EvgpTZlQ1teGGq/eaj/DHC+1WdG1CVJE7Js6FfVXwLnkry7lXYCzwHHgL2tthd4tK0fA/YkuS7JVgYnbJ9sU0AXk+xoV+3cPdRHkjQB68ds9++BzyZ5M/Ad4N8y+IVxNMk9wAvAXQBVdTLJUQa/GF4G7quqV9rz3As8DGwAHmsPSdKEjBX6VfU0MDti187LtD8IHBxRnwNuWcHxSZKuou4+ketXLEjqWXehL0k9M/QlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFD/zL8Nk5Ja9FYoZ/ku0meSfJ0krlWuz7J8SSn23LTUPsDSc4kOZXkjqH6be15ziR5oN1BS5I0ISt5p/8vq+rWqvrxzVT2Ayeqahtwom2TZDuwB7gZ2AU8mGRd6/MQsI/BLRS3tf2SpAm5kumd3cDhtn4YuHOofqSqLlXVWeAMcHu7efrGqnq8qgp4ZKiPJGkCxg39Ar6a5Kkk+1rtxnazc9ryhlafBs4N9Z1vtem2vrj+Kkn2JZlLMrewsDDmIUqSljPujdE/UFXnk9wAHE/yrSXajpqnryXqry5WHQIOAczOzo5sI0laubHe6VfV+ba8AHwRuB14qU3Z0JYXWvN5YPNQ9xngfKvPjKhLkiZk2dBP8rYkP/njdeBfAc8Cx4C9rdle4NG2fgzYk+S6JFsZnLB9sk0BXUyyo121c/dQH0nSBIwzvXMj8MV2deV64Per6itJvg4cTXIP8AJwF0BVnUxyFHgOeBm4r6peac91L/AwsAF4rD0kSROybOhX1XeA94yofw/YeZk+B4GDI+pzwC0rP0xJ0tXgJ3IlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhv4SvGWipLXG0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6sjYoZ9kXZJvJvlS274+yfEkp9ty01DbA0nOJDmV5I6h+m1Jnmn7Hmh30JIkTchK3ul/HHh+aHs/cKKqtgEn2jZJtgN7gJuBXcCDSda1Pg8B+xjcQnFb2y9JmpCxQj/JDPAR4FND5d3A4bZ+GLhzqH6kqi5V1VngDHB7u3n6xqp6vKoKeGSojyRpAsZ9p/87wK8Dfz9Uu7Hd7Jy2vKHVp4FzQ+3mW226rS+uS5ImZNnQT/KLwIWqemrM5xw1T19L1Ee95r4kc0nmFhYWxnzZ5fkJW0m9G+ed/geAjyb5LnAE+GCS3wNealM2tOWF1n4e2DzUfwY43+ozI+qvUlWHqmq2qmanpqZWMBxJ0lKWDf2qOlBVM1W1hcEJ2j+qqo8Bx4C9rdle4NG2fgzYk+S6JFsZnLB9sk0BXUyyo121c/dQH0nSBFzJdfr3Ax9Ochr4cNumqk4CR4HngK8A91XVK63PvQxOBp8Bvg08dgWvPxFOCUlaS9avpHFVfQ34Wlv/HrDzMu0OAgdH1OeAW1Z6kJKkq8NP5EpSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOjLOjdHfkuTJJH+a5GSS32z165McT3K6LTcN9TmQ5EySU0nuGKrfluSZtu+BdttESdKEjPNO/xLwwap6D3ArsCvJDmA/cKKqtgEn2jZJtjO4l+7NwC7gwSTr2nM9BOxjcN/cbW2/JGlCxrkxelXV/2ubb2qPAnYDh1v9MHBnW98NHKmqS1V1lsH9cG9PchOwsaoer6oCHhnqI0magLHm9JOsS/I0cAE4XlVPADdW1YsAbXlDaz4NnBvqPt9q0219cX3U6+1LMpdkbmFhYQXDkSQtZazQr6pXqupWYIbBu/albm4+ap6+lqiPer1DVTVbVbNTU1PjHKIkaQwrunqnqr4PfI3BXPxLbcqGtrzQms0Dm4e6zQDnW31mRF2SNCHjXL0zleQdbX0D8CHgW8AxYG9rthd4tK0fA/YkuS7JVgYnbJ9sU0AXk+xoV+3cPdTnDW3L/i9f60OQpKti/RhtbgIOtytwfgI4WlVfSvI4cDTJPcALwF0AVXUyyVHgOeBl4L6qeqU9173Aw8AG4LH2kCRNyLKhX1V/Brx3RP17wM7L9DkIHBxRnwOWOh8gSXod+YlcSeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKE/Jr9/R9JaYOhLUkcMfUnqiKEvSR0x9CWpI4a+JHVknDtnbU7yx0meT3Iyycdb/fokx5OcbstNQ30OJDmT5FSSO4bqtyV5pu17oN1BS5I0IeO8038Z+E9V9c+AHcB9SbYD+4ETVbUNONG2afv2ADczuJfug+2uWwAPAfsY3EJxW9svSZqQZUO/ql6sqm+09YvA88A0sBs43JodBu5s67uBI1V1qarOAmeA29vN0zdW1eNVVcAjQ30kSROwojn9JFsY3DrxCeDGdrNz2vKG1mwaODfUbb7Vptv64vqo19mXZC7J3MLCwkoOUZK0hLFDP8nbgT8EPlFVP1iq6YhaLVF/dbHqUFXNVtXs1NTUuIcoSVrGWKGf5E0MAv+zVfWFVn6pTdnQlhdafR7YPNR9Bjjf6jMj6pKkCRnn6p0Anwaer6rfHtp1DNjb1vcCjw7V9yS5LslWBidsn2xTQBeT7GjPefdQn1XB79+RtNqtH6PNB4BfBp5J8nSr/WfgfuBoknuAF4C7AKrqZJKjwHMMrvy5r6peaf3uBR4GNgCPtYckaUKWDf2q+j+Mno8H2HmZPgeBgyPqc8AtKzlASdLV4ydyJakjhr4kdcTQl6SOGPqS1JFuQt/LLSWpo9CXJBn6K+ZfDJJWM0Nfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JFx7pz1mSQXkjw7VLs+yfEkp9ty09C+A0nOJDmV5I6h+m1Jnmn7Hmh3z5IkTdA47/QfBnYtqu0HTlTVNuBE2ybJdmAPcHPr82CSda3PQ8A+BrdP3DbiOVcNP5UrabVaNvSr6k+Av15U3g0cbuuHgTuH6keq6lJVnQXOALe3G6dvrKrHq6qAR4b6SJIm5LXO6d/YbnROW97Q6tPAuaF286023dYX10dKsi/JXJK5hYWF13iIkqTFrvaJ3FHz9LVEfaSqOlRVs1U1OzU1ddUOTpJ691pD/6U2ZUNbXmj1eWDzULsZ4Hyrz4yor1rO60tajV5r6B8D9rb1vcCjQ/U9Sa5LspXBCdsn2xTQxSQ72lU7dw/1kSRNyPrlGiT5HPBzwDuTzAOfBO4Hjia5B3gBuAugqk4mOQo8B7wM3FdVr7SnupfBlUAbgMfaQ5I0QcuGflX90mV27bxM+4PAwRH1OeCWFR2dJOmq8hO5ktQRQ/8KeDJX0mpj6EtSRwx9SeqIoS9JHTH0Jakjhv4V8mSupNXE0Jekjhj6V4Hv9iWtFoa+JHXE0Jekjhj6V4lTPJJWgy5Cf1KBbPBLeqPrIvQlSQOG/lXmu31Jb2SG/uvA4Jf0RjXx0E+yK8mpJGeS7J/060+KwS/pjWjZO2ddTUnWAf8D+DCDm6V/PcmxqnpukscxKYuD/7v3f+QaHYkkDUw09IHbgTNV9R2AJEeA3Qzuqfu6eCO9417qWL57/0fYsv/L//CL4XLrknQlUlWTe7HkXwO7qupX2vYvA/+8qn51Ubt9wL62+W7g1Gt8yXcCf/Ua+65WjrkPvY25t/HClY/5n1TV1OLipN/pZ0TtVb91quoQcOiKXyyZq6rZK32e1cQx96G3Mfc2Xnj9xjzpE7nzwOah7Rng/ISPQZK6NenQ/zqwLcnWJG8G9gDHJnwMktStiU7vVNXLSX4V+N/AOuAzVXXydXzJK54iWoUccx96G3Nv44XXacwTPZErSbq2/ESuJHXE0JekjqzJ0F+rX/WQZHOSP07yfJKTST7e6tcnOZ7kdFtuGupzoP0cTiW549od/ZVJsi7JN5N8qW2v6TEneUeSzyf5Vvv3fv9aHnOSX2v/TT+b5HNJ3rIWx5vkM0kuJHl2qLbicSa5Lckzbd8DSUZdDj9aVa2pB4MTxN8G3gW8GfhTYPu1Pq6rNLabgPe19Z8E/i+wHfivwP5W3w/8l7a+vY3/OmBr+7msu9bjeI1j/4/A7wNfattreszAYeBX2vqbgXes1TED08BZYEPbPgr8m7U4XuBngfcBzw7VVjxO4Eng/Qw++/QY8PPjHsNafKf/D1/1UFU/BH78VQ+rXlW9WFXfaOsXgecZ/A+zm0FI0JZ3tvXdwJGqulRVZ4EzDH4+q0qSGeAjwKeGymt2zEk2MgiHTwNU1Q+r6vus4TEzuJJwQ5L1wFsZfH5nzY23qv4E+OtF5RWNM8lNwMaqerwGvwEeGeqzrLUY+tPAuaHt+VZbU5JsAd4LPAHcWFUvwuAXA3BDa7ZWfha/A/w68PdDtbU85ncBC8DvtimtTyV5G2t0zFX1F8BvAS8ALwJ/U1VfZY2Od4SVjnO6rS+uj2Uthv5YX/WwmiV5O/CHwCeq6gdLNR1RW1U/iyS/CFyoqqfG7TKitqrGzOBd7/uAh6rqvcDfMviz/3JW9ZjbHPZuBlMYPw28LcnHluoyorZqxrsClxvnFY1/LYb+mv6qhyRvYhD4n62qL7TyS+1PPtryQquvhZ/FB4CPJvkug6m6Dyb5Pdb2mOeB+ap6om1/nsEvgbU65g8BZ6tqoap+BHwB+BnW7ngXW+k459v64vpY1mLor9mvemhn6D8NPF9Vvz206xiwt63vBR4dqu9Jcl2SrcA2BieAVo2qOlBVM1W1hcG/5R9V1cdY22P+S+Bckne30k4GXz++Vsf8ArAjyVvbf+M7GZyvWqvjXWxF42xTQBeT7Gg/r7uH+izvWp/Nfp3OkP8Cgytbvg38xrU+nqs4rn/B4M+4PwOebo9fAH4KOAGcbsvrh/r8Rvs5nGIFZ/jfiA/g5/jHq3fW9JiBW4G59m/9v4BNa3nMwG8C3wKeBf4ngytW1tx4gc8xOG/xIwbv2O95LeMEZtvP6tvAf6d9u8I4D7+GQZI6shandyRJl2HoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI78fz0O4LRsbDd/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens_train = [len(inp) for inp in  input_ids_train]\n",
    "plt.hist(lens_train, bins=1000, range=(0,1000))\n",
    "plt.show()\n",
    "lens_validation = [len(inp) for inp in  input_ids_validation]\n",
    "plt.hist(lens_validation, bins=1000, range=(0,1000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((np.array(lens_train)<=256).sum()/ len(lens_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum sequence length.\n",
    "MAX_LEN = 256\n",
    "\n",
    "print('Padding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "print('Padding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# Pad our input tokens with value 0.\n",
    "input_ids_train = pad_sequences(input_ids_train, maxlen=MAX_LEN)\n",
    "input_ids_validation = pad_sequences(input_ids_validation, maxlen=MAX_LEN)\n",
    "input_ids_test = pad_sequences(input_ids_test, maxlen=MAX_LEN)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks_train = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids_train:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks_train.append(att_mask)\n",
    "    \n",
    "# Create attention masks\n",
    "attention_masks_validation = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids_validation:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks_validation.append(att_mask)\n",
    "\n",
    "    \n",
    "attention_masks_test = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids_test:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks_test.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename\n",
    "train_inputs, validation_inputs, test_inputs, train_labels, validation_labels, test_labels = input_ids_train, input_ids_validation, input_ids_test, labels_train, labels_validation, labels_test\n",
    "train_masks, validation_masks, test_masks = attention_masks_train, attention_masks_validation, attention_masks_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset & dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all inputs and labels into torch tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "test_masks = torch.tensor(test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([353376, 256])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model & optimiser & scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_LABELS = 3  # 3 for MNLI, 2 for IMDB, Toxic-WIKI, PUBMED\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = NUM_LABELS,\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 4  # 2 for text classification, 4 for MNLI \n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, \n",
    "                                            num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return (pred_flat == labels_flat).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation only - to make sure that accuracy is more or less random at the beginnig\n",
    "print(\"\")\n",
    "print(\"Running Validation...\")\n",
    "device = \"cuda\"\n",
    "t0 = time.time()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for batch in validation_dataloader:\n",
    "\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "    # values prior to applying an activation function like the softmax.\n",
    "    logits = outputs[0]\n",
    "    \n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences.\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Accumulate the total accuracy.\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    # Track the number of batches\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "# Report the final accuracy for this validation run.\n",
    "print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    print()\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 200 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull theloss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0 - This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.4f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), open(data_path+\"_bert.pth\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with a saved model & cpu - Load a trained model that you have fine-tuned\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
    "model_loaded = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", state_dict=torch.load(data_path+\"_bert.pth\"), num_labels=NUM_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "text = ('it was tedious movie at times but altogether i would recommend it', 'the movie is unrecommended')\n",
    "model_loaded.eval()\n",
    "with torch.no_grad():\n",
    "    if type(text) == tuple:\n",
    "        sent_token = torch.Tensor(pad_sequences([tokenizer.encode(*text, add_special_tokens=True)], 128)).long()\n",
    "    else:\n",
    "        sent_token = torch.Tensor(pad_sequences([tokenizer.encode(text, add_special_tokens=True)], 128)).long()\n",
    "    sent_att = (sent_token > 0).int()\n",
    "    res = model_loaded(sent_token, attention_mask=sent_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.2395, -1.3262,  4.2226]]),)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## infer on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'data/mnli/mnli'\n",
    "model_path = base_path + '_bert2.pth'\n",
    "tst_path = base_path + '_test_clean.csv'\n",
    "out_path = base_path + '_test_pred.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", state_dict=torch.load(model_path), num_labels=NUM_LABELS)\n",
    "model_loaded.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rad the dataset\n",
    "tst_df = pd.read_csv(tst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "proba_list = []\n",
    "raw_out = []\n",
    "# evaluation only\n",
    "print(\"\")\n",
    "print(\"Running Test...\")\n",
    "device = \"cuda\"\n",
    "t0 = time.time()\n",
    "\n",
    "model_loaded.eval()\n",
    "\n",
    "# Tracking variables \n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for batch in test_dataloader:\n",
    "\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model_loaded(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # Get the \"logits\" output by the model\n",
    "    logits = outputs[0]\n",
    "    \n",
    "    raw_out.append(logits.cpu().numpy())\n",
    "    \n",
    "    probs, preds = F.softmax(logits).max(1)\n",
    "    \n",
    "    pred_list.append(preds.cpu().numpy())\n",
    "    proba_list.append(probs.cpu().numpy())\n",
    "    \n",
    "tst_df['preds'] = np.concatenate(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# look at distibution of probabilities\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(np.concatenate(proba_list), bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8347330381228686"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure of accuracy and no mistakes\n",
    "(tst_df['preds']==tst_df['label']).sum()/len(tst_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result\n",
    "tst_df.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### infernce with other code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.TextModels.E2EBert as E2EBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.TextModels.E2EBert' from '/home/gallil/Desktop/projects/LUNATC/src/TextModels/E2EBert.py'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(E2EBert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "code_model = E2EBert.BertTextModel(trained_model=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 ms  7.04 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "code_model.predict_proba(32*['amazing film !'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield ndx, iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, ['thank you for understanding . i think very highly of you and would not revert without discussion .', ': dear god this site is horrible .', '\"::: somebody will invariably try to add religion ? really ?? you mean , the way people have invariably kept adding \"\" religion \"\" to the samuel beckett infobox ? and why do you bother bringing up the long - dead completely non - existent \"\" influences \"\" issue ? you\\'re just flailing , making up crap on the fly . ::: for comparison , the only explicit acknowledgement in the entire amos oz article that he is personally jewish is in the categories ! \"'])\n",
      "(3, ['\" it says it right there that it is a type . the \"\" type \"\" of institution is needed in this case because there are three levels of suny schools : - university centers and doctoral granting institutions - state colleges - community colleges . it is needed in this case to clarify that ub is a suny center . it says it even in binghamton university , university at albany , state university of new york , and stony brook university . stop trying to say it\\'s not because i am totally right in this case .\"', '\" = before adding a new product to the list , make sure it\\'s relevant = before adding a new product to the list , make sure it has a wikipedia entry already , \"\" proving \"\" it\\'s relevance and giving the reader the possibility to read more about it . otherwise it could be subject to deletion . see this article\\'s revision history .\"', 'this other one from 1897'])\n",
      "(6, ['= reason for banning throwing = this article needs a section on / why / throwing is banned . at the moment , to a non - cricket fan , it seems kind of arbitrary .', '|blocked ]] from editing wikipedia . |', '= arabs are committing genocide in iraq , but no protests in europe . = may europe also burn in hell .'])\n",
      "(9, ['please stop . if you continue to vandalize wikipedia , as you did to homosexuality , you will be blocked from editing .'])\n"
     ]
    }
   ],
   "source": [
    "for b in batch(tst_df.content.iloc[:10].values.tolist(), 3):\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99998349126688016655"
     ]
    }
   ],
   "source": [
    "code_preds = []\n",
    "for i, text in enumerate(tst_df.content):\n",
    "    print(f'\\r{i/len(tst_df)}', end='')\n",
    "    code_preds.append(code_model.predict_proba(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995047380064054555"
     ]
    }
   ],
   "source": [
    "code_preds = []\n",
    "for i, text in batch(tst_df.content.values.tolist(), 64):\n",
    "    print(f'\\r{i/len(tst_df)}', end='')\n",
    "    code_preds.append(code_model.predict_proba(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.abs((np.concatenate(code_preds) - np.concatenate(raw_out))) > 0.0001).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60574, 2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(raw_out).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gallilm2",
   "language": "python",
   "name": "gallilm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
