{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "f = open('log2.txt', 'w')\n",
    "sys.stdout = f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_val = 42\n",
    "device = \"cuda:0\"\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/mnli2/mnli\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path+\"_train_clean.csv\")\n",
    "df_train, df_validation = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(data_path+\"_test_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.head(1000)\n",
    "df_validation = df_validation.head(1000)\n",
    "df_test = df_test.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for 2 text tasks like NLI\n",
    "if \"content2\" in df_train.columns:\n",
    "    df_train[\"content\"] = list(zip(df_train.content, df_train.content2))\n",
    "    df_train = df_train.drop(\"content2\", 1)\n",
    "    df_validation[\"content\"] = list(zip(df_validation.content, df_validation.content2))\n",
    "    df_validation = df_validation.drop(\"content2\", 1)\n",
    "    df_test[\"content\"] = list(zip(df_test.content, df_test.content2))\n",
    "    df_test = df_test.drop(\"content2\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lists of sentences and their labels.\n",
    "sentences_train = df_train.content.values\n",
    "labels_train = df_train.label.values\n",
    "\n",
    "sentences_validation = df_validation.content.values\n",
    "labels_validation = df_validation.label.values\n",
    "\n",
    "sentences_test = df_test.content.values\n",
    "labels_test = df_test.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tokenising & formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train done!\n",
      "Validation done!\n",
      "Test done!\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids_train = []\n",
    "\n",
    "# For every sentence in train\n",
    "for sent in sentences_train:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        *sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_train.append(encoded_sent)\n",
    "print(\"Train done!\")\n",
    "    \n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids_validation = []\n",
    "\n",
    "# For every sentence in test\n",
    "for sent in sentences_validation:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        *sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_validation.append(encoded_sent)\n",
    "print(\"Validation done!\")\n",
    "    \n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids_test = []\n",
    "\n",
    "# For every sentence in test\n",
    "for sent in sentences_test:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        *sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_test.append(encoded_sent)\n",
    "print(\"Test done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(input_ids, maxlen):\n",
    "    padded = []\n",
    "    for inp in input_ids:\n",
    "        if len(inp) >= maxlen:\n",
    "            padded.append(inp[:maxlen-1] + [inp[-1]])\n",
    "        else:\n",
    "            padded.append(inp + [0]*(maxlen - len(inp)))\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### histogram of length for choosing the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens_train = [len(inp) for inp in  input_ids_train]\n",
    "plt.hist(lens_train, bins=1000, range=(0,1000))\n",
    "plt.show()\n",
    "lens_validation = [len(inp) for inp in  input_ids_validation]\n",
    "plt.hist(lens_validation, bins=1000, range=(0,1000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print((np.array(lens_train)<=256).sum()/ len(lens_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding/truncating all sentences to 256 values...\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Set the maximum sequence length.\n",
    "MAX_LEN = 256\n",
    "\n",
    "print('Padding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "print('Padding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# Pad our input tokens with value 0.\n",
    "input_ids_train = pad_sequences(input_ids_train, maxlen=MAX_LEN)\n",
    "input_ids_validation = pad_sequences(input_ids_validation, maxlen=MAX_LEN)\n",
    "input_ids_test = pad_sequences(input_ids_test, maxlen=MAX_LEN)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks_train = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids_train:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks_train.append(att_mask)\n",
    "    \n",
    "# Create attention masks\n",
    "attention_masks_validation = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids_validation:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks_validation.append(att_mask)\n",
    "\n",
    "    \n",
    "attention_masks_test = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids_test:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks_test.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename\n",
    "train_inputs, validation_inputs, test_inputs, train_labels, validation_labels, test_labels = input_ids_train, input_ids_validation, input_ids_test, labels_train, labels_validation, labels_test\n",
    "train_masks, validation_masks, test_masks = attention_masks_train, attention_masks_validation, attention_masks_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset & dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all inputs and labels into torch tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "test_masks = torch.tensor(test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 256])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model & optimiser & scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_LABELS = 3  # 3 for MNLI, 2 for IMDB, Toxic-WIKI, PUBMED\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = NUM_LABELS,\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 4  # 2 for text classification, 4 for MNLI \n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, \n",
    "                                            num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return (pred_flat == labels_flat).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.32\n",
      "  Validation took: 0:00:08\n"
     ]
    }
   ],
   "source": [
    "# evaluation only - to make sure that accuracy is more or less random at the beginnig\n",
    "print(\"\")\n",
    "print(\"Running Validation...\")\n",
    "device = \"cuda\"\n",
    "t0 = time.time()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for batch in validation_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "    # values prior to applying an activation function like the softmax.\n",
    "    logits = outputs[0]\n",
    "    \n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences.\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Accumulate the total accuracy.\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    # Track the number of batches\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "# Report the final accuracy for this validation run.\n",
    "print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.11\n",
      "  Training epcoh took: 0:00:24\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.4008\n",
      "  Validation took: 0:00:08\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:00:25\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.5069\n",
      "  Validation took: 0:00:08\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-28-41ec85a7afd6>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     55\u001B[0m         \u001B[0;31m# Perform a backward pass to calculate the gradients.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 56\u001B[0;31m         \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     57\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m         \u001B[0;31m# Clip the norm of the gradients to 1.0 - This is to help prevent the \"exploding gradients\" problem.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/torch/tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph)\u001B[0m\n\u001B[1;32m    219\u001B[0m                 \u001B[0mretain_graph\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    220\u001B[0m                 create_graph=create_graph)\n\u001B[0;32m--> 221\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    222\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    223\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001B[0m\n\u001B[1;32m    130\u001B[0m     Variable._execution_engine.run_backward(\n\u001B[1;32m    131\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 132\u001B[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001B[0m\u001B[1;32m    133\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    134\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    print()\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 200 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull theloss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0 - This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.4f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), open(data_path+\"_bert.pth\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with a saved model & cpu - Load a trained model that you have fine-tuned\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
    "model_loaded = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", state_dict=torch.load(data_path+\"_bert.pth\"), num_labels=NUM_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "text = ('it was tedious movie at times but altogether i would recommend it', 'the movie is unrecommended')\n",
    "model_loaded.eval()\n",
    "with torch.no_grad():\n",
    "    if type(text) == tuple:\n",
    "        sent_token = torch.Tensor(pad_sequences([tokenizer.encode(*text, add_special_tokens=True)], 128)).long()\n",
    "    else:\n",
    "        sent_token = torch.Tensor(pad_sequences([tokenizer.encode(text, add_special_tokens=True)], 128)).long()\n",
    "    sent_att = (sent_token > 0).int()\n",
    "    res = model_loaded(sent_token, attention_mask=sent_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.2395, -1.3262,  4.2226]]),)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## infer on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'data/mnli2/mnli'\n",
    "model_path = base_path + '_bert.pth'\n",
    "tst_path = base_path + '_test_clean.csv'\n",
    "out_path = base_path + '_test_pred_bert.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_LABELS = 3\n",
    "model_loaded = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", state_dict=torch.load(model_path), num_labels=NUM_LABELS)\n",
    "model_loaded.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "tst_df = pd.read_csv(tst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "proba_list = []\n",
    "raw_out = []\n",
    "# evaluation only\n",
    "print(\"\")\n",
    "print(\"Running Test...\")\n",
    "device = \"cuda\"\n",
    "t0 = time.time()\n",
    "\n",
    "model_loaded.eval()\n",
    "\n",
    "# Tracking variables \n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for batch in test_dataloader:\n",
    "\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model_loaded(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # Get the \"logits\" output by the model\n",
    "    logits = outputs[0]\n",
    "    \n",
    "    raw_out.append(logits.cpu().numpy())\n",
    "    \n",
    "    probs, preds = F.softmax(logits).max(1)\n",
    "    \n",
    "    pred_list.append(preds.cpu().numpy())\n",
    "    proba_list.append(probs.cpu().numpy())\n",
    "    \n",
    "tst_df['preds'] = np.concatenate(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# look at distibution of probabilities\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(np.concatenate(proba_list), bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df[\"preds\"] = np.concatenate(code_preds).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8372"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure of accuracy and no mistakes\n",
    "(tst_df['preds']==tst_df['label']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result\n",
    "tst_df.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### infernce with other code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import src.TextModels.Bert as Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.TextModels.E2EBert' from '/home/gallil/Desktop/projects/LUNATC/src/TextModels/E2EBert.py'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(Bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for 2 text tasks like NLI\n",
    "if \"content2\" in tst_df.columns:\n",
    "    tst_df[\"content\"] = list(zip(tst_df.content, tst_df.content2))\n",
    "    tst_df = tst_df.drop(\"content2\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_model = Bert.BertTextModel(num_classes=3, trained_model=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "code_model.predict_proba(32*['amazing film !'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield ndx, iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code_preds = []\n",
    "# for i, text in enumerate(tst_df.content):\n",
    "#     print(f'\\r{i/len(tst_df)}', end='')\n",
    "#     code_preds.append(code_model.predict_proba(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9984"
     ]
    }
   ],
   "source": [
    "code_preds = []\n",
    "for i, text in batch(tst_df.content.values.tolist(), 64):\n",
    "    print(f'\\r{i/len(tst_df)}', end='')\n",
    "    if type(text[0]) == tuple:\n",
    "        text = tuple(zip(*text))\n",
    "    code_preds.append(code_model.predict_proba(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.abs((np.concatenate(code_preds) - np.concatenate(raw_out))) > 0.0001).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8372"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.concatenate(code_preds).argmax(1) == tst_df.label).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(on the basis of engineering estimates , the e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(tuppence was first at the rendezvous ., no on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(the discount shopping centers here rival thos...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(right inexperience also that's something that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(we shall be pinched at first , of course , be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>(do you watch that ?, can you see ?)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>(to a western ear , the most predictable of la...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>(the recorder captured the sounds of loud thum...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99989</th>\n",
       "      <td>(that's a good attitude !, you feel good about...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99990</th>\n",
       "      <td>(bloomer ( for `flower '), butter ( for `ram '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99991 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  label\n",
       "0      (on the basis of engineering estimates , the e...      1\n",
       "1      (tuppence was first at the rendezvous ., no on...      0\n",
       "2      (the discount shopping centers here rival thos...      2\n",
       "3      (right inexperience also that's something that...      0\n",
       "4      (we shall be pinched at first , of course , be...      1\n",
       "...                                                  ...    ...\n",
       "99986               (do you watch that ?, can you see ?)      2\n",
       "99987  (to a western ear , the most predictable of la...      2\n",
       "99988  (the recorder captured the sounds of loud thum...      2\n",
       "99989  (that's a good attitude !, you feel good about...      1\n",
       "99990  (bloomer ( for `flower '), butter ( for `ram '...      0\n",
       "\n",
       "[99991 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8368707690741589"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.concatenate(code_preds).argmax(1) == tst_df.label).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348857331908179"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.concatenate(code_preds).argmax(1) == tst_df.label).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gallilm2",
   "language": "python",
   "name": "gallilm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}