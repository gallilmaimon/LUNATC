{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to analyse the log files produced by different attack methods in order to key metrics, namely attack success rate and oracle access (logit access and classification access)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "data_path = 'data/aclImdb/imdb'\n",
    "model_type = 'bert'\n",
    "sim_thresh = 0.7\n",
    "test_indices = [8, 13, 17, 35, 83, 103, 111, 129, 182, 184, 189, 221, 232, 237, 255, 264, 297, 328, 336, 338, 345, 356, 363, 430, 435, 436, 472, 473, 474, 477, 488, 489, 493, 521, 527, 537, 549, 589, 608, 610, 634, 642, 656, 669, 723, 740, 743, 761, 766, 768, 786, 794, 805, 812, 813, 832, 844, 861, 887, 889, 923, 961, 963, 982, 986, 992, 1024, 1050, 1068, 1077, 1086, 1090, 1129, 1145, 1158, 1167, 1175, 1226, 1235, 1242, 1261, 1269, 1311, 1318, 1342, 1351, 1363, 1369, 1392, 1430, 1443, 1447, 1454, 1466, 1468, 1473, 1488, 1508, 1509, 1515, 1520, 1604, 1622, 1626, 1630, 1632, 1647, 1663, 1672, 1684, 1698, 1706, 1721, 1731, 1739, 1747, 1769, 1794, 1823, 1825, 1872, 1884, 1900, 1901, 1902, 1917, 1938, 1941, 1948, 1950, 1955, 1967, 1971, 1976, 2005, 2009, 2013, 2038, 2041, 2042, 2045, 2088, 2093, 2098, 2099, 2101, 2108, 2122, 2134, 2145, 2190, 2197, 2198, 2222, 2226, 2238, 2259, 2272, 2283, 2284, 2303, 2310, 2316, 2326, 2346, 2372, 2373, 2375, 2378, 2404, 2410, 2431, 2460, 2469, 2542, 2551, 2558, 2561, 2564, 2568, 2592, 2604, 2611, 2621, 2623, 2626, 2636, 2645, 2665, 2670, 2700, 2713, 2724, 2733, 2752, 2756, 2773, 2819, 2842, 2843, 2852, 2854, 2890, 2891, 2896, 2901, 2906, 2911, 2920, 2921, 2925, 2977, 2989, 2994, 3027, 3031, 3052, 3069, 3086, 3117, 3136, 3151, 3159, 3174, 3180, 3213, 3220, 3225, 3228, 3237, 3243, 3249, 3252, 3260, 3263, 3270, 3283, 3285, 3286, 3288, 3291, 3301, 3302, 3308, 3309, 3311, 3312, 3316, 3323, 3324, 3326, 3329, 3330, 3333, 3335, 3336, 3341, 3343, 3344, 3345, 3351, 3352, 3353, 3355, 3356, 3358, 3359, 3368, 3371, 3373, 3374, 3377, 3378, 3388, 3392, 3394, 3397, 3402, 3403, 3404, 3405, 3406, 3408, 3413, 3421, 3422, 3427, 3429, 3436, 3438, 3440, 3441, 3448, 3451, 3453, 3458, 3462, 3470, 3478, 3485, 3486, 3491, 3492, 3505, 3507, 3511, 3517, 3518, 3522, 3523, 3525, 3527, 3528, 3533, 3536, 3537, 3543, 3544, 3551, 3555, 3560, 3564, 3567, 3572, 3573, 3574, 3584, 3588, 3589, 3590, 3592, 3595, 3596, 3597, 3598, 3601, 3603, 3616, 3617, 3622, 3629, 3636, 3641, 3648, 3649, 3651, 3661, 3666, 3667, 3670, 3672, 3676, 3677, 3679, 3680, 3683, 3686, 3689, 3690, 3691, 3694, 3696, 3702, 3705, 3706, 3708, 3710, 3711, 3712, 3713, 3714, 3715, 3717, 3720, 3724, 3725, 3727, 3733, 3740]\n",
    "genfooler_seed = 42\n",
    "genfooler_trainsize = 5\n",
    "lunatc_run_name = f'{data_path}_dqn_contin_results/'  # This is the default name but you might want to change to indicate train size, seed or anything else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack Sucess Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section calculates the attack success rates of the different baselines and allows us to get the key results from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textfooler attack success rate:  30.34300791556728\n",
      "PWWS attack success rate:  79.68337730870712\n",
      "Simple Search attack success rate:  94.72295514511873\n"
     ]
    }
   ],
   "source": [
    "### Baselines\n",
    "# Textfooler\n",
    "df_tf = pd.read_csv(f'{data_path}_tf_{model_type}.csv').iloc[test_indices]\n",
    "suc_tf = np.where(df_tf.max_score > sim_thresh)[0]\n",
    "print('Textfooler attack success rate: ', 100*len(suc_tf)/len(test_indices))\n",
    "\n",
    "# PWWS\n",
    "df_pwws = pd.read_csv(f'{data_path}_pwws_{model_type}.csv').iloc[test_indices]\n",
    "suc_pwws = np.where(df_pwws.max_score > sim_thresh)[0]\n",
    "print('PWWS attack success rate: ', 100*len(suc_pwws)/len(test_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenFooler_PWWS attack success rate:  37.20316622691293\n"
     ]
    }
   ],
   "source": [
    "## Baselines with randomness - these can be run for different seeds to acheive the results in the paper\n",
    "# Simple Search\n",
    "suc_search = []\n",
    "for i in test_indices:\n",
    "    try:\n",
    "        df = pd.read_csv(f'{data_path}_dqn_results/{i}.csv')\n",
    "        if df.score.max() > 100*sim_thresh:\n",
    "            suc_search.append(i)\n",
    "    except:\n",
    "        print(i)\n",
    "print('Simple Search attack success rate: ', 100*len(suc_search)/len(test_indices))\n",
    "\n",
    "# GenFooler - tf\n",
    "df_gtf = pd.read_csv(f'{data_path}_genfooler_{model_type}/attack_tf{genfooler_trainsize}_{genfooler_seed}.csv')\n",
    "suc_gtf = np.where(df_gtf.max_score > sim_thresh)[0]\n",
    "print('GenFooler_TF attack success rate: ', 100*len(suc_gtf)/len(test_indices))\n",
    "\n",
    "# GenFooler - pwws\n",
    "df_gpwws = pd.read_csv(f'{data_path}_genfooler_{model_type}/attack_pwws{genfooler_trainsize}_{genfooler_seed}.csv')\n",
    "suc_gpwws = np.where(df_gpwws.max_score > sim_thresh)[0]\n",
    "print('GenFooler_PWWS attack success rate: ', 100*len(suc_gpwws)/len(test_indices))\n",
    "\n",
    "# LUNATC\n",
    "suc_lunatc = []\n",
    "for i in test_indices:\n",
    "    try:\n",
    "        df = pd.read_csv(f'{lunatc_run_name}/{i}.csv')\n",
    "        if df.score.max() > 100*sim_thresh:\n",
    "            suc_lunatc.append(i)\n",
    "    except:\n",
    "        print(i)\n",
    "print('LUNATC attack success rate: ', 100*len(suc_lunatc)/len(test_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oracle Access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section describes how to calculate the oracle access of different methods. This seperates logit access and class access. This is done after the attack is completed in order to be more efficient if this calculation isn't needed - this means it uses specific knoweldge of the algorithms internals to calculate the oracle access - it will not neccesarily output correct results for other attack methods!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sise/home/gallilm/LUNATC/\n",
      "WARNING:tensorflow:From /home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gallilm/.conda/envs/gallilm2/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import src.Environments.utils.action_utils as act_utils\n",
    "from src.TextModels.Bert import BertTextModel\n",
    "from src.TextModels.WordLSTM import WordLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "sess = tf.Session()\n",
    "sess.run([tf.global_variables_initializer(), tf.tables_initializer()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_synonym_oracle_access(text, word_index, text_model, sess, topn=50, word_sim_thresh=0.9, sentence_sim_thresh=0.7):\n",
    "    \"\"\"\n",
    "    This function calculates how many times the oracle is accessed to evaluate a certain synonym replacement action \n",
    "    :param text: the original text\n",
    "    :param word_index: the index of the word to be replaced\n",
    "    :param text_model: the language model being \"attacked\"\n",
    "    :param sess: an initialised tensorflow session for runtime efficiency\n",
    "    :param topn: how many candidates to consider as synonyms\n",
    "    :param word_sim_thresh: how similar does a candidate synonym need to be in order to be considered\n",
    "    :param sentence_sim_thresh: how similar does the new sentence need to be to the original\n",
    "    :return: the number of times the orocale is accessed\n",
    "    \"\"\"\n",
    "    new_text, new_word_index = act_utils.get_words_local_env(text, word_index)\n",
    "\n",
    "    # Get the list of words from the entire text\n",
    "    words = new_text.split()\n",
    "    word = words[new_word_index]\n",
    "\n",
    "    # if word not in vocabulary\n",
    "    if word in act_utils.STOPWORDS or word not in act_utils.word_vectors:\n",
    "        return 0\n",
    "\n",
    "    # find synonym options\n",
    "    rep_options = act_utils.possible_synonyms(word, topn, word_sim_thresh, False)\n",
    "\n",
    "    # no good enough synonyms\n",
    "    if len(rep_options) == 0:\n",
    "        return 0\n",
    "\n",
    "    # get only those with same POS\n",
    "    same_pos_inds = act_utils.get_same_POS_replacements(text, word_index, rep_options)\n",
    "    if len(same_pos_inds) == 0:\n",
    "        return 0\n",
    "    rep_options = act_utils.itemgetter(*same_pos_inds)(rep_options)\n",
    "    if type(rep_options) == str:\n",
    "        rep_options = list([rep_options])\n",
    "    else:\n",
    "        rep_options = list(rep_options)\n",
    "\n",
    "    # get sentence similarity to original\n",
    "    sent_options = []\n",
    "    for opt in rep_options:\n",
    "        words[new_word_index] = opt\n",
    "        sent_options.append(' '.join(words))\n",
    "    sentence_similarity = act_utils.get_similarity([new_text] + sent_options, sess)\n",
    "    cand_mask = (sentence_similarity >= sentence_sim_thresh)\n",
    "\n",
    "    # regenerate the entire text options for classification and returning\n",
    "    sent_options = []\n",
    "    all_words = text.split()\n",
    "    for opt in rep_options:\n",
    "        all_words[word_index] = opt\n",
    "        sent_options.append(' '.join(all_words))\n",
    "\n",
    "    if cand_mask.sum() == 1:\n",
    "        return 0\n",
    "    elif cand_mask.sum() > 1:\n",
    "        sent_options = [i for (i, v) in zip(sent_options, cand_mask) if v]\n",
    "        return cand_mask.sum()\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_action_access(r):\n",
    "    inds_ = np.where((np.array(r.best_sent.split()) != np.array(r.content.split())))[0]\n",
    "    return sum([replace_with_synonym_oracle_access(r.content, i, model, sess) for i in inds_])\n",
    "\n",
    "def calc_pwws_access(r):\n",
    "    return sum([replace_with_synonym_oracle_access(r.content, i, model, sess) for i in range(len(r.content.split()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == 'bert':\n",
    "    model = BertTextModel(trained_model=data_path + '_bert.pth', device=device)\n",
    "elif model_type == 'lstm':\n",
    "    model = LSTM.WordLSTM(trained_model=data_path + '_word_lstm.pth', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textfooler - logit access:  171.28496042216358 class access:  22.88126649076517\n"
     ]
    }
   ],
   "source": [
    "# Textfooler\n",
    "df_tf = pd.read_csv(f'{data_path}_tf_{model_type}.csv').iloc[test_indices]\n",
    "df_tf['logit_access'] = df_tf.apply(calc_action_access, axis=1) + df_tf.apply(lambda r: len(r.content.split()), axis=1)\n",
    "df_tf['class_access'] = df_tf.apply(lambda r: (np.array(r.content.split()) != np.array(r.best_sent.split())).sum() + 1, axis=1)\n",
    "print('Textfooler - logit access: ', df_tf.logit_access.mean(), 'class access: ', df_tf.class_access.mean())\n",
    "\n",
    "# PWWS\n",
    "df_pwws = pd.read_csv(f'{data_path}_pwws_{model_type}.csv').iloc[test_indices]\n",
    "df_pwws['logit_access'] = df_pwws.apply(calc_pwws_access, axis=1) + df_pwws.apply(lambda r: len(r.content.split()), axis=1)\n",
    "df_pwws['class_access'] = df_pwws.apply(lambda r: (np.array(r.content.split()) != np.array(r.best_sent.split())).sum() + 1, axis=1)\n",
    "print('PWWS - logit access: ', df_pwws.logit_access.mean(), 'class access: ', df_pwws.class_access.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Search - logit access:  61.47229551451187 class access:  24.21372031662269\n"
     ]
    }
   ],
   "source": [
    "# Simple Search\n",
    "search_dfs = []\n",
    "for i in test_indices:\n",
    "    try:\n",
    "        search_dfs.append(pd.read_csv(f'{data_path}_dqn_results/{i}.csv').iloc[[0]])\n",
    "    except:\n",
    "        print(i)\n",
    "df_search = pd.concat(search_dfs)\n",
    "df_search.columns = ['content', 'best_sent', 'max_score']\n",
    "df_search['logit_access'] = df_search.apply(calc_action_access, axis=1)\n",
    "df_search['class_access'] = df_search.apply(lambda r: (np.array(r.content.split()) != np.array(r.best_sent.split())).sum() + 1, axis=1)\n",
    "print('Simple Search - logit access: ', df_search.logit_access.mean(), 'class access: ', df_search.class_access.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LUNATC\n",
    "lunatc_dfs = []\n",
    "for i in test_indices:\n",
    "    try:\n",
    "        lunatc_dfs.append(pd.read_csv(f'{lunatc_run_name}/{i}.csv').iloc[[0]])\n",
    "    except:\n",
    "        print(i)\n",
    "df_lunatc = pd.concat(lunatc_dfs)\n",
    "df_lunatc.columns = ['content', 'best_sent', 'max_score']\n",
    "df_lunatc['logit_access'] = df_lunatc.apply(calc_action_access, axis=1)\n",
    "df_lunatc['class_access'] = df_lunatc.apply(lambda r: (np.array(r.content.split()) != np.array(r.best_sent.split())).sum() + 1, axis=1)\n",
    "print('LUNATC - logit access: ', df_lunatc.logit_access.mean(), 'class access: ', df_lunatc.class_access.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gallilm2",
   "language": "python",
   "name": "gallilm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
